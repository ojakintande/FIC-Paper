# FIC-Paper

This paper introduces the Fairness Information Criterion (FIC) framework, a unified method for statistically rigorous and context-aware fairness auditing in machine learning. Moving beyond binary fairness determinations, FIC integrates performance evaluation with multi-criteria fairness assessment, examining Independence, Separation,
and Sufficiency, under an adjustable fairness significance threshold (αF ). The framework outputs an interpretable four-tier benchmark (Unacceptable, Questionable, Acceptable, Optimum) supported by visual disparity diagnostics. We evaluate FIC on two high-stakes real-world domains: recidivism risk assessment (COMPAS dataset, n = 5278) and income classification (Adult dataset, n = 45222). Both datasets exhibit significant pre-existing disparities. Using logistic regression variants (L1/L2 regularized) with stratified 70-30 splits, we demonstrate how fairness conclusions are inherently threshold-dependent. At a stringent αF = 0.05, models show statistically significant disparities across multiple racial groups, failing the fairness audit. As αF is relaxed to 0.20, most comparisons achieve fairness certification, illustrating a quantifiable fairness–utility trade-off. These results underscore that fairness is not binary, but an adjustable threshold that must be aligned with domain-specific equity requirements.
The FIC framework offers practitioners an actionable, statistically grounded tool for transparency and accountability, advancing the development of context-aware and ethically deployable AI systems. 

Keywords: Algorithmic Fairness, Fairness Auditing, Fairness Information Criterion, Statistical Testing, Actionable & Interpretable Benchmarking Tier.
