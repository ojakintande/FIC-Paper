{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b33b3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#................................... FIC Score Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19bd075",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################..... Simulated Cases .......................###################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3ac4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#... With all FIC Benmarking Tiers for alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f48ac9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FAIRNESS INFORMATION CRITERION (FIC) ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "CASE 1: Healthcare - Depression Diagnosis\n",
      "================================================================================\n",
      "GROUP METRICS TABLE (Baseline Logistic Regression):\n",
      "            accuracy  selection_rate     tpr     tnr     fpr     fnr     ppv     npv      f1     auc\n",
      "Male          0.7470          0.0281  0.0581  0.9821  0.0179  0.9419  0.5263  0.7534  0.1047  0.6563\n",
      "Female        0.6834          0.0148  0.0143  0.9850  0.0150  0.9857  0.3000  0.6892  0.0273  0.6029\n",
      "Non-binary    0.5338          0.0338  0.0294  0.9625  0.0375  0.9706  0.4000  0.5385  0.0548  0.6287\n",
      "FIC ANALYSIS TABLE:\n",
      "         Group Pair              alphaF=0.05 Hypothesis alphaF=0.05               alphaF=0.1    Hypothesis alphaF=0.1              alphaF=0.15   Hypothesis alphaF=0.15               alphaF=0.2    Hypothesis alphaF=0.2\n",
      "Female - Non-binary omega=0.1496, FIC=-1.993     Reject H₀ (Unfair) omega=0.1496, FIC=-0.496       Reject H₀ (Unfair)  omega=0.1496, FIC=0.002 Fail to reject Ho (Fair)  omega=0.1496, FIC=0.252 Fail to reject Ho (Fair)\n",
      "      Male - Female omega=0.0636, FIC=-0.272     Reject H₀ (Unfair)  omega=0.0636, FIC=0.364 Fail to reject Ho (Fair)  omega=0.0636, FIC=0.576 Fail to reject Ho (Fair)  omega=0.0636, FIC=0.682 Fail to reject Ho (Fair)\n",
      "  Male - Non-binary omega=0.2133, FIC=-3.265     Reject H₀ (Unfair) omega=0.2133, FIC=-1.133       Reject H₀ (Unfair) omega=0.2133, FIC=-0.422       Reject H₀ (Unfair) omega=0.2133, FIC=-0.066       Reject H₀ (Unfair)\n",
      "TIER CLASSIFICATION:\n",
      "\n",
      "For alphaF = 0.05:\n",
      "--------------------------------------------------\n",
      "Male - Female: ω=0.0636, FIC=-0.272 → Unacceptable\n",
      "Male - Non-binary: ω=0.2133, FIC=-3.265 → Unacceptable\n",
      "Female - Non-binary: ω=0.1496, FIC=-1.993 → Unacceptable\n",
      "\n",
      "For alphaF = 0.1:\n",
      "--------------------------------------------------\n",
      "Male - Female: ω=0.0636, FIC=0.364 → Questionable\n",
      "Male - Non-binary: ω=0.2133, FIC=-1.133 → Unacceptable\n",
      "Female - Non-binary: ω=0.1496, FIC=-0.496 → Unacceptable\n",
      "\n",
      "For alphaF = 0.15:\n",
      "--------------------------------------------------\n",
      "Male - Female: ω=0.0636, FIC=0.576 → Acceptable\n",
      "Male - Non-binary: ω=0.2133, FIC=-0.422 → Unacceptable\n",
      "Female - Non-binary: ω=0.1496, FIC=0.002 → Questionable\n",
      "\n",
      "For alphaF = 0.2:\n",
      "--------------------------------------------------\n",
      "Male - Female: ω=0.0636, FIC=0.682 → Acceptable\n",
      "Male - Non-binary: ω=0.2133, FIC=-0.066 → Unacceptable\n",
      "Female - Non-binary: ω=0.1496, FIC=0.252 → Questionable\n",
      "GENERATING VISUALIZATIONS...\n",
      "MODEL COMPARISON:\n",
      "   Model Overall Accuracy Avg FIC alphaF=0.10) ω_max (alphaF=0.10)\n",
      "BASELINE           0.6973               -0.422              0.2133\n",
      "      L1           0.7013               -0.416              0.2124\n",
      "      L2           0.6973               -0.422              0.2133\n",
      "\n",
      "================================================================================\n",
      "CASE 2: Criminal Justice - Recidivism Risk\n",
      "================================================================================\n",
      "GROUP METRICS TABLE (Baseline Logistic Regression):\n",
      "                  accuracy  selection_rate     tpr    tnr    fpr     fnr  ppv     npv      f1     auc\n",
      "Africa              0.6812          0.0021  0.0000  0.997  0.003  1.0000  0.0  0.6826  0.0000  0.5930\n",
      "Asia                0.7345          0.0029  0.0110  1.000  0.000  0.9890  1.0  0.7337  0.0217  0.6480\n",
      "South America       0.7757          0.0000  0.0000  1.000  0.000  1.0000  0.0  0.7757  0.0000  0.6109\n",
      "Oceania             0.8091          0.0000  0.0000  1.000  0.000  1.0000  0.0  0.8091  0.0000  0.6340\n",
      "EU                  0.8412          0.0000  0.0000  1.000  0.000  1.0000  0.0  0.8412  0.0000  0.6728\n",
      "Arab/Middle East    0.7235          0.0046  0.0164  1.000  0.000  0.9836  1.0  0.7222  0.0323  0.6484\n",
      "North America       0.8030          0.0038  0.0189  1.000  0.000  0.9811  1.0  0.8023  0.0370  0.5709\n",
      "FIC ANALYSIS TABLE:\n",
      "                      Group Pair              alphaF=0.05   Hypothesis alphaF=0.05               alphaF=0.1    Hypothesis alphaF=0.1              alphaF=0.15   Hypothesis alphaF=0.15              alphaF=0.2    Hypothesis alphaF=0.2\n",
      "       Africa - Arab/Middle East  omega=0.0423, FIC=0.153 Fail to reject Ho (Fair)  omega=0.0423, FIC=0.577 Fail to reject Ho (Fair)  omega=0.0423, FIC=0.718 Fail to reject Ho (Fair) omega=0.0423, FIC=0.788 Fail to reject Ho (Fair)\n",
      "                   Africa - Asia omega=0.0534, FIC=-0.067       Reject H₀ (Unfair)  omega=0.0534, FIC=0.466 Fail to reject Ho (Fair)  omega=0.0534, FIC=0.644 Fail to reject Ho (Fair) omega=0.0534, FIC=0.733 Fail to reject Ho (Fair)\n",
      "                     Africa - EU omega=0.1600, FIC=-2.200       Reject H₀ (Unfair) omega=0.1600, FIC=-0.600       Reject H₀ (Unfair) omega=0.1600, FIC=-0.067       Reject H₀ (Unfair) omega=0.1600, FIC=0.200 Fail to reject Ho (Fair)\n",
      "          Africa - North America omega=0.1219, FIC=-1.437       Reject H₀ (Unfair) omega=0.1219, FIC=-0.219       Reject H₀ (Unfair)  omega=0.1219, FIC=0.188 Fail to reject Ho (Fair) omega=0.1219, FIC=0.391 Fail to reject Ho (Fair)\n",
      "                Africa - Oceania omega=0.1279, FIC=-1.559       Reject H₀ (Unfair) omega=0.1279, FIC=-0.279       Reject H₀ (Unfair)  omega=0.1279, FIC=0.147 Fail to reject Ho (Fair) omega=0.1279, FIC=0.360 Fail to reject Ho (Fair)\n",
      "          Africa - South America omega=0.0945, FIC=-0.890       Reject H₀ (Unfair)  omega=0.0945, FIC=0.055 Fail to reject Ho (Fair)  omega=0.0945, FIC=0.370 Fail to reject Ho (Fair) omega=0.0945, FIC=0.527 Fail to reject Ho (Fair)\n",
      "Arab/Middle East - North America omega=0.0795, FIC=-0.591       Reject H₀ (Unfair)  omega=0.0795, FIC=0.205 Fail to reject Ho (Fair)  omega=0.0795, FIC=0.470 Fail to reject Ho (Fair) omega=0.0795, FIC=0.602 Fail to reject Ho (Fair)\n",
      "         Asia - Arab/Middle East  omega=0.0110, FIC=0.780 Fail to reject Ho (Fair)  omega=0.0110, FIC=0.890 Fail to reject Ho (Fair)  omega=0.0110, FIC=0.927 Fail to reject Ho (Fair) omega=0.0110, FIC=0.945 Fail to reject Ho (Fair)\n",
      "                       Asia - EU omega=0.1067, FIC=-1.133       Reject H₀ (Unfair) omega=0.1067, FIC=-0.067       Reject H₀ (Unfair)  omega=0.1067, FIC=0.289 Fail to reject Ho (Fair) omega=0.1067, FIC=0.467 Fail to reject Ho (Fair)\n",
      "            Asia - North America omega=0.0685, FIC=-0.370       Reject H₀ (Unfair)  omega=0.0685, FIC=0.315 Fail to reject Ho (Fair)  omega=0.0685, FIC=0.543 Fail to reject Ho (Fair) omega=0.0685, FIC=0.657 Fail to reject Ho (Fair)\n",
      "                  Asia - Oceania omega=0.0746, FIC=-0.492       Reject H₀ (Unfair)  omega=0.0746, FIC=0.254 Fail to reject Ho (Fair)  omega=0.0746, FIC=0.503 Fail to reject Ho (Fair) omega=0.0746, FIC=0.627 Fail to reject Ho (Fair)\n",
      "            Asia - South America  omega=0.0412, FIC=0.177 Fail to reject Ho (Fair)  omega=0.0412, FIC=0.588 Fail to reject Ho (Fair)  omega=0.0412, FIC=0.726 Fail to reject Ho (Fair) omega=0.0412, FIC=0.794 Fail to reject Ho (Fair)\n",
      "           EU - Arab/Middle East omega=0.1177, FIC=-1.353       Reject H₀ (Unfair) omega=0.1177, FIC=-0.177       Reject H₀ (Unfair)  omega=0.1177, FIC=0.216 Fail to reject Ho (Fair) omega=0.1177, FIC=0.412 Fail to reject Ho (Fair)\n",
      "              EU - North America  omega=0.0381, FIC=0.237 Fail to reject Ho (Fair)  omega=0.0381, FIC=0.619 Fail to reject Ho (Fair)  omega=0.0381, FIC=0.746 Fail to reject Ho (Fair) omega=0.0381, FIC=0.809 Fail to reject Ho (Fair)\n",
      "      Oceania - Arab/Middle East omega=0.0856, FIC=-0.712       Reject H₀ (Unfair)  omega=0.0856, FIC=0.144 Fail to reject Ho (Fair)  omega=0.0856, FIC=0.429 Fail to reject Ho (Fair) omega=0.0856, FIC=0.572 Fail to reject Ho (Fair)\n",
      "                    Oceania - EU  omega=0.0321, FIC=0.358 Fail to reject Ho (Fair)  omega=0.0321, FIC=0.679 Fail to reject Ho (Fair)  omega=0.0321, FIC=0.786 Fail to reject Ho (Fair) omega=0.0321, FIC=0.840 Fail to reject Ho (Fair)\n",
      "         Oceania - North America  omega=0.0061, FIC=0.879 Fail to reject Ho (Fair)  omega=0.0061, FIC=0.939 Fail to reject Ho (Fair)  omega=0.0061, FIC=0.960 Fail to reject Ho (Fair) omega=0.0061, FIC=0.970 Fail to reject Ho (Fair)\n",
      "South America - Arab/Middle East omega=0.0522, FIC=-0.043       Reject H₀ (Unfair)  omega=0.0522, FIC=0.478 Fail to reject Ho (Fair)  omega=0.0522, FIC=0.652 Fail to reject Ho (Fair) omega=0.0522, FIC=0.739 Fail to reject Ho (Fair)\n",
      "              South America - EU omega=0.0655, FIC=-0.310       Reject H₀ (Unfair)  omega=0.0655, FIC=0.345 Fail to reject Ho (Fair)  omega=0.0655, FIC=0.563 Fail to reject Ho (Fair) omega=0.0655, FIC=0.673 Fail to reject Ho (Fair)\n",
      "   South America - North America  omega=0.0274, FIC=0.453 Fail to reject Ho (Fair)  omega=0.0274, FIC=0.726 Fail to reject Ho (Fair)  omega=0.0274, FIC=0.818 Fail to reject Ho (Fair) omega=0.0274, FIC=0.863 Fail to reject Ho (Fair)\n",
      "         South America - Oceania  omega=0.0334, FIC=0.332 Fail to reject Ho (Fair)  omega=0.0334, FIC=0.666 Fail to reject Ho (Fair)  omega=0.0334, FIC=0.777 Fail to reject Ho (Fair) omega=0.0334, FIC=0.833 Fail to reject Ho (Fair)\n",
      "TIER CLASSIFICATION:\n",
      "\n",
      "For alphaF = 0.05:\n",
      "--------------------------------------------------\n",
      "Africa - Asia: ω=0.0534, FIC=-0.067 → Unacceptable\n",
      "Africa - South America: ω=0.0945, FIC=-0.890 → Unacceptable\n",
      "Africa - Oceania: ω=0.1279, FIC=-1.559 → Unacceptable\n",
      "Africa - EU: ω=0.1600, FIC=-2.200 → Unacceptable\n",
      "Africa - Arab/Middle East: ω=0.0423, FIC=0.153 → Questionable\n",
      "Africa - North America: ω=0.1219, FIC=-1.437 → Unacceptable\n",
      "Asia - South America: ω=0.0412, FIC=0.177 → Questionable\n",
      "Asia - Oceania: ω=0.0746, FIC=-0.492 → Unacceptable\n",
      "Asia - EU: ω=0.1067, FIC=-1.133 → Unacceptable\n",
      "Asia - Arab/Middle East: ω=0.0110, FIC=0.780 → Optimum (omega_max < 0.0125)\n",
      "Asia - North America: ω=0.0685, FIC=-0.370 → Unacceptable\n",
      "South America - Oceania: ω=0.0334, FIC=0.332 → Questionable\n",
      "South America - EU: ω=0.0655, FIC=-0.310 → Unacceptable\n",
      "South America - Arab/Middle East: ω=0.0522, FIC=-0.043 → Unacceptable\n",
      "South America - North America: ω=0.0274, FIC=0.453 → Questionable\n",
      "Oceania - EU: ω=0.0321, FIC=0.358 → Questionable\n",
      "Oceania - Arab/Middle East: ω=0.0856, FIC=-0.712 → Unacceptable\n",
      "Oceania - North America: ω=0.0061, FIC=0.879 → Optimum (omega_max < 0.0125)\n",
      "EU - Arab/Middle East: ω=0.1177, FIC=-1.353 → Unacceptable\n",
      "EU - North America: ω=0.0381, FIC=0.237 → Questionable\n",
      "Arab/Middle East - North America: ω=0.0795, FIC=-0.591 → Unacceptable\n",
      "\n",
      "For alphaF = 0.1:\n",
      "--------------------------------------------------\n",
      "Africa - Asia: ω=0.0534, FIC=0.466 → Questionable\n",
      "Africa - South America: ω=0.0945, FIC=0.055 → Questionable\n",
      "Africa - Oceania: ω=0.1279, FIC=-0.279 → Unacceptable\n",
      "Africa - EU: ω=0.1600, FIC=-0.600 → Unacceptable\n",
      "Africa - Arab/Middle East: ω=0.0423, FIC=0.577 → Acceptable\n",
      "Africa - North America: ω=0.1219, FIC=-0.219 → Unacceptable\n",
      "Asia - South America: ω=0.0412, FIC=0.588 → Acceptable\n",
      "Asia - Oceania: ω=0.0746, FIC=0.254 → Questionable\n",
      "Asia - EU: ω=0.1067, FIC=-0.067 → Unacceptable\n",
      "Asia - Arab/Middle East: ω=0.0110, FIC=0.890 → Optimum (omega_max < 0.0250)\n",
      "Asia - North America: ω=0.0685, FIC=0.315 → Questionable\n",
      "South America - Oceania: ω=0.0334, FIC=0.666 → Acceptable\n",
      "South America - EU: ω=0.0655, FIC=0.345 → Questionable\n",
      "South America - Arab/Middle East: ω=0.0522, FIC=0.478 → Questionable\n",
      "South America - North America: ω=0.0274, FIC=0.726 → Acceptable\n",
      "Oceania - EU: ω=0.0321, FIC=0.679 → Acceptable\n",
      "Oceania - Arab/Middle East: ω=0.0856, FIC=0.144 → Questionable\n",
      "Oceania - North America: ω=0.0061, FIC=0.939 → Optimum (omega_max < 0.0250)\n",
      "EU - Arab/Middle East: ω=0.1177, FIC=-0.177 → Unacceptable\n",
      "EU - North America: ω=0.0381, FIC=0.619 → Acceptable\n",
      "Arab/Middle East - North America: ω=0.0795, FIC=0.205 → Questionable\n",
      "\n",
      "For alphaF = 0.15:\n",
      "--------------------------------------------------\n",
      "Africa - Asia: ω=0.0534, FIC=0.644 → Acceptable\n",
      "Africa - South America: ω=0.0945, FIC=0.370 → Questionable\n",
      "Africa - Oceania: ω=0.1279, FIC=0.147 → Questionable\n",
      "Africa - EU: ω=0.1600, FIC=-0.067 → Unacceptable\n",
      "Africa - Arab/Middle East: ω=0.0423, FIC=0.718 → Acceptable\n",
      "Africa - North America: ω=0.1219, FIC=0.188 → Questionable\n",
      "Asia - South America: ω=0.0412, FIC=0.726 → Acceptable\n",
      "Asia - Oceania: ω=0.0746, FIC=0.503 → Acceptable\n",
      "Asia - EU: ω=0.1067, FIC=0.289 → Questionable\n",
      "Asia - Arab/Middle East: ω=0.0110, FIC=0.927 → Optimum (omega_max < 0.0375)\n",
      "Asia - North America: ω=0.0685, FIC=0.543 → Acceptable\n",
      "South America - Oceania: ω=0.0334, FIC=0.777 → Optimum (omega_max < 0.0375)\n",
      "South America - EU: ω=0.0655, FIC=0.563 → Acceptable\n",
      "South America - Arab/Middle East: ω=0.0522, FIC=0.652 → Acceptable\n",
      "South America - North America: ω=0.0274, FIC=0.818 → Optimum (omega_max < 0.0375)\n",
      "Oceania - EU: ω=0.0321, FIC=0.786 → Optimum (omega_max < 0.0375)\n",
      "Oceania - Arab/Middle East: ω=0.0856, FIC=0.429 → Questionable\n",
      "Oceania - North America: ω=0.0061, FIC=0.960 → Optimum (omega_max < 0.0375)\n",
      "EU - Arab/Middle East: ω=0.1177, FIC=0.216 → Questionable\n",
      "EU - North America: ω=0.0381, FIC=0.746 → Acceptable\n",
      "Arab/Middle East - North America: ω=0.0795, FIC=0.470 → Questionable\n",
      "\n",
      "For alphaF = 0.2:\n",
      "--------------------------------------------------\n",
      "Africa - Asia: ω=0.0534, FIC=0.733 → Acceptable\n",
      "Africa - South America: ω=0.0945, FIC=0.527 → Acceptable\n",
      "Africa - Oceania: ω=0.1279, FIC=0.360 → Questionable\n",
      "Africa - EU: ω=0.1600, FIC=0.200 → Questionable\n",
      "Africa - Arab/Middle East: ω=0.0423, FIC=0.788 → Optimum (omega_max < 0.0500)\n",
      "Africa - North America: ω=0.1219, FIC=0.391 → Questionable\n",
      "Asia - South America: ω=0.0412, FIC=0.794 → Optimum (omega_max < 0.0500)\n",
      "Asia - Oceania: ω=0.0746, FIC=0.627 → Acceptable\n",
      "Asia - EU: ω=0.1067, FIC=0.467 → Questionable\n",
      "Asia - Arab/Middle East: ω=0.0110, FIC=0.945 → Optimum (omega_max < 0.0500)\n",
      "Asia - North America: ω=0.0685, FIC=0.657 → Acceptable\n",
      "South America - Oceania: ω=0.0334, FIC=0.833 → Optimum (omega_max < 0.0500)\n",
      "South America - EU: ω=0.0655, FIC=0.673 → Acceptable\n",
      "South America - Arab/Middle East: ω=0.0522, FIC=0.739 → Acceptable\n",
      "South America - North America: ω=0.0274, FIC=0.863 → Optimum (omega_max < 0.0500)\n",
      "Oceania - EU: ω=0.0321, FIC=0.840 → Optimum (omega_max < 0.0500)\n",
      "Oceania - Arab/Middle East: ω=0.0856, FIC=0.572 → Acceptable\n",
      "Oceania - North America: ω=0.0061, FIC=0.970 → Optimum (omega_max < 0.0500)\n",
      "EU - Arab/Middle East: ω=0.1177, FIC=0.412 → Questionable\n",
      "EU - North America: ω=0.0381, FIC=0.809 → Optimum (omega_max < 0.0500)\n",
      "Arab/Middle East - North America: ω=0.0795, FIC=0.602 → Acceptable\n",
      "GENERATING VISUALIZATIONS...\n",
      "MODEL COMPARISON:\n",
      "   Model Overall Accuracy Avg FIC alphaF=0.10) ω_max (alphaF=0.10)\n",
      "BASELINE           0.7675                0.315              0.1600\n",
      "      L1           0.7671                0.306              0.1600\n",
      "      L2           0.7675                0.315              0.1600\n",
      "\n",
      "================================================================================\n",
      "SUMMARY REPORT\n",
      "================================================================================\n",
      "CASE 1 - HEALTHCARE KEY FINDINGS:\n",
      "------------------------------------------------------------\n",
      "alphaF=0.05: omega_max = 0.2133\n",
      "  Tier distribution: {'Optimum': 0, 'Acceptable': 0, 'Questionable': 0, 'Unacceptable': 3}\n",
      "alphaF=0.1: omega_max = 0.2133\n",
      "  Tier distribution: {'Optimum': 0, 'Acceptable': 0, 'Questionable': 1, 'Unacceptable': 2}\n",
      "alphaF=0.2: omega_max = 0.2133\n",
      "  Tier distribution: {'Optimum': 0, 'Acceptable': 1, 'Questionable': 1, 'Unacceptable': 1}\n",
      "CASE 2 - CRIMINAL JUSTICE KEY FINDINGS:\n",
      "------------------------------------------------------------\n",
      "alphaF=0.05: omega_max = 0.1600 (Africa - EU)\n",
      "alphaF=0.1: omega_max = 0.1600 (Africa - EU)\n",
      "alphaF=0.2: omega_max = 0.1600 (Africa - EU)\n",
      "\n",
      "================================================================================\n",
      "ANALYSIS COMPLETE - HIGH-QUALITY PLOTS SAVED\n",
      "================================================================================\n",
      "All done\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create output directory\n",
    "output_dir = \"fic_results\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Set style for publication quality\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Global font settings for consistency\n",
    "plt.rcParams.update({\n",
    "    'font.size': 12,\n",
    "    'axes.titlesize': 16,\n",
    "    'axes.labelsize': 14,\n",
    "    'xtick.labelsize': 12,\n",
    "    'ytick.labelsize': 12,\n",
    "    'legend.fontsize': 12,\n",
    "})\n",
    "\n",
    "# ============================================\n",
    "# 1. DATA SIMULATION (unchanged)\n",
    "# ============================================\n",
    "\n",
    "def generate_healthcare_data(n=5000):\n",
    "    np.random.seed(42)\n",
    "    gender = np.random.choice(['Male', 'Female', 'Non-binary'], size=n, p=[0.455, 0.449, 0.096])\n",
    "    age = np.clip(np.random.normal(loc=45, scale=15, size=n), 18, 85)\n",
    "    income = np.clip(np.random.lognormal(mean=10.5, sigma=0.8, size=n), 20000, 200000)\n",
    "    marital_status = np.random.choice(['Single', 'Married', 'Divorced', 'Widowed'], size=n, p=[0.3, 0.4, 0.2, 0.1])\n",
    "    immigration_status = np.random.choice(['Citizen', 'Immigrant', 'Refugee'], size=n, p=[0.7, 0.25, 0.05])\n",
    "    education = np.random.choice(['High School', 'College', 'Bachelor', 'Master', 'PhD'], size=n, p=[0.2, 0.3, 0.3, 0.15, 0.05])\n",
    "    job_status = np.random.choice(['Employed', 'Unemployed', 'Student', 'Retired'], size=n, p=[0.6, 0.15, 0.15, 0.1])\n",
    "\n",
    "    depression_prob = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        base = 0.15 if gender[i] == 'Male' else 0.20 if gender[i] == 'Female' else 0.35\n",
    "        prob = base\n",
    "        if job_status[i] == 'Unemployed': prob += 0.20\n",
    "        if income[i] < 30000: prob += 0.15\n",
    "        if age[i] < 25 or age[i] > 65: prob += 0.10\n",
    "        depression_prob[i] = np.clip(prob, 0, 0.95)\n",
    "    depression = np.random.binomial(1, depression_prob)\n",
    "\n",
    "    data = pd.DataFrame({\n",
    "        'age': age, 'income': income, 'marital_status': marital_status,\n",
    "        'immigration_status': immigration_status, 'education': education,\n",
    "        'job_status': job_status, 'gender': gender, 'depression': depression\n",
    "    })\n",
    "    return data\n",
    "\n",
    "def generate_criminal_justice_data(n=8000):\n",
    "    np.random.seed(42)\n",
    "    regions = ['Africa', 'EU', 'South America', 'North America', 'Arab/Middle East', 'Asia', 'Oceania']\n",
    "    region_weights = [0.20, 0.25, 0.15, 0.10, 0.10, 0.15, 0.05]\n",
    "    region = np.random.choice(regions, size=n, p=region_weights)\n",
    "    gender = np.random.choice(['Male', 'Female'], size=n, p=[0.7, 0.3])\n",
    "    age = np.clip(np.random.normal(loc=35, scale=12, size=n), 18, 70)\n",
    "    income = np.clip(np.random.lognormal(mean=10.0, sigma=0.9, size=n), 15000, 150000)\n",
    "    prior_convictions = np.clip(np.random.poisson(lam=1.5, size=n), 0, 10)\n",
    "    education = np.random.choice(['Less than HS', 'High School', 'Some College', 'College', 'Graduate'], size=n, p=[0.1, 0.3, 0.25, 0.25, 0.1])\n",
    "    employment = np.random.choice(['Employed', 'Unemployed', 'Student', 'Other'], size=n, p=[0.5, 0.25, 0.15, 0.1])\n",
    "    asylum_seeker = np.random.choice([0, 1], size=n, p=[0.85, 0.15])\n",
    "\n",
    "    high_risk_prob = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        base_rates = {'Africa': 0.25, 'EU': 0.10, 'South America': 0.20, 'North America': 0.15,\n",
    "                      'Arab/Middle East': 0.22, 'Asia': 0.18, 'Oceania': 0.12}\n",
    "        base = base_rates[region[i]]\n",
    "        prob = base\n",
    "        if asylum_seeker[i] == 1: prob += 0.15\n",
    "        if employment[i] == 'Unemployed': prob += 0.12\n",
    "        high_risk_prob[i] = np.clip(prob, 0, 0.95)\n",
    "    high_risk = np.random.binomial(1, high_risk_prob)\n",
    "\n",
    "    data = pd.DataFrame({\n",
    "        'gender': gender, 'age': age, 'income': income, 'prior_convictions': prior_convictions,\n",
    "        'education': education, 'employment': employment, 'asylum_seeker': asylum_seeker,\n",
    "        'region': region, 'high_risk': high_risk\n",
    "    })\n",
    "    return data\n",
    "\n",
    "# ============================================\n",
    "# 2-3. MODEL & FIC (unchanged for logic)\n",
    "# ============================================\n",
    "\n",
    "def compute_all_metrics(y_true, y_pred, y_prob):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_true, y_pred),\n",
    "        'selection_rate': (tp + fp) / len(y_true),\n",
    "        'tpr': tp / (tp + fn) if (tp + fn) > 0 else 0,\n",
    "        'tnr': tn / (tn + fp) if (tn + fp) > 0 else 0,\n",
    "        'fpr': fp / (fp + tn) if (fp + tn) > 0 else 0,\n",
    "        'fnr': fn / (tp + fn) if (tp + fn) > 0 else 0,\n",
    "        'ppv': tp / (tp + fp) if (tp + fp) > 0 else 0,\n",
    "        'npv': tn / (tn + fn) if (tn + fn) > 0 else 0,\n",
    "        'f1': f1_score(y_true, y_pred),\n",
    "        'auc': roc_auc_score(y_true, y_prob) if len(np.unique(y_true)) > 1 else np.nan\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "def train_and_evaluate_models(data, target_col, protected_col, model_type='baseline'):\n",
    "    X = data.drop(columns=[target_col, protected_col])\n",
    "    y = data[target_col]\n",
    "    categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "    numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(drop='first'), categorical_cols)\n",
    "    ])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "    protected_test = data.loc[X_test.index, protected_col]\n",
    "\n",
    "    X_train_processed = preprocessor.fit_transform(X_train)\n",
    "    X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "    if model_type == 'baseline':\n",
    "        model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "    elif model_type == 'l1':\n",
    "        model = LogisticRegression(penalty='l1', solver='liblinear', random_state=42, max_iter=1000, C=1.0)\n",
    "    elif model_type == 'l2':\n",
    "        model = LogisticRegression(penalty='l2', random_state=42, max_iter=1000, C=1.0)\n",
    "    else:\n",
    "        model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "    model.fit(X_train_processed, y_train)\n",
    "    y_pred = model.predict(X_test_processed)\n",
    "    y_prob = model.predict_proba(X_test_processed)[:, 1]\n",
    "\n",
    "    group_metrics = {}\n",
    "    for group in protected_test.unique():\n",
    "        mask = protected_test == group\n",
    "        if mask.sum() > 0:\n",
    "            group_metrics[group] = compute_all_metrics(y_test[mask], y_pred[mask], y_prob[mask])\n",
    "\n",
    "    return group_metrics, (X_test, y_test, protected_test, y_pred, y_prob)\n",
    "\n",
    "class FairnessInformationCriterion:\n",
    "    def __init__(self, alphaF_values=[0.05, 0.10, 0.15, 0.20]):\n",
    "        self.alphaF_values = alphaF_values\n",
    "\n",
    "    def compute_omega(self, metric1, metric2):\n",
    "        return abs(metric1 - metric2)\n",
    "\n",
    "    def compute_fic(self, omega, alphaF):\n",
    "        return 1 - (omega / alphaF)\n",
    "\n",
    "    def classify_tier(self, fic_score):\n",
    "        if fic_score > 0.75:\n",
    "            return \"Optimum\"\n",
    "        elif fic_score > 0.50:\n",
    "            return \"Acceptable\"\n",
    "        elif fic_score > 0:\n",
    "            return \"Questionable\"\n",
    "        else:\n",
    "            return \"Unacceptable\"\n",
    "\n",
    "    def analyze_fairness(self, group_metrics, metric_name='accuracy'):\n",
    "        results = {}\n",
    "        groups = list(group_metrics.keys())\n",
    "        for alphaF in self.alphaF_values:\n",
    "            results[alphaF] = {}\n",
    "            for i, g1 in enumerate(groups):\n",
    "                for g2 in groups[i+1:]:\n",
    "                    pair = f\"{g1} - {g2}\"\n",
    "                    m1 = group_metrics[g1].get(metric_name, np.nan)\n",
    "                    m2 = group_metrics[g2].get(metric_name, np.nan)\n",
    "                    if not np.isnan(m1) and not np.isnan(m2):\n",
    "                        omega = self.compute_omega(m1, m2)\n",
    "                        fic_score = self.compute_fic(omega, alphaF)\n",
    "                        tier = self.classify_tier(fic_score)\n",
    "                        results[alphaF][pair] = {\n",
    "                            'omega': omega, 'fic_score': fic_score, 'tier': tier,\n",
    "                            'metric1': m1, 'metric2': m2\n",
    "                        }\n",
    "        return results\n",
    "\n",
    "# ============================================\n",
    "# 4. IMPROVED VISUALIZATIONS\n",
    "# ============================================\n",
    "\n",
    "def plot_fic_heatmaps(fic_results, dataset_name, metric='accuracy'):\n",
    "    alphaF_values = sorted(fic_results.keys())\n",
    "    if not alphaF_values:\n",
    "        return\n",
    "\n",
    "    pairs = list(fic_results[alphaF_values[0]].keys())\n",
    "    all_groups = sorted(set(g for p in pairs for g in p.split(' - ')))\n",
    "\n",
    "    # Larger figure\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(20, 16))\n",
    "    fig.suptitle(f'{dataset_name}: FIC Heatmaps for Different alphaF Values ({metric})',\n",
    "                 fontsize=20, fontweight='bold', y=0.98)\n",
    "\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for idx, alphaF in enumerate(alphaF_values):\n",
    "        ax = axes[idx]\n",
    "        n = len(all_groups)\n",
    "        mat = np.full((n, n), np.nan)\n",
    "        group_idx = {g: i for i, g in enumerate(all_groups)}\n",
    "\n",
    "        for pair, d in fic_results[alphaF].items():\n",
    "            g1, g2 = pair.split(' - ')\n",
    "            i, j = group_idx[g1], group_idx[g2]\n",
    "            mat[i, j] = mat[j, i] = d['fic_score']\n",
    "\n",
    "        im = ax.imshow(mat, cmap='RdYlGn', vmin=-1, vmax=1, aspect='equal')\n",
    "\n",
    "        # Colorbar\n",
    "        cbar = fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "        cbar.set_label('FIC Score', fontsize=14, fontweight='bold')\n",
    "        cbar.ax.tick_params(labelsize=12)\n",
    "\n",
    "        # Bold text inside cells\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                if i != j and not np.isnan(mat[i, j]):\n",
    "                    text = ax.text(j, i, f'{mat[i,j]:.3f}',\n",
    "                                   ha='center', va='center',\n",
    "                                   fontsize=14, fontweight='bold',\n",
    "                                   color='white' if abs(mat[i,j]) > 0.5 else 'black')\n",
    "\n",
    "        ax.set_xticks(range(n))\n",
    "        ax.set_yticks(range(n))\n",
    "        ax.set_xticklabels(all_groups, rotation=45, ha='right', fontsize=13, fontweight='bold')\n",
    "        ax.set_yticklabels(all_groups, fontsize=13, fontweight='bold')\n",
    "        ax.set_title(f'alphaF = {alphaF}', fontsize=18, fontweight='bold', pad=20)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.savefig(os.path.join(output_dir, f'{dataset_name}_FIC_Heatmaps_{metric}.png'), dpi=400, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def plot_benchmarking_tiers(fic_results, dataset_name, metric='accuracy'):\n",
    "    # Sort alphaF values to ensure consistent order\n",
    "    alphaF_values = sorted(fic_results.keys())\n",
    "    \n",
    "    # Define colors for tiers\n",
    "    colors = {'Optimum': '#2E8B57', 'Acceptable': '#FFD700', \n",
    "              'Questionable': '#FF8C00', 'Unacceptable': '#DC143C'}\n",
    "    \n",
    "    for alphaF in alphaF_values:\n",
    "        if alphaF not in fic_results or not fic_results[alphaF]:\n",
    "            print(f\"No data for alphaF={alphaF} in benchmarking tiers\")\n",
    "            continue\n",
    "        \n",
    "        # Create a separate figure for each alphaF value\n",
    "        fig, ax = plt.subplots(figsize=(18, 10))\n",
    "        \n",
    "        data = fic_results[alphaF]\n",
    "        pairs = list(data.keys())\n",
    "        fic_scores = [data[p]['fic_score'] for p in pairs]\n",
    "        tiers = [data[p]['tier'] for p in pairs]\n",
    "        \n",
    "        # Create bar colors based on tiers\n",
    "        bar_colors = [colors[t] for t in tiers]\n",
    "        \n",
    "        # Create bars\n",
    "        bars = ax.bar(range(len(pairs)), fic_scores, color=bar_colors, \n",
    "                      edgecolor='black', linewidth=1.5, width=0.7)\n",
    "        \n",
    "        # Add tier threshold lines\n",
    "        ax.axhline(0.75, color='darkgreen', linestyle='--', linewidth=2.5, \n",
    "                   label='Optimum (>0.75)')\n",
    "        ax.axhline(0.50, color='goldenrod', linestyle='--', linewidth=2.5, \n",
    "                   label='Acceptable (>0.50)')\n",
    "        ax.axhline(0.00, color='darkred', linestyle='--', linewidth=2.5, \n",
    "                   label='Unacceptable (≤0.00)')\n",
    "        \n",
    "        # Add value and tier labels on bars\n",
    "        for bar, score, tier in zip(bars, fic_scores, tiers):\n",
    "            height = bar.get_height()\n",
    "            # Position text based on bar height\n",
    "            if height >= 0:\n",
    "                ax.text(bar.get_x() + bar.get_width()/2, height + 0.02,\n",
    "                        f'{score:.3f}\\n({tier})',\n",
    "                        ha='center', va='bottom',\n",
    "                        fontsize=11, fontweight='bold', color='black')\n",
    "            else:\n",
    "                ax.text(bar.get_x() + bar.get_width()/2, height - 0.05,\n",
    "                        f'{score:.3f}\\n({tier})',\n",
    "                        ha='center', va='top',\n",
    "                        fontsize=11, fontweight='bold', color='black')\n",
    "        \n",
    "        # Customize axes\n",
    "        ax.set_xlabel('Group Pairs', fontsize=16, fontweight='bold', labelpad=15)\n",
    "        ax.set_ylabel('FIC Score', fontsize=16, fontweight='bold', labelpad=15)\n",
    "        ax.set_title(f'{dataset_name}: FIC Benchmarking Tiers ({metric}, alphaF={alphaF})',\n",
    "                    fontsize=20, fontweight='bold', pad=20)\n",
    "        \n",
    "        # Set x-ticks with rotation for readability\n",
    "        ax.set_xticks(range(len(pairs)))\n",
    "        ax.set_xticklabels(pairs, rotation=45, ha='right', fontsize=13, fontweight='bold')\n",
    "        \n",
    "        # Set consistent y-axis limits\n",
    "        ax.set_ylim(-0.3, 1.15)\n",
    "        \n",
    "        # Add grid\n",
    "        ax.grid(True, axis='y', alpha=0.4, linestyle='--')\n",
    "        \n",
    "        # Add legend\n",
    "        ax.legend(fontsize=14, loc='upper left')\n",
    "        \n",
    "        # Adjust layout\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save the figure with alphaF in the filename\n",
    "        plt.savefig(os.path.join(output_dir, f'{dataset_name}_Benchmarking_Tiers_alphaF_{alphaF}_{metric}.png'), \n",
    "                    dpi=400, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "# ============================================\n",
    "# 5-7. REST OF CODE (analyze_dataset, run_complete_analysis, etc.)\n",
    "# ============================================\n",
    "\n",
    "def analyze_dataset(dataset_name, data_generator, target_col, protected_col, case_number=1, model_types=['baseline', 'l1', 'l2']):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"CASE {case_number}: {dataset_name}\")\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "    data = data_generator()\n",
    "    fic_framework = FairnessInformationCriterion()\n",
    "\n",
    "    baseline_metrics, _ = train_and_evaluate_models(data, target_col, protected_col, 'baseline')\n",
    "\n",
    "    metrics_df = pd.DataFrame.from_dict(baseline_metrics, orient='index')\n",
    "    metrics_df = metrics_df[['accuracy', 'selection_rate', 'tpr', 'tnr', 'fpr', 'fnr', 'ppv', 'npv', 'f1', 'auc']]\n",
    "    print(\"GROUP METRICS TABLE (Baseline Logistic Regression):\")\n",
    "    print(metrics_df.round(4).to_string())\n",
    "    metrics_df.to_csv(os.path.join(output_dir, f'Case{case_number}_Group_Metrics.csv'))\n",
    "\n",
    "    fic_results = fic_framework.analyze_fairness(baseline_metrics, 'accuracy')\n",
    "\n",
    "    # FIC table\n",
    "    fic_table = []\n",
    "    for pair in sorted(set(p for a in fic_results.values() for p in a.keys())):\n",
    "        row = {'Group Pair': pair}\n",
    "        for af in fic_framework.alphaF_values:\n",
    "            if af in fic_results and pair in fic_results[af]:\n",
    "                d = fic_results[af][pair]\n",
    "                row[f'alphaF={af}'] = f\"omega={d['omega']:.4f}, FIC={d['fic_score']:.3f}\"\n",
    "                row[f'Hypothesis alphaF={af}'] = \"Fail to reject Ho (Fair)\" if d['omega'] <= af else \"Reject H₀ (Unfair)\"\n",
    "            else:\n",
    "                row[f'alphaF={af}'] = \"N/A\"; row[f'Hypothesis alphaF={af}'] = \"N/A\"\n",
    "        fic_table.append(row)\n",
    "    fic_df = pd.DataFrame(fic_table)\n",
    "    print(\"FIC ANALYSIS TABLE:\")\n",
    "    print(fic_df.to_string(index=False))\n",
    "    fic_df.to_csv(os.path.join(output_dir, f'Case{case_number}_FIC_Analysis.csv'), index=False)\n",
    "\n",
    "    # Tier classification\n",
    "    tier_data = []\n",
    "    print(\"TIER CLASSIFICATION:\")\n",
    "    for af in fic_framework.alphaF_values:\n",
    "        print(f\"\\nFor alphaF = {af}:\")\n",
    "        print(\"-\" * 50)\n",
    "        if af in fic_results:\n",
    "            for pair, d in fic_results[af].items():\n",
    "                tier = fic_framework.classify_tier(d['fic_score'])\n",
    "                msg = tier if d['fic_score'] <= 0.75 else f\"{tier} (omega_max < {0.25*af:.4f})\"\n",
    "                print(f\"{pair}: ω={d['omega']:.4f}, FIC={d['fic_score']:.3f} → {msg}\")\n",
    "                tier_data.append({'alphaF': af, 'Group Pair': pair, 'ω': d['omega'], 'FIC': d['fic_score'], 'Tier': tier})\n",
    "    tier_df = pd.DataFrame(tier_data)\n",
    "    tier_df.to_csv(os.path.join(output_dir, f'Case{case_number}_Tier_Classification.csv'), index=False)\n",
    "\n",
    "    print(\"GENERATING VISUALIZATIONS...\")\n",
    "    plot_fic_heatmaps(fic_results, f'Case{case_number}_{dataset_name}')\n",
    "    plot_benchmarking_tiers(fic_results, f'Case{case_number}_{dataset_name}')\n",
    "\n",
    "    # Model comparison\n",
    "    print(\"MODEL COMPARISON:\")\n",
    "    comparison = []\n",
    "    for mt in model_types:\n",
    "        mets, test_data = train_and_evaluate_models(data, target_col, protected_col, mt)\n",
    "        model_fic = fic_framework.analyze_fairness(mets, 'accuracy')\n",
    "        avg_fic = np.mean([d['fic_score'] for d in model_fic[0.10].values()]) if 0.10 in model_fic and model_fic[0.10] else np.nan\n",
    "        max_omega = max([d['omega'] for d in model_fic[0.10].values()]) if 0.10 in model_fic and model_fic[0.10] else np.nan\n",
    "        _, y_test, _, y_pred, _ = test_data\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        comparison.append({\n",
    "            'Model': mt.upper(),\n",
    "            'Overall Accuracy': f\"{acc:.4f}\",\n",
    "            'Avg FIC alphaF=0.10)': f\"{avg_fic:.3f}\" if not np.isnan(avg_fic) else \"N/A\",\n",
    "            'ω_max (alphaF=0.10)': f\"{max_omega:.4f}\" if not np.isnan(max_omega) else \"N/A\"\n",
    "        })\n",
    "    comparison_df = pd.DataFrame(comparison)\n",
    "    print(comparison_df.to_string(index=False))\n",
    "    comparison_df.to_csv(os.path.join(output_dir, f'Case{case_number}_Model_Comparison.csv'), index=False)\n",
    "\n",
    "    return {\n",
    "        'data': data,\n",
    "        'baseline_metrics': baseline_metrics,\n",
    "        'fic_results': fic_results,\n",
    "        'metrics_df': metrics_df,\n",
    "        'fic_df': fic_df,\n",
    "        'tier_df': tier_df,\n",
    "        'comparison_df': comparison_df\n",
    "    }\n",
    "\n",
    "def run_complete_analysis():\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"FAIRNESS INFORMATION CRITERION (FIC) ANALYSIS\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    healthcare_results = analyze_dataset(\n",
    "        dataset_name=\"Healthcare - Depression Diagnosis\",\n",
    "        data_generator=lambda: generate_healthcare_data(5000),\n",
    "        target_col='depression',\n",
    "        protected_col='gender',\n",
    "        case_number=1\n",
    "    )\n",
    "\n",
    "    criminal_results = analyze_dataset(\n",
    "        dataset_name=\"Criminal Justice - Recidivism Risk\",\n",
    "        data_generator=lambda: generate_criminal_justice_data(8000),\n",
    "        target_col='high_risk',\n",
    "        protected_col='region',\n",
    "        case_number=2\n",
    "    )\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"SUMMARY REPORT\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    print(\"CASE 1 - HEALTHCARE KEY FINDINGS:\")\n",
    "    print(\"-\" * 60)\n",
    "    for af in [0.05, 0.10, 0.20]:\n",
    "        if af in healthcare_results['fic_results'] and healthcare_results['fic_results'][af]:\n",
    "            omegas = [d['omega'] for d in healthcare_results['fic_results'][af].values()]\n",
    "            max_o = max(omegas)\n",
    "            tiers = {'Optimum': 0, 'Acceptable': 0, 'Questionable': 0, 'Unacceptable': 0}\n",
    "            fic = FairnessInformationCriterion()\n",
    "            for d in healthcare_results['fic_results'][af].values():\n",
    "                tiers[fic.classify_tier(d['fic_score'])] += 1\n",
    "            print(f\"alphaF={af}: omega_max = {max_o:.4f}\")\n",
    "            print(f\"  Tier distribution: {tiers}\")\n",
    "\n",
    "    print(\"CASE 2 - CRIMINAL JUSTICE KEY FINDINGS:\")\n",
    "    print(\"-\" * 60)\n",
    "    for af in [0.05, 0.10, 0.20]:\n",
    "        if af in criminal_results['fic_results'] and criminal_results['fic_results'][af]:\n",
    "            items = list(criminal_results['fic_results'][af].items())\n",
    "            max_o = max(d['omega'] for _, d in items)\n",
    "            worst_pair = max(items, key=lambda x: x[1]['omega'])[0]\n",
    "            print(f\"alphaF={af}: omega_max = {max_o:.4f} ({worst_pair})\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ANALYSIS COMPLETE - HIGH-QUALITY PLOTS SAVED\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    return healthcare_results, criminal_results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    healthcare_results, criminal_results = run_complete_analysis()\n",
    "\n",
    "    print(\"All done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8937443",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13419d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#..................With all PLots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f2bb9ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FAIRNESS INFORMATION CRITERION (FIC) ANALYSIS - SIMULATED DATASETS\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "CASE 1: Healthcare - Depression Diagnosis\n",
      "================================================================================\n",
      "Generated healthcare data: 5000 samples\n",
      "Depression prevalence: 0.300\n",
      "Gender distribution:\n",
      "gender\n",
      "Male          0.461\n",
      "Female        0.447\n",
      "Non-binary    0.093\n",
      "Name: proportion, dtype: float64\n",
      "GROUP METRICS TABLE (Baseline Logistic Regression):\n",
      "            accuracy  selection_rate     tpr     tnr     fpr     fnr     ppv     npv      f1     auc\n",
      "Male          0.7470          0.0281  0.0581  0.9821  0.0179  0.9419  0.5263  0.7534  0.1047  0.6563\n",
      "Female        0.6834          0.0148  0.0143  0.9850  0.0150  0.9857  0.3000  0.6892  0.0273  0.6029\n",
      "Non-binary    0.5338          0.0338  0.0294  0.9625  0.0375  0.9706  0.4000  0.5385  0.0548  0.6287\n",
      "\n",
      "GENERATING VISUALIZATIONS FOR ALL METRICS...\n",
      "\n",
      "============================================================\n",
      "ANALYZING METRIC: ACCURACY\n",
      "============================================================\n",
      "Summary for accuracy:\n",
      "  αF=0.05: ω_max=0.2133, ω_avg=0.1422, Tiers={'Optimum': 0, 'Acceptable': 0, 'Questionable': 0, 'Unacceptable': 3}\n",
      "  αF=0.1: ω_max=0.2133, ω_avg=0.1422, Tiers={'Optimum': 0, 'Acceptable': 0, 'Questionable': 1, 'Unacceptable': 2}\n",
      "  αF=0.15: ω_max=0.2133, ω_avg=0.1422, Tiers={'Optimum': 0, 'Acceptable': 1, 'Questionable': 1, 'Unacceptable': 1}\n",
      "  αF=0.2: ω_max=0.2133, ω_avg=0.1422, Tiers={'Optimum': 0, 'Acceptable': 1, 'Questionable': 1, 'Unacceptable': 1}\n",
      "\n",
      "============================================================\n",
      "ANALYZING METRIC: SELECTION_RATE\n",
      "============================================================\n",
      "Summary for selection_rate:\n",
      "  αF=0.05: ω_max=0.0190, ω_avg=0.0127, Tiers={'Optimum': 1, 'Acceptable': 2, 'Questionable': 0, 'Unacceptable': 0}\n",
      "  αF=0.1: ω_max=0.0190, ω_avg=0.0127, Tiers={'Optimum': 3, 'Acceptable': 0, 'Questionable': 0, 'Unacceptable': 0}\n",
      "  αF=0.15: ω_max=0.0190, ω_avg=0.0127, Tiers={'Optimum': 3, 'Acceptable': 0, 'Questionable': 0, 'Unacceptable': 0}\n",
      "  αF=0.2: ω_max=0.0190, ω_avg=0.0127, Tiers={'Optimum': 3, 'Acceptable': 0, 'Questionable': 0, 'Unacceptable': 0}\n",
      "\n",
      "============================================================\n",
      "ANALYZING METRIC: TPR\n",
      "============================================================\n",
      "Summary for tpr:\n",
      "  αF=0.05: ω_max=0.0439, ω_avg=0.0292, Tiers={'Optimum': 0, 'Acceptable': 1, 'Questionable': 2, 'Unacceptable': 0}\n",
      "  αF=0.1: ω_max=0.0439, ω_avg=0.0292, Tiers={'Optimum': 1, 'Acceptable': 2, 'Questionable': 0, 'Unacceptable': 0}\n",
      "  αF=0.15: ω_max=0.0439, ω_avg=0.0292, Tiers={'Optimum': 2, 'Acceptable': 1, 'Questionable': 0, 'Unacceptable': 0}\n",
      "  αF=0.2: ω_max=0.0439, ω_avg=0.0292, Tiers={'Optimum': 3, 'Acceptable': 0, 'Questionable': 0, 'Unacceptable': 0}\n",
      "\n",
      "============================================================\n",
      "ANALYZING METRIC: TNR\n",
      "============================================================\n",
      "Summary for tnr:\n",
      "  αF=0.05: ω_max=0.0225, ω_avg=0.0150, Tiers={'Optimum': 1, 'Acceptable': 2, 'Questionable': 0, 'Unacceptable': 0}\n",
      "  αF=0.1: ω_max=0.0225, ω_avg=0.0150, Tiers={'Optimum': 3, 'Acceptable': 0, 'Questionable': 0, 'Unacceptable': 0}\n",
      "  αF=0.15: ω_max=0.0225, ω_avg=0.0150, Tiers={'Optimum': 3, 'Acceptable': 0, 'Questionable': 0, 'Unacceptable': 0}\n",
      "  αF=0.2: ω_max=0.0225, ω_avg=0.0150, Tiers={'Optimum': 3, 'Acceptable': 0, 'Questionable': 0, 'Unacceptable': 0}\n",
      "\n",
      "============================================================\n",
      "ANALYZING METRIC: FPR\n",
      "============================================================\n",
      "Summary for fpr:\n",
      "  αF=0.05: ω_max=0.0225, ω_avg=0.0150, Tiers={'Optimum': 1, 'Acceptable': 2, 'Questionable': 0, 'Unacceptable': 0}\n",
      "  αF=0.1: ω_max=0.0225, ω_avg=0.0150, Tiers={'Optimum': 3, 'Acceptable': 0, 'Questionable': 0, 'Unacceptable': 0}\n",
      "  αF=0.15: ω_max=0.0225, ω_avg=0.0150, Tiers={'Optimum': 3, 'Acceptable': 0, 'Questionable': 0, 'Unacceptable': 0}\n",
      "  αF=0.2: ω_max=0.0225, ω_avg=0.0150, Tiers={'Optimum': 3, 'Acceptable': 0, 'Questionable': 0, 'Unacceptable': 0}\n",
      "\n",
      "============================================================\n",
      "ANALYZING METRIC: FNR\n",
      "============================================================\n",
      "Summary for fnr:\n",
      "  αF=0.05: ω_max=0.0439, ω_avg=0.0292, Tiers={'Optimum': 0, 'Acceptable': 1, 'Questionable': 2, 'Unacceptable': 0}\n",
      "  αF=0.1: ω_max=0.0439, ω_avg=0.0292, Tiers={'Optimum': 1, 'Acceptable': 2, 'Questionable': 0, 'Unacceptable': 0}\n",
      "  αF=0.15: ω_max=0.0439, ω_avg=0.0292, Tiers={'Optimum': 2, 'Acceptable': 1, 'Questionable': 0, 'Unacceptable': 0}\n",
      "  αF=0.2: ω_max=0.0439, ω_avg=0.0292, Tiers={'Optimum': 3, 'Acceptable': 0, 'Questionable': 0, 'Unacceptable': 0}\n",
      "\n",
      "============================================================\n",
      "ANALYZING METRIC: PPV\n",
      "============================================================\n",
      "Summary for ppv:\n",
      "  αF=0.05: ω_max=0.2263, ω_avg=0.1509, Tiers={'Optimum': 0, 'Acceptable': 0, 'Questionable': 0, 'Unacceptable': 3}\n",
      "  αF=0.1: ω_max=0.2263, ω_avg=0.1509, Tiers={'Optimum': 0, 'Acceptable': 0, 'Questionable': 0, 'Unacceptable': 3}\n",
      "  αF=0.15: ω_max=0.2263, ω_avg=0.1509, Tiers={'Optimum': 0, 'Acceptable': 0, 'Questionable': 2, 'Unacceptable': 1}\n",
      "  αF=0.2: ω_max=0.2263, ω_avg=0.1509, Tiers={'Optimum': 0, 'Acceptable': 0, 'Questionable': 2, 'Unacceptable': 1}\n",
      "\n",
      "============================================================\n",
      "ANALYZING METRIC: NPV\n",
      "============================================================\n",
      "Summary for npv:\n",
      "  αF=0.05: ω_max=0.2150, ω_avg=0.1433, Tiers={'Optimum': 0, 'Acceptable': 0, 'Questionable': 0, 'Unacceptable': 3}\n",
      "  αF=0.1: ω_max=0.2150, ω_avg=0.1433, Tiers={'Optimum': 0, 'Acceptable': 0, 'Questionable': 1, 'Unacceptable': 2}\n",
      "  αF=0.15: ω_max=0.2150, ω_avg=0.1433, Tiers={'Optimum': 0, 'Acceptable': 1, 'Questionable': 0, 'Unacceptable': 2}\n",
      "  αF=0.2: ω_max=0.2150, ω_avg=0.1433, Tiers={'Optimum': 0, 'Acceptable': 1, 'Questionable': 1, 'Unacceptable': 1}\n",
      "\n",
      "============================================================\n",
      "ANALYZING METRIC: F1\n",
      "============================================================\n",
      "Summary for f1:\n",
      "  αF=0.05: ω_max=0.0774, ω_avg=0.0516, Tiers={'Optimum': 0, 'Acceptable': 0, 'Questionable': 2, 'Unacceptable': 1}\n",
      "  αF=0.1: ω_max=0.0774, ω_avg=0.0516, Tiers={'Optimum': 0, 'Acceptable': 2, 'Questionable': 1, 'Unacceptable': 0}\n",
      "  αF=0.15: ω_max=0.0774, ω_avg=0.0516, Tiers={'Optimum': 1, 'Acceptable': 1, 'Questionable': 1, 'Unacceptable': 0}\n",
      "  αF=0.2: ω_max=0.0774, ω_avg=0.0516, Tiers={'Optimum': 2, 'Acceptable': 1, 'Questionable': 0, 'Unacceptable': 0}\n",
      "\n",
      "============================================================\n",
      "ANALYZING METRIC: AUC\n",
      "============================================================\n",
      "Summary for auc:\n",
      "  αF=0.05: ω_max=0.0534, ω_avg=0.0356, Tiers={'Optimum': 0, 'Acceptable': 0, 'Questionable': 2, 'Unacceptable': 1}\n",
      "  αF=0.1: ω_max=0.0534, ω_avg=0.0356, Tiers={'Optimum': 0, 'Acceptable': 2, 'Questionable': 1, 'Unacceptable': 0}\n",
      "  αF=0.15: ω_max=0.0534, ω_avg=0.0356, Tiers={'Optimum': 2, 'Acceptable': 1, 'Questionable': 0, 'Unacceptable': 0}\n",
      "  αF=0.2: ω_max=0.0534, ω_avg=0.0356, Tiers={'Optimum': 2, 'Acceptable': 1, 'Questionable': 0, 'Unacceptable': 0}\n",
      "\n",
      "FIC ANALYSIS TABLE (Accuracy):\n",
      "         Group Pair              alphaF=0.05 Hypothesis alphaF=0.05               alphaF=0.1    Hypothesis alphaF=0.1              alphaF=0.15   Hypothesis alphaF=0.15               alphaF=0.2    Hypothesis alphaF=0.2\n",
      "Female - Non-binary omega=0.1496, FIC=-1.993     Reject H₀ (Unfair) omega=0.1496, FIC=-0.496       Reject H₀ (Unfair)  omega=0.1496, FIC=0.002 Fail to reject H₀ (Fair)  omega=0.1496, FIC=0.252 Fail to reject H₀ (Fair)\n",
      "      Male - Female omega=0.0636, FIC=-0.272     Reject H₀ (Unfair)  omega=0.0636, FIC=0.364 Fail to reject H₀ (Fair)  omega=0.0636, FIC=0.576 Fail to reject H₀ (Fair)  omega=0.0636, FIC=0.682 Fail to reject H₀ (Fair)\n",
      "  Male - Non-binary omega=0.2133, FIC=-3.265     Reject H₀ (Unfair) omega=0.2133, FIC=-1.133       Reject H₀ (Unfair) omega=0.2133, FIC=-0.422       Reject H₀ (Unfair) omega=0.2133, FIC=-0.066       Reject H₀ (Unfair)\n",
      "\n",
      "TIER CLASSIFICATION (Accuracy):\n",
      "\n",
      "For αF = 0.05:\n",
      "--------------------------------------------------\n",
      "Male - Female: ω=0.0636, FIC=-0.272 → Unacceptable\n",
      "Male - Non-binary: ω=0.2133, FIC=-3.265 → Unacceptable\n",
      "Female - Non-binary: ω=0.1496, FIC=-1.993 → Unacceptable\n",
      "\n",
      "For αF = 0.1:\n",
      "--------------------------------------------------\n",
      "Male - Female: ω=0.0636, FIC=0.364 → Questionable\n",
      "Male - Non-binary: ω=0.2133, FIC=-1.133 → Unacceptable\n",
      "Female - Non-binary: ω=0.1496, FIC=-0.496 → Unacceptable\n",
      "\n",
      "For αF = 0.15:\n",
      "--------------------------------------------------\n",
      "Male - Female: ω=0.0636, FIC=0.576 → Acceptable\n",
      "Male - Non-binary: ω=0.2133, FIC=-0.422 → Unacceptable\n",
      "Female - Non-binary: ω=0.1496, FIC=0.002 → Questionable\n",
      "\n",
      "For αF = 0.2:\n",
      "--------------------------------------------------\n",
      "Male - Female: ω=0.0636, FIC=0.682 → Acceptable\n",
      "Male - Non-binary: ω=0.2133, FIC=-0.066 → Unacceptable\n",
      "Female - Non-binary: ω=0.1496, FIC=0.252 → Questionable\n",
      "\n",
      "MODEL COMPARISON:\n",
      "   Model Overall Accuracy Avg FIC (αF=0.10) ω_max (αF=0.10)\n",
      "BASELINE           0.6973            -0.422          0.2133\n",
      "      L1           0.7013            -0.416          0.2124\n",
      "      L2           0.6973            -0.422          0.2133\n",
      "\n",
      "================================================================================\n",
      "CASE 2: Criminal Justice - Recidivism Risk\n",
      "================================================================================\n",
      "Generated criminal justice data: 8000 samples\n",
      "High risk prevalence: 0.240\n",
      "Region distribution:\n",
      "region\n",
      "EU                  0.252\n",
      "Africa              0.206\n",
      "Asia                0.150\n",
      "South America       0.149\n",
      "North America       0.102\n",
      "Arab/Middle East    0.092\n",
      "Oceania             0.049\n",
      "Name: proportion, dtype: float64\n",
      "GROUP METRICS TABLE (Baseline Logistic Regression):\n",
      "                  accuracy  selection_rate     tpr     tnr     fpr     fnr     ppv     npv      f1     auc\n",
      "Africa              0.7082          0.0101  0.0070  0.9887  0.0113  0.9930  0.2000  0.7134  0.0136  0.5620\n",
      "South America       0.7424          0.0083  0.0109  0.9926  0.0074  0.9891  0.3333  0.7458  0.0211  0.5868\n",
      "Asia                0.7255          0.0109  0.0198  0.9925  0.0075  0.9802  0.5000  0.7280  0.0381  0.6197\n",
      "EU                  0.8253          0.0133  0.0381  0.9919  0.0081  0.9619  0.5000  0.8297  0.0708  0.6065\n",
      "Oceania             0.7769          0.0077  0.0000  0.9902  0.0098  1.0000  0.0000  0.7829  0.0000  0.5886\n",
      "North America       0.7773          0.0091  0.0204  0.9942  0.0058  0.9796  0.5000  0.7798  0.0392  0.5619\n",
      "Arab/Middle East    0.7175          0.0269  0.0169  0.9695  0.0305  0.9831  0.1667  0.7327  0.0308  0.5931\n",
      "\n",
      "GENERATING VISUALIZATIONS FOR ALL METRICS...\n",
      "\n",
      "============================================================\n",
      "ANALYZING METRIC: ACCURACY\n",
      "============================================================\n",
      "Summary for accuracy:\n",
      "  αF=0.05: ω_max=0.1170, ω_avg=0.0497, Tiers={'Optimum': 3, 'Acceptable': 3, 'Questionable': 5, 'Unacceptable': 10}\n",
      "  αF=0.1: ω_max=0.1170, ω_avg=0.0497, Tiers={'Optimum': 6, 'Acceptable': 5, 'Questionable': 8, 'Unacceptable': 2}\n",
      "  αF=0.15: ω_max=0.1170, ω_avg=0.0497, Tiers={'Optimum': 9, 'Acceptable': 8, 'Questionable': 4, 'Unacceptable': 0}\n",
      "  αF=0.2: ω_max=0.1170, ω_avg=0.0497, Tiers={'Optimum': 11, 'Acceptable': 8, 'Questionable': 2, 'Unacceptable': 0}\n",
      "\n",
      "============================================================\n",
      "ANALYZING METRIC: SELECTION_RATE\n",
      "============================================================\n",
      "Summary for selection_rate:\n",
      "  αF=0.05: ω_max=0.0192, ω_avg=0.0066, Tiers={'Optimum': 15, 'Acceptable': 6, 'Questionable': 0, 'Unacceptable': 0}\n",
      "  αF=0.1: ω_max=0.0192, ω_avg=0.0066, Tiers={'Optimum': 21, 'Acceptable': 0, 'Questionable': 0, 'Unacceptable': 0}\n",
      "  αF=0.15: ω_max=0.0192, ω_avg=0.0066, Tiers={'Optimum': 21, 'Acceptable': 0, 'Questionable': 0, 'Unacceptable': 0}\n",
      "  αF=0.2: ω_max=0.0192, ω_avg=0.0066, Tiers={'Optimum': 21, 'Acceptable': 0, 'Questionable': 0, 'Unacceptable': 0}\n",
      "\n",
      "============================================================\n",
      "ANALYZING METRIC: TPR\n",
      "============================================================\n",
      "Summary for tpr:\n",
      "  αF=0.05: ω_max=0.0381, ω_avg=0.0143, Tiers={'Optimum': 10, 'Acceptable': 8, 'Questionable': 3, 'Unacceptable': 0}\n",
      "  αF=0.1: ω_max=0.0381, ω_avg=0.0143, Tiers={'Optimum': 18, 'Acceptable': 3, 'Questionable': 0, 'Unacceptable': 0}\n",
      "  αF=0.15: ω_max=0.0381, ω_avg=0.0143, Tiers={'Optimum': 20, 'Acceptable': 1, 'Questionable': 0, 'Unacceptable': 0}\n",
      "  αF=0.2: ω_max=0.0381, ω_avg=0.0143, Tiers={'Optimum': 21, 'Acceptable': 0, 'Questionable': 0, 'Unacceptable': 0}\n",
      "\n",
      "============================================================\n",
      "ANALYZING METRIC: TNR\n",
      "============================================================\n",
      "Summary for tnr:\n",
      "  αF=0.05: ω_max=0.0246, ω_avg=0.0080, Tiers={'Optimum': 15, 'Acceptable': 6, 'Questionable': 0, 'Unacceptable': 0}\n",
      "  αF=0.1: ω_max=0.0246, ω_avg=0.0080, Tiers={'Optimum': 21, 'Acceptable': 0, 'Questionable': 0, 'Unacceptable': 0}\n",
      "  αF=0.15: ω_max=0.0246, ω_avg=0.0080, Tiers={'Optimum': 21, 'Acceptable': 0, 'Questionable': 0, 'Unacceptable': 0}\n",
      "  αF=0.2: ω_max=0.0246, ω_avg=0.0080, Tiers={'Optimum': 21, 'Acceptable': 0, 'Questionable': 0, 'Unacceptable': 0}\n",
      "\n",
      "============================================================\n",
      "ANALYZING METRIC: FPR\n",
      "============================================================\n",
      "Summary for fpr:\n",
      "  αF=0.05: ω_max=0.0246, ω_avg=0.0080, Tiers={'Optimum': 15, 'Acceptable': 6, 'Questionable': 0, 'Unacceptable': 0}\n",
      "  αF=0.1: ω_max=0.0246, ω_avg=0.0080, Tiers={'Optimum': 21, 'Acceptable': 0, 'Questionable': 0, 'Unacceptable': 0}\n",
      "  αF=0.15: ω_max=0.0246, ω_avg=0.0080, Tiers={'Optimum': 21, 'Acceptable': 0, 'Questionable': 0, 'Unacceptable': 0}\n",
      "  αF=0.2: ω_max=0.0246, ω_avg=0.0080, Tiers={'Optimum': 21, 'Acceptable': 0, 'Questionable': 0, 'Unacceptable': 0}\n",
      "\n",
      "============================================================\n",
      "ANALYZING METRIC: FNR\n",
      "============================================================\n",
      "Summary for fnr:\n",
      "  αF=0.05: ω_max=0.0381, ω_avg=0.0143, Tiers={'Optimum': 10, 'Acceptable': 8, 'Questionable': 3, 'Unacceptable': 0}\n",
      "  αF=0.1: ω_max=0.0381, ω_avg=0.0143, Tiers={'Optimum': 18, 'Acceptable': 3, 'Questionable': 0, 'Unacceptable': 0}\n",
      "  αF=0.15: ω_max=0.0381, ω_avg=0.0143, Tiers={'Optimum': 20, 'Acceptable': 1, 'Questionable': 0, 'Unacceptable': 0}\n",
      "  αF=0.2: ω_max=0.0381, ω_avg=0.0143, Tiers={'Optimum': 21, 'Acceptable': 0, 'Questionable': 0, 'Unacceptable': 0}\n",
      "\n",
      "============================================================\n",
      "ANALYZING METRIC: PPV\n",
      "============================================================\n",
      "Summary for ppv:\n",
      "  αF=0.05: ω_max=0.5000, ω_avg=0.2349, Tiers={'Optimum': 3, 'Acceptable': 0, 'Questionable': 1, 'Unacceptable': 17}\n",
      "  αF=0.1: ω_max=0.5000, ω_avg=0.2349, Tiers={'Optimum': 3, 'Acceptable': 1, 'Questionable': 0, 'Unacceptable': 17}\n",
      "  αF=0.15: ω_max=0.5000, ω_avg=0.2349, Tiers={'Optimum': 4, 'Acceptable': 0, 'Questionable': 1, 'Unacceptable': 16}\n",
      "  αF=0.2: ω_max=0.5000, ω_avg=0.2349, Tiers={'Optimum': 4, 'Acceptable': 0, 'Questionable': 6, 'Unacceptable': 11}\n",
      "\n",
      "============================================================\n",
      "ANALYZING METRIC: NPV\n",
      "============================================================\n",
      "Summary for npv:\n",
      "  αF=0.05: ω_max=0.1163, ω_avg=0.0482, Tiers={'Optimum': 2, 'Acceptable': 4, 'Questionable': 6, 'Unacceptable': 9}\n",
      "  αF=0.1: ω_max=0.1163, ω_avg=0.0482, Tiers={'Optimum': 6, 'Acceptable': 6, 'Questionable': 7, 'Unacceptable': 2}\n",
      "  αF=0.15: ω_max=0.1163, ω_avg=0.0482, Tiers={'Optimum': 9, 'Acceptable': 8, 'Questionable': 4, 'Unacceptable': 0}\n",
      "  αF=0.2: ω_max=0.1163, ω_avg=0.0482, Tiers={'Optimum': 12, 'Acceptable': 7, 'Questionable': 2, 'Unacceptable': 0}\n",
      "\n",
      "============================================================\n",
      "ANALYZING METRIC: F1\n",
      "============================================================\n",
      "Summary for f1:\n",
      "  αF=0.05: ω_max=0.0708, ω_avg=0.0267, Tiers={'Optimum': 5, 'Acceptable': 6, 'Questionable': 8, 'Unacceptable': 2}\n",
      "  αF=0.1: ω_max=0.0708, ω_avg=0.0267, Tiers={'Optimum': 11, 'Acceptable': 8, 'Questionable': 2, 'Unacceptable': 0}\n",
      "  αF=0.15: ω_max=0.0708, ω_avg=0.0267, Tiers={'Optimum': 15, 'Acceptable': 6, 'Questionable': 0, 'Unacceptable': 0}\n",
      "  αF=0.2: ω_max=0.0708, ω_avg=0.0267, Tiers={'Optimum': 19, 'Acceptable': 2, 'Questionable': 0, 'Unacceptable': 0}\n",
      "\n",
      "============================================================\n",
      "ANALYZING METRIC: AUC\n",
      "============================================================\n",
      "Summary for auc:\n",
      "  αF=0.05: ω_max=0.0578, ω_avg=0.0256, Tiers={'Optimum': 4, 'Acceptable': 6, 'Questionable': 9, 'Unacceptable': 2}\n",
      "  αF=0.1: ω_max=0.0578, ω_avg=0.0256, Tiers={'Optimum': 10, 'Acceptable': 9, 'Questionable': 2, 'Unacceptable': 0}\n",
      "  αF=0.15: ω_max=0.0578, ω_avg=0.0256, Tiers={'Optimum': 17, 'Acceptable': 4, 'Questionable': 0, 'Unacceptable': 0}\n",
      "  αF=0.2: ω_max=0.0578, ω_avg=0.0256, Tiers={'Optimum': 19, 'Acceptable': 2, 'Questionable': 0, 'Unacceptable': 0}\n",
      "\n",
      "FIC ANALYSIS TABLE (Accuracy):\n",
      "                      Group Pair              alphaF=0.05   Hypothesis alphaF=0.05               alphaF=0.1    Hypothesis alphaF=0.1             alphaF=0.15   Hypothesis alphaF=0.15              alphaF=0.2    Hypothesis alphaF=0.2\n",
      "       Africa - Arab/Middle East  omega=0.0092, FIC=0.815 Fail to reject H₀ (Fair)  omega=0.0092, FIC=0.908 Fail to reject H₀ (Fair) omega=0.0092, FIC=0.938 Fail to reject H₀ (Fair) omega=0.0092, FIC=0.954 Fail to reject H₀ (Fair)\n",
      "                   Africa - Asia  omega=0.0173, FIC=0.654 Fail to reject H₀ (Fair)  omega=0.0173, FIC=0.827 Fail to reject H₀ (Fair) omega=0.0173, FIC=0.885 Fail to reject H₀ (Fair) omega=0.0173, FIC=0.914 Fail to reject H₀ (Fair)\n",
      "                     Africa - EU omega=0.1170, FIC=-1.341       Reject H₀ (Unfair) omega=0.1170, FIC=-0.170       Reject H₀ (Unfair) omega=0.1170, FIC=0.220 Fail to reject H₀ (Fair) omega=0.1170, FIC=0.415 Fail to reject H₀ (Fair)\n",
      "          Africa - North America omega=0.0690, FIC=-0.380       Reject H₀ (Unfair)  omega=0.0690, FIC=0.310 Fail to reject H₀ (Fair) omega=0.0690, FIC=0.540 Fail to reject H₀ (Fair) omega=0.0690, FIC=0.655 Fail to reject H₀ (Fair)\n",
      "                Africa - Oceania omega=0.0687, FIC=-0.373       Reject H₀ (Unfair)  omega=0.0687, FIC=0.313 Fail to reject H₀ (Fair) omega=0.0687, FIC=0.542 Fail to reject H₀ (Fair) omega=0.0687, FIC=0.657 Fail to reject H₀ (Fair)\n",
      "          Africa - South America  omega=0.0341, FIC=0.317 Fail to reject H₀ (Fair)  omega=0.0341, FIC=0.659 Fail to reject H₀ (Fair) omega=0.0341, FIC=0.772 Fail to reject H₀ (Fair) omega=0.0341, FIC=0.829 Fail to reject H₀ (Fair)\n",
      "         Asia - Arab/Middle East  omega=0.0081, FIC=0.839 Fail to reject H₀ (Fair)  omega=0.0081, FIC=0.919 Fail to reject H₀ (Fair) omega=0.0081, FIC=0.946 Fail to reject H₀ (Fair) omega=0.0081, FIC=0.960 Fail to reject H₀ (Fair)\n",
      "                       Asia - EU omega=0.0997, FIC=-0.995       Reject H₀ (Unfair)  omega=0.0997, FIC=0.003 Fail to reject H₀ (Fair) omega=0.0997, FIC=0.335 Fail to reject H₀ (Fair) omega=0.0997, FIC=0.501 Fail to reject H₀ (Fair)\n",
      "            Asia - North America omega=0.0517, FIC=-0.035       Reject H₀ (Unfair)  omega=0.0517, FIC=0.483 Fail to reject H₀ (Fair) omega=0.0517, FIC=0.655 Fail to reject H₀ (Fair) omega=0.0517, FIC=0.741 Fail to reject H₀ (Fair)\n",
      "                  Asia - Oceania omega=0.0514, FIC=-0.028       Reject H₀ (Unfair)  omega=0.0514, FIC=0.486 Fail to reject H₀ (Fair) omega=0.0514, FIC=0.657 Fail to reject H₀ (Fair) omega=0.0514, FIC=0.743 Fail to reject H₀ (Fair)\n",
      "           EU - Arab/Middle East omega=0.1078, FIC=-1.156       Reject H₀ (Unfair) omega=0.1078, FIC=-0.078       Reject H₀ (Unfair) omega=0.1078, FIC=0.281 Fail to reject H₀ (Fair) omega=0.1078, FIC=0.461 Fail to reject H₀ (Fair)\n",
      "              EU - North America  omega=0.0480, FIC=0.040 Fail to reject H₀ (Fair)  omega=0.0480, FIC=0.520 Fail to reject H₀ (Fair) omega=0.0480, FIC=0.680 Fail to reject H₀ (Fair) omega=0.0480, FIC=0.760 Fail to reject H₀ (Fair)\n",
      "                    EU - Oceania  omega=0.0484, FIC=0.033 Fail to reject H₀ (Fair)  omega=0.0484, FIC=0.516 Fail to reject H₀ (Fair) omega=0.0484, FIC=0.678 Fail to reject H₀ (Fair) omega=0.0484, FIC=0.758 Fail to reject H₀ (Fair)\n",
      "North America - Arab/Middle East omega=0.0598, FIC=-0.196       Reject H₀ (Unfair)  omega=0.0598, FIC=0.402 Fail to reject H₀ (Fair) omega=0.0598, FIC=0.601 Fail to reject H₀ (Fair) omega=0.0598, FIC=0.701 Fail to reject H₀ (Fair)\n",
      "      Oceania - Arab/Middle East omega=0.0594, FIC=-0.189       Reject H₀ (Unfair)  omega=0.0594, FIC=0.406 Fail to reject H₀ (Fair) omega=0.0594, FIC=0.604 Fail to reject H₀ (Fair) omega=0.0594, FIC=0.703 Fail to reject H₀ (Fair)\n",
      "         Oceania - North America  omega=0.0003, FIC=0.993 Fail to reject H₀ (Fair)  omega=0.0003, FIC=0.997 Fail to reject H₀ (Fair) omega=0.0003, FIC=0.998 Fail to reject H₀ (Fair) omega=0.0003, FIC=0.998 Fail to reject H₀ (Fair)\n",
      "South America - Arab/Middle East  omega=0.0249, FIC=0.502 Fail to reject H₀ (Fair)  omega=0.0249, FIC=0.751 Fail to reject H₀ (Fair) omega=0.0249, FIC=0.834 Fail to reject H₀ (Fair) omega=0.0249, FIC=0.876 Fail to reject H₀ (Fair)\n",
      "            South America - Asia  omega=0.0168, FIC=0.663 Fail to reject H₀ (Fair)  omega=0.0168, FIC=0.832 Fail to reject H₀ (Fair) omega=0.0168, FIC=0.888 Fail to reject H₀ (Fair) omega=0.0168, FIC=0.916 Fail to reject H₀ (Fair)\n",
      "              South America - EU omega=0.0829, FIC=-0.658       Reject H₀ (Unfair)  omega=0.0829, FIC=0.171 Fail to reject H₀ (Fair) omega=0.0829, FIC=0.447 Fail to reject H₀ (Fair) omega=0.0829, FIC=0.585 Fail to reject H₀ (Fair)\n",
      "   South America - North America  omega=0.0349, FIC=0.302 Fail to reject H₀ (Fair)  omega=0.0349, FIC=0.651 Fail to reject H₀ (Fair) omega=0.0349, FIC=0.767 Fail to reject H₀ (Fair) omega=0.0349, FIC=0.826 Fail to reject H₀ (Fair)\n",
      "         South America - Oceania  omega=0.0345, FIC=0.309 Fail to reject H₀ (Fair)  omega=0.0345, FIC=0.655 Fail to reject H₀ (Fair) omega=0.0345, FIC=0.770 Fail to reject H₀ (Fair) omega=0.0345, FIC=0.827 Fail to reject H₀ (Fair)\n",
      "\n",
      "TIER CLASSIFICATION (Accuracy):\n",
      "\n",
      "For αF = 0.05:\n",
      "--------------------------------------------------\n",
      "Africa - South America: ω=0.0341, FIC=0.317 → Questionable\n",
      "Africa - Asia: ω=0.0173, FIC=0.654 → Acceptable\n",
      "Africa - EU: ω=0.1170, FIC=-1.341 → Unacceptable\n",
      "Africa - Oceania: ω=0.0687, FIC=-0.373 → Unacceptable\n",
      "Africa - North America: ω=0.0690, FIC=-0.380 → Unacceptable\n",
      "Africa - Arab/Middle East: ω=0.0092, FIC=0.815 → Optimum (omega_max < 0.0125)\n",
      "South America - Asia: ω=0.0168, FIC=0.663 → Acceptable\n",
      "South America - EU: ω=0.0829, FIC=-0.658 → Unacceptable\n",
      "South America - Oceania: ω=0.0345, FIC=0.309 → Questionable\n",
      "South America - North America: ω=0.0349, FIC=0.302 → Questionable\n",
      "South America - Arab/Middle East: ω=0.0249, FIC=0.502 → Acceptable\n",
      "Asia - EU: ω=0.0997, FIC=-0.995 → Unacceptable\n",
      "Asia - Oceania: ω=0.0514, FIC=-0.028 → Unacceptable\n",
      "Asia - North America: ω=0.0517, FIC=-0.035 → Unacceptable\n",
      "Asia - Arab/Middle East: ω=0.0081, FIC=0.839 → Optimum (omega_max < 0.0125)\n",
      "EU - Oceania: ω=0.0484, FIC=0.033 → Questionable\n",
      "EU - North America: ω=0.0480, FIC=0.040 → Questionable\n",
      "EU - Arab/Middle East: ω=0.1078, FIC=-1.156 → Unacceptable\n",
      "Oceania - North America: ω=0.0003, FIC=0.993 → Optimum (omega_max < 0.0125)\n",
      "Oceania - Arab/Middle East: ω=0.0594, FIC=-0.189 → Unacceptable\n",
      "North America - Arab/Middle East: ω=0.0598, FIC=-0.196 → Unacceptable\n",
      "\n",
      "For αF = 0.1:\n",
      "--------------------------------------------------\n",
      "Africa - South America: ω=0.0341, FIC=0.659 → Acceptable\n",
      "Africa - Asia: ω=0.0173, FIC=0.827 → Optimum (omega_max < 0.0250)\n",
      "Africa - EU: ω=0.1170, FIC=-0.170 → Unacceptable\n",
      "Africa - Oceania: ω=0.0687, FIC=0.313 → Questionable\n",
      "Africa - North America: ω=0.0690, FIC=0.310 → Questionable\n",
      "Africa - Arab/Middle East: ω=0.0092, FIC=0.908 → Optimum (omega_max < 0.0250)\n",
      "South America - Asia: ω=0.0168, FIC=0.832 → Optimum (omega_max < 0.0250)\n",
      "South America - EU: ω=0.0829, FIC=0.171 → Questionable\n",
      "South America - Oceania: ω=0.0345, FIC=0.655 → Acceptable\n",
      "South America - North America: ω=0.0349, FIC=0.651 → Acceptable\n",
      "South America - Arab/Middle East: ω=0.0249, FIC=0.751 → Optimum (omega_max < 0.0250)\n",
      "Asia - EU: ω=0.0997, FIC=0.003 → Questionable\n",
      "Asia - Oceania: ω=0.0514, FIC=0.486 → Questionable\n",
      "Asia - North America: ω=0.0517, FIC=0.483 → Questionable\n",
      "Asia - Arab/Middle East: ω=0.0081, FIC=0.919 → Optimum (omega_max < 0.0250)\n",
      "EU - Oceania: ω=0.0484, FIC=0.516 → Acceptable\n",
      "EU - North America: ω=0.0480, FIC=0.520 → Acceptable\n",
      "EU - Arab/Middle East: ω=0.1078, FIC=-0.078 → Unacceptable\n",
      "Oceania - North America: ω=0.0003, FIC=0.997 → Optimum (omega_max < 0.0250)\n",
      "Oceania - Arab/Middle East: ω=0.0594, FIC=0.406 → Questionable\n",
      "North America - Arab/Middle East: ω=0.0598, FIC=0.402 → Questionable\n",
      "\n",
      "For αF = 0.15:\n",
      "--------------------------------------------------\n",
      "Africa - South America: ω=0.0341, FIC=0.772 → Optimum (omega_max < 0.0375)\n",
      "Africa - Asia: ω=0.0173, FIC=0.885 → Optimum (omega_max < 0.0375)\n",
      "Africa - EU: ω=0.1170, FIC=0.220 → Questionable\n",
      "Africa - Oceania: ω=0.0687, FIC=0.542 → Acceptable\n",
      "Africa - North America: ω=0.0690, FIC=0.540 → Acceptable\n",
      "Africa - Arab/Middle East: ω=0.0092, FIC=0.938 → Optimum (omega_max < 0.0375)\n",
      "South America - Asia: ω=0.0168, FIC=0.888 → Optimum (omega_max < 0.0375)\n",
      "South America - EU: ω=0.0829, FIC=0.447 → Questionable\n",
      "South America - Oceania: ω=0.0345, FIC=0.770 → Optimum (omega_max < 0.0375)\n",
      "South America - North America: ω=0.0349, FIC=0.767 → Optimum (omega_max < 0.0375)\n",
      "South America - Arab/Middle East: ω=0.0249, FIC=0.834 → Optimum (omega_max < 0.0375)\n",
      "Asia - EU: ω=0.0997, FIC=0.335 → Questionable\n",
      "Asia - Oceania: ω=0.0514, FIC=0.657 → Acceptable\n",
      "Asia - North America: ω=0.0517, FIC=0.655 → Acceptable\n",
      "Asia - Arab/Middle East: ω=0.0081, FIC=0.946 → Optimum (omega_max < 0.0375)\n",
      "EU - Oceania: ω=0.0484, FIC=0.678 → Acceptable\n",
      "EU - North America: ω=0.0480, FIC=0.680 → Acceptable\n",
      "EU - Arab/Middle East: ω=0.1078, FIC=0.281 → Questionable\n",
      "Oceania - North America: ω=0.0003, FIC=0.998 → Optimum (omega_max < 0.0375)\n",
      "Oceania - Arab/Middle East: ω=0.0594, FIC=0.604 → Acceptable\n",
      "North America - Arab/Middle East: ω=0.0598, FIC=0.601 → Acceptable\n",
      "\n",
      "For αF = 0.2:\n",
      "--------------------------------------------------\n",
      "Africa - South America: ω=0.0341, FIC=0.829 → Optimum (omega_max < 0.0500)\n",
      "Africa - Asia: ω=0.0173, FIC=0.914 → Optimum (omega_max < 0.0500)\n",
      "Africa - EU: ω=0.1170, FIC=0.415 → Questionable\n",
      "Africa - Oceania: ω=0.0687, FIC=0.657 → Acceptable\n",
      "Africa - North America: ω=0.0690, FIC=0.655 → Acceptable\n",
      "Africa - Arab/Middle East: ω=0.0092, FIC=0.954 → Optimum (omega_max < 0.0500)\n",
      "South America - Asia: ω=0.0168, FIC=0.916 → Optimum (omega_max < 0.0500)\n",
      "South America - EU: ω=0.0829, FIC=0.585 → Acceptable\n",
      "South America - Oceania: ω=0.0345, FIC=0.827 → Optimum (omega_max < 0.0500)\n",
      "South America - North America: ω=0.0349, FIC=0.826 → Optimum (omega_max < 0.0500)\n",
      "South America - Arab/Middle East: ω=0.0249, FIC=0.876 → Optimum (omega_max < 0.0500)\n",
      "Asia - EU: ω=0.0997, FIC=0.501 → Acceptable\n",
      "Asia - Oceania: ω=0.0514, FIC=0.743 → Acceptable\n",
      "Asia - North America: ω=0.0517, FIC=0.741 → Acceptable\n",
      "Asia - Arab/Middle East: ω=0.0081, FIC=0.960 → Optimum (omega_max < 0.0500)\n",
      "EU - Oceania: ω=0.0484, FIC=0.758 → Optimum (omega_max < 0.0500)\n",
      "EU - North America: ω=0.0480, FIC=0.760 → Optimum (omega_max < 0.0500)\n",
      "EU - Arab/Middle East: ω=0.1078, FIC=0.461 → Questionable\n",
      "Oceania - North America: ω=0.0003, FIC=0.998 → Optimum (omega_max < 0.0500)\n",
      "Oceania - Arab/Middle East: ω=0.0594, FIC=0.703 → Acceptable\n",
      "North America - Arab/Middle East: ω=0.0598, FIC=0.701 → Acceptable\n",
      "\n",
      "MODEL COMPARISON:\n",
      "   Model Overall Accuracy Avg FIC (αF=0.10) ω_max (αF=0.10)\n",
      "BASELINE           0.7562             0.503          0.1170\n",
      "      L1           0.7562             0.509          0.1150\n",
      "      L2           0.7562             0.503          0.1170\n",
      "\n",
      "================================================================================\n",
      "SUMMARY REPORT - SIMULATED DATASETS\n",
      "================================================================================\n",
      "CASE 1 - HEALTHCARE KEY FINDINGS:\n",
      "------------------------------------------------------------\n",
      "Total samples: 5000\n",
      "Depression prevalence: 0.300\n",
      "\n",
      "Gender distribution:\n",
      "  Male: 2303 (0.461)\n",
      "  Female: 2234 (0.447)\n",
      "  Non-binary: 463 (0.093)\n",
      "\n",
      "Depression by gender:\n",
      "  Female: 0.299\n",
      "  Male: 0.267\n",
      "  Non-binary: 0.469\n",
      "\n",
      "CASE 2 - CRIMINAL JUSTICE KEY FINDINGS:\n",
      "------------------------------------------------------------\n",
      "Total samples: 8000\n",
      "High risk prevalence: 0.240\n",
      "\n",
      "Region distribution:\n",
      "  EU: 2013 (0.252)\n",
      "  Africa: 1652 (0.206)\n",
      "  Asia: 1198 (0.150)\n",
      "  South America: 1194 (0.149)\n",
      "  North America: 815 (0.102)\n",
      "  Arab/Middle East: 737 (0.092)\n",
      "  Oceania: 391 (0.049)\n",
      "\n",
      "================================================================================\n",
      "ANALYSIS COMPLETE - HIGH-QUALITY PLOTS SAVED\n",
      "================================================================================\n",
      "Generated plots for all metrics: accuracy, selection_rate, tpr, tnr, fpr, fnr, ppv, npv, f1, auc\n",
      "Each metric has:\n",
      "  - 1 heatmap figure (2x2 grid for all alphaF values)\n",
      "  - 4 benchmarking tier plots (one for each alphaF: 0.05, 0.10, 0.15, 0.20)\n",
      "\n",
      "All plots saved in both PNG and PDF formats.\n",
      "PNG files saved in: fic_results_ALL_PLOTS/\n",
      "PDF files saved in: fic_results_ALL_PLOTS\\PDF_plots/\n",
      "All analysis completed!\n",
      "Results saved to: fic_results_ALL_PLOTS/\n",
      "PDF files saved to: fic_results_ALL_PLOTS\\PDF_plots/\n",
      "Files include:\n",
      "  - Group metrics (CSV)\n",
      "  - FIC analysis tables for accuracy (CSV)\n",
      "  - Tier classification for accuracy (CSV)\n",
      "  - Model comparison (CSV)\n",
      "  - FIC heatmaps for ALL 10 metrics (PNG + PDF)\n",
      "  - Benchmarking tiers for ALL 10 metrics (4 plots per metric = 40 PNG + 40 PDF files)\n",
      "Total plots generated: 50 PNG files + 50 PDF files = 100 total files\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create output directory\n",
    "output_dir = \"fic_results_ALL_PLOTS\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Also create PDF subdirectory\n",
    "pdf_dir = os.path.join(output_dir, \"PDF_plots\")\n",
    "os.makedirs(pdf_dir, exist_ok=True)\n",
    "\n",
    "# Set style for publication quality\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Global font settings for consistency\n",
    "plt.rcParams.update({\n",
    "    'font.size': 12,\n",
    "    'axes.titlesize': 16,\n",
    "    'axes.labelsize': 14,\n",
    "    'xtick.labelsize': 12,\n",
    "    'ytick.labelsize': 12,\n",
    "    'legend.fontsize': 12,\n",
    "})\n",
    "\n",
    "# ============================================\n",
    "# 1. DATA SIMULATION\n",
    "# ============================================\n",
    "\n",
    "def generate_healthcare_data(n=5000):\n",
    "    \"\"\"\n",
    "    Generate healthcare data for depression diagnosis\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Gender distribution with realistic proportions\n",
    "    gender = np.random.choice(['Male', 'Female', 'Non-binary'], \n",
    "                             size=n, \n",
    "                             p=[0.455, 0.449, 0.096])\n",
    "    \n",
    "    # Age and income with realistic distributions\n",
    "    age = np.clip(np.random.normal(loc=45, scale=15, size=n), 18, 85)\n",
    "    income = np.clip(np.random.lognormal(mean=10.5, sigma=0.8, size=n), \n",
    "                    20000, 200000)\n",
    "    \n",
    "    # Demographic variables\n",
    "    marital_status = np.random.choice(['Single', 'Married', 'Divorced', 'Widowed'], \n",
    "                                     size=n, \n",
    "                                     p=[0.3, 0.4, 0.2, 0.1])\n",
    "    \n",
    "    immigration_status = np.random.choice(['Citizen', 'Immigrant', 'Refugee'], \n",
    "                                         size=n, \n",
    "                                         p=[0.7, 0.25, 0.05])\n",
    "    \n",
    "    education = np.random.choice(['High School', 'College', 'Bachelor', 'Master', 'PhD'], \n",
    "                                size=n, \n",
    "                                p=[0.2, 0.3, 0.3, 0.15, 0.05])\n",
    "    \n",
    "    job_status = np.random.choice(['Employed', 'Unemployed', 'Student', 'Retired'], \n",
    "                                 size=n, \n",
    "                                 p=[0.6, 0.15, 0.15, 0.1])\n",
    "\n",
    "    # Generate depression probabilities with realistic biases\n",
    "    depression_prob = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        base = 0.15 if gender[i] == 'Male' else 0.20 if gender[i] == 'Female' else 0.35\n",
    "        \n",
    "        prob = base\n",
    "        if job_status[i] == 'Unemployed': \n",
    "            prob += 0.20\n",
    "        if income[i] < 30000: \n",
    "            prob += 0.15\n",
    "        if age[i] < 25 or age[i] > 65: \n",
    "            prob += 0.10\n",
    "        \n",
    "        depression_prob[i] = np.clip(prob, 0, 0.95)\n",
    "    \n",
    "    # Generate binary depression outcome\n",
    "    depression = np.random.binomial(1, depression_prob)\n",
    "\n",
    "    # Create DataFrame\n",
    "    data = pd.DataFrame({\n",
    "        'age': age, \n",
    "        'income': income, \n",
    "        'marital_status': marital_status,\n",
    "        'immigration_status': immigration_status, \n",
    "        'education': education,\n",
    "        'job_status': job_status, \n",
    "        'gender': gender, \n",
    "        'depression': depression\n",
    "    })\n",
    "    \n",
    "    print(f\"Generated healthcare data: {len(data)} samples\")\n",
    "    print(f\"Depression prevalence: {depression.mean():.3f}\")\n",
    "    print(f\"Gender distribution:\")\n",
    "    print(data['gender'].value_counts(normalize=True).round(3))\n",
    "    \n",
    "    return data\n",
    "\n",
    "def generate_criminal_justice_data(n=8000):\n",
    "    \"\"\"\n",
    "    Generate criminal justice data for recidivism risk prediction\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Region distribution\n",
    "    regions = ['Africa', 'EU', 'South America', 'North America', \n",
    "               'Arab/Middle East', 'Asia', 'Oceania']\n",
    "    region_weights = [0.20, 0.25, 0.15, 0.10, 0.10, 0.15, 0.05]\n",
    "    region = np.random.choice(regions, size=n, p=region_weights)\n",
    "    \n",
    "    # Demographic variables\n",
    "    gender = np.random.choice(['Male', 'Female'], size=n, p=[0.7, 0.3])\n",
    "    age = np.clip(np.random.normal(loc=35, scale=12, size=n), 18, 70)\n",
    "    income = np.clip(np.random.lognormal(mean=10.0, sigma=0.9, size=n), \n",
    "                    15000, 150000)\n",
    "    \n",
    "    prior_convictions = np.clip(np.random.poisson(lam=1.5, size=n), 0, 10)\n",
    "    \n",
    "    education = np.random.choice(['Less than HS', 'High School', 'Some College', \n",
    "                                 'College', 'Graduate'], \n",
    "                                size=n, \n",
    "                                p=[0.1, 0.3, 0.25, 0.25, 0.1])\n",
    "    \n",
    "    employment = np.random.choice(['Employed', 'Unemployed', 'Student', 'Other'], \n",
    "                                 size=n, \n",
    "                                 p=[0.5, 0.25, 0.15, 0.1])\n",
    "    \n",
    "    asylum_seeker = np.random.choice([0, 1], size=n, p=[0.85, 0.15])\n",
    "\n",
    "    # Generate high-risk probabilities with regional biases\n",
    "    high_risk_prob = np.zeros(n)\n",
    "    base_rates = {\n",
    "        'Africa': 0.25, \n",
    "        'EU': 0.10, \n",
    "        'South America': 0.20, \n",
    "        'North America': 0.15,\n",
    "        'Arab/Middle East': 0.22, \n",
    "        'Asia': 0.18, \n",
    "        'Oceania': 0.12\n",
    "    }\n",
    "    \n",
    "    for i in range(n):\n",
    "        base = base_rates[region[i]]\n",
    "        prob = base\n",
    "        if asylum_seeker[i] == 1: \n",
    "            prob += 0.15\n",
    "        if employment[i] == 'Unemployed': \n",
    "            prob += 0.12\n",
    "        if prior_convictions[i] > 3: \n",
    "            prob += 0.10\n",
    "        \n",
    "        high_risk_prob[i] = np.clip(prob, 0, 0.95)\n",
    "    \n",
    "    # Generate binary high-risk outcome\n",
    "    high_risk = np.random.binomial(1, high_risk_prob)\n",
    "\n",
    "    # Create DataFrame\n",
    "    data = pd.DataFrame({\n",
    "        'gender': gender, \n",
    "        'age': age, \n",
    "        'income': income, \n",
    "        'prior_convictions': prior_convictions,\n",
    "        'education': education, \n",
    "        'employment': employment, \n",
    "        'asylum_seeker': asylum_seeker,\n",
    "        'region': region, \n",
    "        'high_risk': high_risk\n",
    "    })\n",
    "    \n",
    "    print(f\"Generated criminal justice data: {len(data)} samples\")\n",
    "    print(f\"High risk prevalence: {high_risk.mean():.3f}\")\n",
    "    print(f\"Region distribution:\")\n",
    "    print(data['region'].value_counts(normalize=True).round(3))\n",
    "    \n",
    "    return data\n",
    "\n",
    "# ============================================\n",
    "# 2-3. MODEL & FIC\n",
    "# ============================================\n",
    "\n",
    "def compute_all_metrics(y_true, y_pred, y_prob):\n",
    "    \"\"\"\n",
    "    Compute comprehensive performance metrics\n",
    "    \"\"\"\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    \n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_true, y_pred),\n",
    "        'selection_rate': (tp + fp) / len(y_true),\n",
    "        'tpr': tp / (tp + fn) if (tp + fn) > 0 else 0,\n",
    "        'tnr': tn / (tn + fp) if (tn + fp) > 0 else 0,\n",
    "        'fpr': fp / (fp + tn) if (fp + tn) > 0 else 0,\n",
    "        'fnr': fn / (tp + fn) if (tp + fn) > 0 else 0,\n",
    "        'ppv': tp / (tp + fp) if (tp + fp) > 0 else 0,\n",
    "        'npv': tn / (tn + fn) if (tn + fn) > 0 else 0,\n",
    "        'f1': f1_score(y_true, y_pred),\n",
    "        'auc': roc_auc_score(y_true, y_prob) if len(np.unique(y_true)) > 1 else np.nan\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "def train_and_evaluate_models(data, target_col, protected_col, model_type='baseline'):\n",
    "    \"\"\"\n",
    "    Train and evaluate logistic regression models\n",
    "    \"\"\"\n",
    "    X = data.drop(columns=[target_col, protected_col])\n",
    "    y = data[target_col]\n",
    "    \n",
    "    categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "    numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "    # Preprocessing pipeline\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(drop='first'), categorical_cols)\n",
    "    ])\n",
    "\n",
    "    # Train-test split with stratification\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=42, stratify=y\n",
    "    )\n",
    "    protected_test = data.loc[X_test.index, protected_col]\n",
    "\n",
    "    # Preprocess data\n",
    "    X_train_processed = preprocessor.fit_transform(X_train)\n",
    "    X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "    # Model selection\n",
    "    if model_type == 'baseline':\n",
    "        model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "    elif model_type == 'l1':\n",
    "        model = LogisticRegression(penalty='l1', solver='liblinear', \n",
    "                                  random_state=42, max_iter=1000, C=1.0)\n",
    "    elif model_type == 'l2':\n",
    "        model = LogisticRegression(penalty='l2', random_state=42, \n",
    "                                  max_iter=1000, C=1.0)\n",
    "    else:\n",
    "        model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "    # Train model\n",
    "    model.fit(X_train_processed, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test_processed)\n",
    "    y_prob = model.predict_proba(X_test_processed)[:, 1]\n",
    "\n",
    "    # Compute group-wise metrics\n",
    "    group_metrics = {}\n",
    "    for group in protected_test.unique():\n",
    "        mask = protected_test == group\n",
    "        if mask.sum() > 0:\n",
    "            group_metrics[group] = compute_all_metrics(\n",
    "                y_test[mask], y_pred[mask], y_prob[mask]\n",
    "            )\n",
    "\n",
    "    return group_metrics, (X_test, y_test, protected_test, y_pred, y_prob)\n",
    "\n",
    "class FairnessInformationCriterion:\n",
    "    \"\"\"\n",
    "    Fairness Information Criterion (FIC) framework\n",
    "    \"\"\"\n",
    "    def __init__(self, alphaF_values=[0.05, 0.10, 0.15, 0.20]):\n",
    "        self.alphaF_values = alphaF_values\n",
    "\n",
    "    def compute_omega(self, metric1, metric2):\n",
    "        \"\"\"Compute unfairness magnitude (ω)\"\"\"\n",
    "        return abs(metric1 - metric2)\n",
    "\n",
    "    def compute_fic(self, omega, alphaF):\n",
    "        \"\"\"Compute FIC score\"\"\"\n",
    "        return 1 - (omega / alphaF)\n",
    "\n",
    "    def classify_tier(self, fic_score):\n",
    "        \"\"\"Classify FIC score into fairness tiers\"\"\"\n",
    "        if fic_score > 0.75:\n",
    "            return \"Optimum\"\n",
    "        elif fic_score > 0.50:\n",
    "            return \"Acceptable\"\n",
    "        elif fic_score > 0:\n",
    "            return \"Questionable\"\n",
    "        else:\n",
    "            return \"Unacceptable\"\n",
    "\n",
    "    def analyze_fairness(self, group_metrics, metric_name='accuracy'):\n",
    "        \"\"\"\n",
    "        Analyze fairness across all group pairs for all alphaF values\n",
    "        \"\"\"\n",
    "        results = {}\n",
    "        groups = list(group_metrics.keys())\n",
    "        \n",
    "        for alphaF in self.alphaF_values:\n",
    "            results[alphaF] = {}\n",
    "            for i, g1 in enumerate(groups):\n",
    "                for g2 in groups[i+1:]:\n",
    "                    pair = f\"{g1} - {g2}\"\n",
    "                    m1 = group_metrics[g1].get(metric_name, np.nan)\n",
    "                    m2 = group_metrics[g2].get(metric_name, np.nan)\n",
    "                    \n",
    "                    if not np.isnan(m1) and not np.isnan(m2):\n",
    "                        omega = self.compute_omega(m1, m2)\n",
    "                        fic_score = self.compute_fic(omega, alphaF)\n",
    "                        tier = self.classify_tier(fic_score)\n",
    "                        \n",
    "                        results[alphaF][pair] = {\n",
    "                            'omega': omega, \n",
    "                            'fic_score': fic_score, \n",
    "                            'tier': tier,\n",
    "                            'metric1': m1, \n",
    "                            'metric2': m2\n",
    "                        }\n",
    "        return results\n",
    "\n",
    "# ============================================\n",
    "# 4. VISUALIZATIONS - IMPROVED WITH PDF SUPPORT\n",
    "# ============================================\n",
    "\n",
    "def plot_fic_heatmaps(fic_results, dataset_name, metric='accuracy'):\n",
    "    \"\"\"\n",
    "    Create FIC heatmaps for all alphaF values\n",
    "    \"\"\"\n",
    "    alphaF_values = sorted(fic_results.keys())\n",
    "    if not alphaF_values:\n",
    "        return\n",
    "\n",
    "    pairs = list(fic_results[alphaF_values[0]].keys())\n",
    "    all_groups = sorted(set(g for p in pairs for g in p.split(' - ')))\n",
    "\n",
    "    # Larger figure for publication quality\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(20, 16))\n",
    "    fig.suptitle(f'{dataset_name}: FIC Heatmaps for Different αF Values ({metric})',\n",
    "                 fontsize=20, fontweight='bold', y=0.98)\n",
    "\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for idx, alphaF in enumerate(alphaF_values):\n",
    "        ax = axes[idx]\n",
    "        n = len(all_groups)\n",
    "        mat = np.full((n, n), np.nan)\n",
    "        group_idx = {g: i for i, g in enumerate(all_groups)}\n",
    "\n",
    "        # Fill matrix with FIC scores\n",
    "        for pair, d in fic_results[alphaF].items():\n",
    "            g1, g2 = pair.split(' - ')\n",
    "            i, j = group_idx[g1], group_idx[g2]\n",
    "            mat[i, j] = mat[j, i] = d['fic_score']\n",
    "\n",
    "        # Create heatmap\n",
    "        im = ax.imshow(mat, cmap='RdYlGn', vmin=-1, vmax=1, aspect='equal')\n",
    "\n",
    "        # Add value labels inside cells\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                if i != j and not np.isnan(mat[i, j]):\n",
    "                    text = ax.text(j, i, f'{mat[i,j]:.2f}',\n",
    "                                   ha='center', va='center',\n",
    "                                   fontsize=14, fontweight='bold',\n",
    "                                   color='white' if abs(mat[i,j]) > 0.5 else 'black')\n",
    "\n",
    "        # Customize axes\n",
    "        ax.set_xticks(range(n))\n",
    "        ax.set_yticks(range(n))\n",
    "        ax.set_xticklabels(all_groups, rotation=45, ha='right', fontsize=13, fontweight='bold')\n",
    "        ax.set_yticklabels(all_groups, fontsize=13, fontweight='bold')\n",
    "        ax.set_title(f'αF = {alphaF}', fontsize=18, fontweight='bold', pad=20)\n",
    "        \n",
    "        # Add grid\n",
    "        ax.set_xticks(np.arange(-.5, n, 1), minor=True)\n",
    "        ax.set_yticks(np.arange(-.5, n, 1), minor=True)\n",
    "        ax.grid(which='minor', color='gray', linestyle='-', linewidth=0.5, alpha=0.3)\n",
    "\n",
    "    # Add comprehensive colorbar with tier labels\n",
    "    cbar_ax = fig.add_axes([0.78, 0.15, 0.02, 0.7])\n",
    "    cbar = fig.colorbar(im, cax=cbar_ax)\n",
    "    cbar.set_label('FIC Score', fontsize=14, fontweight='bold', labelpad=15)\n",
    "    cbar.ax.tick_params(labelsize=12)\n",
    "    \n",
    "    # Bold colorbar tick labels\n",
    "    for label in cbar.ax.get_yticklabels():\n",
    "        label.set_fontweight('bold')\n",
    "    \n",
    "    # Add tier annotations on colorbar\n",
    "    cbar.ax.text(1.8, 0.90, 'Optimum', transform=cbar.ax.transAxes, \n",
    "                 fontsize=14, fontweight='bold', va='center', ha='left', color='darkgreen')\n",
    "    cbar.ax.text(1.8, 0.60, 'Acceptable', transform=cbar.ax.transAxes, \n",
    "                 fontsize=14, fontweight='bold', va='center', ha='left', color='goldenrod')\n",
    "    cbar.ax.text(1.8, 0.350, 'Questionable', transform=cbar.ax.transAxes, \n",
    "                 fontsize=14, fontweight='bold', va='center', ha='left', color='darkorange')\n",
    "    cbar.ax.text(1.8, 0.100, 'Unacceptable', transform=cbar.ax.transAxes, \n",
    "                 fontsize=14, fontweight='bold', va='center', ha='left', color='darkred')\n",
    "    \n",
    "    # Add tier threshold lines on colorbar\n",
    "    cbar.ax.axhline(0.75, color='darkgreen', linestyle='--', linewidth=3, xmax=0.6)\n",
    "    cbar.ax.axhline(0.50, color='goldenrod', linestyle='--', linewidth=3, xmax=0.6)\n",
    "    cbar.ax.axhline(0.00, color='darkred', linestyle='--', linewidth=3, xmax=0.6)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 0.78, 0.95])\n",
    "    \n",
    "    # Save as PNG and PDF\n",
    "    plt.savefig(os.path.join(output_dir, f'{dataset_name}_FIC_Heatmaps_{metric}.png'), \n",
    "                dpi=400, bbox_inches='tight')\n",
    "    plt.savefig(os.path.join(pdf_dir, f'{dataset_name}_FIC_Heatmaps_{metric}.pdf'), \n",
    "                format='pdf', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_benchmarking_tiers(fic_results, dataset_name, metric='accuracy'):\n",
    "    \"\"\"\n",
    "    Create benchmarking tier plots for each alphaF value\n",
    "    \"\"\"\n",
    "    alphaF_values = sorted(fic_results.keys())\n",
    "    \n",
    "    # Define colors for tiers\n",
    "    colors = {\n",
    "        'Optimum': '#2E8B57', \n",
    "        'Acceptable': '#FFD700', \n",
    "        'Questionable': '#FF8C00', \n",
    "        'Unacceptable': '#DC143C'\n",
    "    }\n",
    "    \n",
    "    for alphaF in alphaF_values:\n",
    "        if alphaF not in fic_results or not fic_results[alphaF]:\n",
    "            continue\n",
    "        \n",
    "        # Create figure with expanded width for legend\n",
    "        fig, ax = plt.subplots(figsize=(20, 8))\n",
    "        \n",
    "        data = fic_results[alphaF]\n",
    "        pairs = list(data.keys())\n",
    "        fic_scores = [data[p]['fic_score'] for p in pairs]\n",
    "        tiers = [data[p]['tier'] for p in pairs]\n",
    "        \n",
    "        # Find dynamic y-axis limits\n",
    "        max_positive = max(fic_scores) if fic_scores else 1.0\n",
    "        min_negative = min(fic_scores) if fic_scores else -0.25\n",
    "        \n",
    "        # Add padding\n",
    "        y_max = max_positive * 1.10 if max_positive > 0 else 0.10\n",
    "        y_min = min_negative * 1.10 if min_negative < 0 else -0.10\n",
    "        \n",
    "        # Ensure minimum range\n",
    "        if y_max - y_min < 0.5:\n",
    "            center = (max_positive + min_negative) / 2\n",
    "            y_max = center + 0.25\n",
    "            y_min = center - 0.25\n",
    "        \n",
    "        # Create bars\n",
    "        bar_colors = [colors[t] for t in tiers]\n",
    "        bars = ax.bar(range(len(pairs)), fic_scores, color=bar_colors, \n",
    "                      edgecolor='black', linewidth=1.2, width=0.6)\n",
    "        \n",
    "        # Add tier threshold lines\n",
    "        ax.axhline(0.75, color='darkgreen', linestyle='--', linewidth=2.0, alpha=0.7)\n",
    "        ax.axhline(0.50, color='goldenrod', linestyle='--', linewidth=2.0, alpha=0.7)\n",
    "        ax.axhline(0.00, color='darkred', linestyle='--', linewidth=2.0, alpha=0.7)\n",
    "        \n",
    "        # Customize axes\n",
    "        ax.set_xlabel('Group Pairs', fontsize=14, fontweight='bold', labelpad=10)\n",
    "        ax.set_ylabel('FIC Score', fontsize=14, fontweight='bold', labelpad=10)\n",
    "        ax.set_title(f'{dataset_name}\\nFIC Benchmarking Tiers ({metric}, αF = {alphaF})',\n",
    "                    fontsize=16, fontweight='bold', pad=15)\n",
    "        \n",
    "        # Set x-ticks\n",
    "        ax.set_xticks(range(len(pairs)))\n",
    "        ax.set_xticklabels(pairs, rotation=45, ha='right', fontsize=11, fontweight='bold')\n",
    "        \n",
    "        # Set y-axis limits\n",
    "        ax.set_ylim(y_min, y_max)\n",
    "        \n",
    "        # Format y-tick labels\n",
    "        y_ticks = ax.get_yticks()\n",
    "        ax.set_yticklabels([f'{tick:.2f}' for tick in y_ticks], fontsize=11, fontweight='bold')\n",
    "        \n",
    "        # Add grid\n",
    "        ax.grid(True, axis='y', alpha=0.3, linestyle='-', linewidth=0.5)\n",
    "        \n",
    "        # Create tier legend\n",
    "        from matplotlib.patches import Patch\n",
    "        legend_elements = [\n",
    "            Patch(facecolor=colors['Optimum'], edgecolor='black', \n",
    "                  label='Optimum (FIC > 0.75)'),\n",
    "            Patch(facecolor=colors['Acceptable'], edgecolor='black', \n",
    "                  label='Acceptable (0.50 < FIC ≤ 0.75)'),\n",
    "            Patch(facecolor=colors['Questionable'], edgecolor='black', \n",
    "                  label='Questionable (0 < FIC ≤ 0.50)'),\n",
    "            Patch(facecolor=colors['Unacceptable'], edgecolor='black', \n",
    "                  label='Unacceptable (FIC ≤ 0)')\n",
    "        ]\n",
    "        \n",
    "        # Create threshold line legend\n",
    "        from matplotlib.lines import Line2D\n",
    "        line_legend_elements = [\n",
    "            Line2D([0], [0], color='darkgreen', linestyle='--', linewidth=2, \n",
    "                   label='Optimum Threshold (0.75)'),\n",
    "            Line2D([0], [0], color='goldenrod', linestyle='--', linewidth=2, \n",
    "                   label='Acceptable Threshold (0.50)'),\n",
    "            Line2D([0], [0], color='darkred', linestyle='--', linewidth=2, \n",
    "                   label='Unacceptable Threshold (0.00)')\n",
    "        ]\n",
    "        \n",
    "        # Place tier legend\n",
    "        tier_legend = ax.legend(handles=legend_elements, fontsize=10, \n",
    "                                loc='upper left', bbox_to_anchor=(1.05, 1.0),\n",
    "                                frameon=True, framealpha=0.9, edgecolor='black',\n",
    "                                title='FIC Tiers', title_fontsize=11)\n",
    "        tier_legend.get_title().set_fontweight('bold')\n",
    "        ax.add_artist(tier_legend)\n",
    "        \n",
    "        # Place threshold legend\n",
    "        threshold_legend = ax.legend(handles=line_legend_elements, fontsize=9, \n",
    "                                     loc='upper left', bbox_to_anchor=(1.05, 0.65),\n",
    "                                     frameon=True, framealpha=0.9, edgecolor='black',\n",
    "                                     title='Thresholds', title_fontsize=10)\n",
    "        threshold_legend.get_title().set_fontweight('bold')\n",
    "        \n",
    "        # Add annotation for alphaF interpretation\n",
    "        annotation_text = f'αF = {alphaF}\\nFIC = 1 - (ω/αF)\\nω = |M₁ - M₂|'\n",
    "        ax.text(0.02, 0.98, annotation_text, transform=ax.transAxes,\n",
    "                fontsize=9, verticalalignment='top', fontweight='bold',\n",
    "                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
    "        \n",
    "        # Adjust layout\n",
    "        plt.tight_layout(rect=[0, 0, 0.80, 1])\n",
    "        \n",
    "        # Save figures\n",
    "        png_filename = f'{dataset_name}_Benchmarking_Tiers_alphaF_{alphaF}_{metric}.png'\n",
    "        pdf_filename = f'{dataset_name}_Benchmarking_Tiers_alphaF_{alphaF}_{metric}.pdf'\n",
    "        \n",
    "        plt.savefig(os.path.join(output_dir, png_filename), \n",
    "                    dpi=400, bbox_inches='tight')\n",
    "        plt.savefig(os.path.join(pdf_dir, pdf_filename), \n",
    "                    format='pdf', bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "# ============================================\n",
    "# 5. ANALYSIS FUNCTIONS - FOR ALL METRICS\n",
    "# ============================================\n",
    "\n",
    "def analyze_dataset(dataset_name, data_generator, target_col, protected_col, \n",
    "                   case_number=1, model_types=['baseline', 'l1', 'l2']):\n",
    "    \"\"\"\n",
    "    Complete analysis for a dataset\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"CASE {case_number}: {dataset_name}\")\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "    # Generate data\n",
    "    data = data_generator()\n",
    "    fic_framework = FairnessInformationCriterion()\n",
    "\n",
    "    # Train baseline model\n",
    "    baseline_metrics, _ = train_and_evaluate_models(data, target_col, \n",
    "                                                   protected_col, 'baseline')\n",
    "\n",
    "    # Create metrics table\n",
    "    metrics_df = pd.DataFrame.from_dict(baseline_metrics, orient='index')\n",
    "    metrics_df = metrics_df[['accuracy', 'selection_rate', 'tpr', 'tnr', \n",
    "                            'fpr', 'fnr', 'ppv', 'npv', 'f1', 'auc']]\n",
    "    \n",
    "    print(\"GROUP METRICS TABLE (Baseline Logistic Regression):\")\n",
    "    print(metrics_df.round(4).to_string())\n",
    "    metrics_df.to_csv(os.path.join(output_dir, \n",
    "                                  f'Case{case_number}_Group_Metrics.csv'))\n",
    "\n",
    "    print(\"\\nGENERATING VISUALIZATIONS FOR ALL METRICS...\")\n",
    "    \n",
    "    # List of all metrics to analyze\n",
    "    all_metrics = ['accuracy', 'selection_rate', 'tpr', 'tnr', \n",
    "                  'fpr', 'fnr', 'ppv', 'npv', 'f1', 'auc']\n",
    "    \n",
    "    # Dictionary to store all FIC results\n",
    "    all_fic_results = {}\n",
    "    \n",
    "    for metric in all_metrics:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"ANALYZING METRIC: {metric.upper()}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # Analyze fairness for this metric\n",
    "        fic_results = fic_framework.analyze_fairness(baseline_metrics, metric)\n",
    "        all_fic_results[metric] = fic_results\n",
    "        \n",
    "        # Generate heatmaps\n",
    "        plot_fic_heatmaps(fic_results, \n",
    "                         f'Case{case_number}_{dataset_name}_{metric}', \n",
    "                         metric)\n",
    "        \n",
    "        # Generate benchmarking tiers\n",
    "        plot_benchmarking_tiers(fic_results, \n",
    "                               f'Case{case_number}_{dataset_name}_{metric}', \n",
    "                               metric)\n",
    "        \n",
    "        # Print summary\n",
    "        print(f\"Summary for {metric}:\")\n",
    "        for af in fic_framework.alphaF_values:\n",
    "            if af in fic_results and fic_results[af]:\n",
    "                omegas = [d['omega'] for d in fic_results[af].values()]\n",
    "                max_o = max(omegas)\n",
    "                avg_o = np.mean(omegas)\n",
    "                tiers = {'Optimum': 0, 'Acceptable': 0, \n",
    "                        'Questionable': 0, 'Unacceptable': 0}\n",
    "                for d in fic_results[af].values():\n",
    "                    tiers[fic_framework.classify_tier(d['fic_score'])] += 1\n",
    "                print(f\"  αF={af}: ω_max={max_o:.4f}, ω_avg={avg_o:.4f}, \"\n",
    "                      f\"Tiers={tiers}\")\n",
    "\n",
    "    # Store FIC results for accuracy (original metric)\n",
    "    fic_results = all_fic_results['accuracy']\n",
    "    \n",
    "    # FIC table for accuracy\n",
    "    fic_table = []\n",
    "    for pair in sorted(set(p for a in fic_results.values() for p in a.keys())):\n",
    "        row = {'Group Pair': pair}\n",
    "        for af in fic_framework.alphaF_values:\n",
    "            if af in fic_results and pair in fic_results[af]:\n",
    "                d = fic_results[af][pair]\n",
    "                row[f'alphaF={af}'] = f\"omega={d['omega']:.4f}, FIC={d['fic_score']:.3f}\"\n",
    "                row[f'Hypothesis alphaF={af}'] = (\"Fail to reject H₀ (Fair)\" \n",
    "                                                  if d['omega'] <= af \n",
    "                                                  else \"Reject H₀ (Unfair)\")\n",
    "            else:\n",
    "                row[f'alphaF={af}'] = \"N/A\"\n",
    "                row[f'Hypothesis alphaF={af}'] = \"N/A\"\n",
    "        fic_table.append(row)\n",
    "    \n",
    "    fic_df = pd.DataFrame(fic_table)\n",
    "    print(\"\\nFIC ANALYSIS TABLE (Accuracy):\")\n",
    "    print(fic_df.to_string(index=False))\n",
    "    fic_df.to_csv(os.path.join(output_dir, \n",
    "                              f'Case{case_number}_FIC_Analysis_accuracy.csv'), \n",
    "                 index=False)\n",
    "\n",
    "    # Tier classification for accuracy\n",
    "    tier_data = []\n",
    "    print(\"\\nTIER CLASSIFICATION (Accuracy):\")\n",
    "    for af in fic_framework.alphaF_values:\n",
    "        print(f\"\\nFor αF = {af}:\")\n",
    "        print(\"-\" * 50)\n",
    "        if af in fic_results:\n",
    "            for pair, d in fic_results[af].items():\n",
    "                tier = fic_framework.classify_tier(d['fic_score'])\n",
    "                msg = (tier if d['fic_score'] <= 0.75 \n",
    "                       else f\"{tier} (omega_max < {0.25*af:.4f})\")\n",
    "                print(f\"{pair}: ω={d['omega']:.4f}, FIC={d['fic_score']:.3f} → {msg}\")\n",
    "                tier_data.append({'alphaF': af, 'Group Pair': pair, \n",
    "                                 'ω': d['omega'], 'FIC': d['fic_score'], \n",
    "                                 'Tier': tier})\n",
    "    \n",
    "    tier_df = pd.DataFrame(tier_data)\n",
    "    tier_df.to_csv(os.path.join(output_dir, \n",
    "                               f'Case{case_number}_Tier_Classification_accuracy.csv'), \n",
    "                  index=False)\n",
    "\n",
    "    # Model comparison\n",
    "    print(\"\\nMODEL COMPARISON:\")\n",
    "    comparison = []\n",
    "    for mt in model_types:\n",
    "        mets, test_data = train_and_evaluate_models(data, target_col, \n",
    "                                                   protected_col, mt)\n",
    "        model_fic = fic_framework.analyze_fairness(mets, 'accuracy')\n",
    "        avg_fic = (np.mean([d['fic_score'] for d in model_fic[0.10].values()]) \n",
    "                  if 0.10 in model_fic and model_fic[0.10] else np.nan)\n",
    "        max_omega = (max([d['omega'] for d in model_fic[0.10].values()]) \n",
    "                    if 0.10 in model_fic and model_fic[0.10] else np.nan)\n",
    "        _, y_test, _, y_pred, _ = test_data\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        comparison.append({\n",
    "            'Model': mt.upper(),\n",
    "            'Overall Accuracy': f\"{acc:.4f}\",\n",
    "            'Avg FIC (αF=0.10)': f\"{avg_fic:.3f}\" if not np.isnan(avg_fic) else \"N/A\",\n",
    "            'ω_max (αF=0.10)': f\"{max_omega:.4f}\" if not np.isnan(max_omega) else \"N/A\"\n",
    "        })\n",
    "    \n",
    "    comparison_df = pd.DataFrame(comparison)\n",
    "    print(comparison_df.to_string(index=False))\n",
    "    comparison_df.to_csv(os.path.join(output_dir, \n",
    "                                     f'Case{case_number}_Model_Comparison.csv'), \n",
    "                        index=False)\n",
    "\n",
    "    return {\n",
    "        'data': data,\n",
    "        'baseline_metrics': baseline_metrics,\n",
    "        'fic_results': fic_results,\n",
    "        'all_fic_results': all_fic_results,\n",
    "        'metrics_df': metrics_df,\n",
    "        'fic_df': fic_df,\n",
    "        'tier_df': tier_df,\n",
    "        'comparison_df': comparison_df\n",
    "    }\n",
    "\n",
    "# ============================================\n",
    "# 6. MAIN ANALYSIS\n",
    "# ============================================\n",
    "\n",
    "def run_complete_analysis():\n",
    "    \"\"\"\n",
    "    Run complete FIC analysis for simulated datasets\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"FAIRNESS INFORMATION CRITERION (FIC) ANALYSIS - SIMULATED DATASETS\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # Healthcare dataset analysis\n",
    "    healthcare_results = analyze_dataset(\n",
    "        dataset_name=\"Healthcare - Depression Diagnosis\",\n",
    "        data_generator=lambda: generate_healthcare_data(5000),\n",
    "        target_col='depression',\n",
    "        protected_col='gender',\n",
    "        case_number=1\n",
    "    )\n",
    "\n",
    "    # Criminal justice dataset analysis\n",
    "    criminal_results = analyze_dataset(\n",
    "        dataset_name=\"Criminal Justice - Recidivism Risk\",\n",
    "        data_generator=lambda: generate_criminal_justice_data(8000),\n",
    "        target_col='high_risk',\n",
    "        protected_col='region',\n",
    "        case_number=2\n",
    "    )\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"SUMMARY REPORT - SIMULATED DATASETS\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    print(\"CASE 1 - HEALTHCARE KEY FINDINGS:\")\n",
    "    print(\"-\" * 60)\n",
    "    data = healthcare_results['data']\n",
    "    print(f\"Total samples: {len(data)}\")\n",
    "    print(f\"Depression prevalence: {data['depression'].mean():.3f}\")\n",
    "    print(\"\\nGender distribution:\")\n",
    "    gender_dist = data['gender'].value_counts()\n",
    "    for gender, count in gender_dist.items():\n",
    "        prop = count / len(data)\n",
    "        print(f\"  {gender}: {count} ({prop:.3f})\")\n",
    "    \n",
    "    print(\"\\nDepression by gender:\")\n",
    "    for gender in sorted(data['gender'].unique()):\n",
    "        subset = data[data['gender'] == gender]\n",
    "        depression_prop = subset['depression'].mean()\n",
    "        print(f\"  {gender}: {depression_prop:.3f}\")\n",
    "\n",
    "    print(\"\\nCASE 2 - CRIMINAL JUSTICE KEY FINDINGS:\")\n",
    "    print(\"-\" * 60)\n",
    "    data = criminal_results['data']\n",
    "    print(f\"Total samples: {len(data)}\")\n",
    "    print(f\"High risk prevalence: {data['high_risk'].mean():.3f}\")\n",
    "    print(\"\\nRegion distribution:\")\n",
    "    region_dist = data['region'].value_counts()\n",
    "    for region, count in region_dist.items():\n",
    "        prop = count / len(data)\n",
    "        print(f\"  {region}: {count} ({prop:.3f})\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ANALYSIS COMPLETE - HIGH-QUALITY PLOTS SAVED\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Generated plots for all metrics: accuracy, selection_rate, tpr, tnr, \"\n",
    "          f\"fpr, fnr, ppv, npv, f1, auc\")\n",
    "    print(f\"Each metric has:\")\n",
    "    print(f\"  - 1 heatmap figure (2x2 grid for all alphaF values)\")\n",
    "    print(f\"  - 4 benchmarking tier plots (one for each alphaF: 0.05, 0.10, 0.15, 0.20)\")\n",
    "    print(f\"\\nAll plots saved in both PNG and PDF formats.\")\n",
    "    print(f\"PNG files saved in: {output_dir}/\")\n",
    "    print(f\"PDF files saved in: {pdf_dir}/\")\n",
    "\n",
    "    return healthcare_results, criminal_results\n",
    "\n",
    "# ============================================\n",
    "# 7. EXECUTION\n",
    "# ============================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run the complete analysis\n",
    "    healthcare_results, criminal_results = run_complete_analysis()\n",
    "\n",
    "    print(\"All analysis completed!\")\n",
    "    print(f\"Results saved to: {output_dir}/\")\n",
    "    print(f\"PDF files saved to: {pdf_dir}/\")\n",
    "    print(\"Files include:\")\n",
    "    print(\"  - Group metrics (CSV)\")\n",
    "    print(\"  - FIC analysis tables for accuracy (CSV)\")\n",
    "    print(\"  - Tier classification for accuracy (CSV)\")\n",
    "    print(\"  - Model comparison (CSV)\")\n",
    "    print(\"  - FIC heatmaps for ALL 10 metrics (PNG + PDF)\")\n",
    "    print(\"  - Benchmarking tiers for ALL 10 metrics (4 plots per metric = 40 PNG + 40 PDF files)\")\n",
    "    print(f\"Total plots generated: {10 + 40} PNG files + {10 + 40} PDF files = {100} total files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d287b3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6467f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#........ With EXCEL NUMERICAL METRIC VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cb6c17e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FAIRNESS INFORMATION CRITERION (FIC) ANALYSIS - SIMULATED DATASETS\n",
      "================================================================================\n",
      "Output directory: fic_results_ALL_METRICS_EXCEL\n",
      "PDF directory: fic_results_ALL_METRICS_EXCEL\\PDF_plots\n",
      "Excel directory: fic_results_ALL_METRICS_EXCEL\\Excel_results\n",
      "\n",
      "================================================================================\n",
      "ANALYZING SIMULATED DATASETS\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "CASE 1: Healthcare - Depression Diagnosis\n",
      "================================================================================\n",
      "Generated healthcare data: 5000 samples\n",
      "Depression prevalence: 0.300\n",
      "Gender distribution:\n",
      "gender\n",
      "Male          0.461\n",
      "Female        0.447\n",
      "Non-binary    0.093\n",
      "Name: proportion, dtype: float64\n",
      "GROUP METRICS TABLE (Baseline Logistic Regression):\n",
      "            accuracy  selection_rate     tpr     tnr     fpr     fnr     ppv     npv      f1     auc\n",
      "Male          0.7470          0.0281  0.0581  0.9821  0.0179  0.9419  0.5263  0.7534  0.1047  0.6563\n",
      "Female        0.6834          0.0148  0.0143  0.9850  0.0150  0.9857  0.3000  0.6892  0.0273  0.6029\n",
      "Non-binary    0.5338          0.0338  0.0294  0.9625  0.0375  0.9706  0.4000  0.5385  0.0548  0.6287\n",
      "Group metrics saved to: fic_results_ALL_METRICS_EXCEL\\Case1_Healthcare_-_Depression_Diagnosis_Group_Metrics.csv\n",
      "GENERATING VISUALIZATIONS FOR ALL METRICS...\n",
      "\n",
      "============================================================\n",
      "ANALYZING METRIC: ACCURACY\n",
      "============================================================\n",
      "Summary for accuracy:\n",
      "\n",
      "============================================================\n",
      "ANALYZING METRIC: SELECTION_RATE\n",
      "============================================================\n",
      "Summary for selection_rate:\n",
      "\n",
      "============================================================\n",
      "ANALYZING METRIC: TPR\n",
      "============================================================\n",
      "Summary for tpr:\n",
      "\n",
      "============================================================\n",
      "ANALYZING METRIC: TNR\n",
      "============================================================\n",
      "Summary for tnr:\n",
      "\n",
      "============================================================\n",
      "ANALYZING METRIC: FPR\n",
      "============================================================\n",
      "Summary for fpr:\n",
      "\n",
      "============================================================\n",
      "ANALYZING METRIC: FNR\n",
      "============================================================\n",
      "Summary for fnr:\n",
      "\n",
      "============================================================\n",
      "ANALYZING METRIC: PPV\n",
      "============================================================\n",
      "Summary for ppv:\n",
      "\n",
      "============================================================\n",
      "ANALYZING METRIC: NPV\n",
      "============================================================\n",
      "Summary for npv:\n",
      "\n",
      "============================================================\n",
      "ANALYZING METRIC: F1\n",
      "============================================================\n",
      "Summary for f1:\n",
      "\n",
      "============================================================\n",
      "ANALYZING METRIC: AUC\n",
      "============================================================\n",
      "Summary for auc:\n",
      "FIC ANALYSIS TABLE (Accuracy):\n",
      "         Group Pair              alphaF=0.05 Hypothesis alphaF=0.05               alphaF=0.1    Hypothesis alphaF=0.1              alphaF=0.15   Hypothesis alphaF=0.15               alphaF=0.2    Hypothesis alphaF=0.2\n",
      "Female - Non-binary omega=0.1496, FIC=-1.993     Reject H₀ (Unfair) omega=0.1496, FIC=-0.496       Reject H₀ (Unfair)  omega=0.1496, FIC=0.002 Fail to reject H₀ (Fair)  omega=0.1496, FIC=0.252 Fail to reject H₀ (Fair)\n",
      "      Male - Female omega=0.0636, FIC=-0.272     Reject H₀ (Unfair)  omega=0.0636, FIC=0.364 Fail to reject H₀ (Fair)  omega=0.0636, FIC=0.576 Fail to reject H₀ (Fair)  omega=0.0636, FIC=0.682 Fail to reject H₀ (Fair)\n",
      "  Male - Non-binary omega=0.2133, FIC=-3.265     Reject H₀ (Unfair) omega=0.2133, FIC=-1.133       Reject H₀ (Unfair) omega=0.2133, FIC=-0.422       Reject H₀ (Unfair) omega=0.2133, FIC=-0.066       Reject H₀ (Unfair)\n",
      "FIC analysis saved to: fic_results_ALL_METRICS_EXCEL\\Case1_Healthcare_-_Depression_Diagnosis_FIC_Analysis_accuracy.csv\n",
      "TIER CLASSIFICATION (Accuracy):\n",
      "\n",
      "For αF = 0.05:\n",
      "--------------------------------------------------\n",
      "Male - Female: ω=0.0636, FIC=-0.272 → Unacceptable\n",
      "Male - Non-binary: ω=0.2133, FIC=-3.265 → Unacceptable\n",
      "Female - Non-binary: ω=0.1496, FIC=-1.993 → Unacceptable\n",
      "\n",
      "For αF = 0.1:\n",
      "--------------------------------------------------\n",
      "Male - Female: ω=0.0636, FIC=0.364 → Questionable\n",
      "Male - Non-binary: ω=0.2133, FIC=-1.133 → Unacceptable\n",
      "Female - Non-binary: ω=0.1496, FIC=-0.496 → Unacceptable\n",
      "\n",
      "For αF = 0.15:\n",
      "--------------------------------------------------\n",
      "Male - Female: ω=0.0636, FIC=0.576 → Acceptable\n",
      "Male - Non-binary: ω=0.2133, FIC=-0.422 → Unacceptable\n",
      "Female - Non-binary: ω=0.1496, FIC=0.002 → Questionable\n",
      "\n",
      "For αF = 0.2:\n",
      "--------------------------------------------------\n",
      "Male - Female: ω=0.0636, FIC=0.682 → Acceptable\n",
      "Male - Non-binary: ω=0.2133, FIC=-0.066 → Unacceptable\n",
      "Female - Non-binary: ω=0.1496, FIC=0.252 → Questionable\n",
      "✓ Tier classification saved to: fic_results_ALL_METRICS_EXCEL\\Case1_Healthcare_-_Depression_Diagnosis_Tier_Classification_accuracy.csv\n",
      "MODEL COMPARISON:\n",
      "   Model Overall Accuracy Avg FIC (αF=0.10) ω_max (αF=0.10)\n",
      "BASELINE           0.6973            -0.422          0.2133\n",
      "      L1           0.7013            -0.416          0.2124\n",
      "      L2           0.6973            -0.422          0.2133\n",
      "Model comparison saved to: fic_results_ALL_METRICS_EXCEL\\Case1_Healthcare_-_Depression_Diagnosis_Model_Comparison.csv\n",
      "\n",
      "================================================================================\n",
      "CREATING COMPREHENSIVE EXCEL REPORT FOR HEALTHCARE - DEPRESSION DIAGNOSIS\n",
      "================================================================================\n",
      "1. Saving Group Metrics Table...\n",
      "2. Saving FIC Analysis Tables for all metrics...\n",
      "3. Saving Tier Classification Summary for all metrics...\n",
      "4. Saving Benchmarking Tiers Numerical Values...\n",
      "5. Saving Summary Statistics for each metric...\n",
      "6. Saving Model Comparison...\n",
      "7. Saving Dataset Statistics...\n",
      "8. Creating Fairness Assessment Matrix...\n",
      "  ✓ Excel file saved: Healthcare_-_Depression_Diagnosis_FIC_Complete_Analysis.xlsx\n",
      "\n",
      "✓ Excel report saved: fic_results_ALL_METRICS_EXCEL\\Excel_results\\Healthcare_-_Depression_Diagnosis_FIC_Complete_Analysis.xlsx\n",
      "  Total sheets: 35\n",
      "\n",
      "Excel sheets created:\n",
      "   1. Group_Metrics\n",
      "   2. FIC_Analysis_accuracy\n",
      "   3. FIC_Analysis_selection_rate\n",
      "   4. FIC_Analysis_tpr\n",
      "   5. FIC_Analysis_tnr\n",
      "   6. FIC_Analysis_fpr\n",
      "   7. FIC_Analysis_fnr\n",
      "   8. FIC_Analysis_ppv\n",
      "   9. FIC_Analysis_npv\n",
      "  10. FIC_Analysis_f1\n",
      "  11. FIC_Analysis_auc\n",
      "  12. Tier_Summary_accuracy\n",
      "  13. Tier_Summary_selection_rate\n",
      "  14. Tier_Summary_tpr\n",
      "  15. Tier_Summary_tnr\n",
      "  16. Tier_Summary_fpr\n",
      "  17. Tier_Summary_fnr\n",
      "  18. Tier_Summary_ppv\n",
      "  19. Tier_Summary_npv\n",
      "  20. Tier_Summary_f1\n",
      "  21. Tier_Summary_auc\n",
      "  22. Benchmark_Tiers_accuracy\n",
      "  23. Benchmark_Tiers_selection_rate\n",
      "  24. Benchmark_Tiers_tpr\n",
      "  25. Benchmark_Tiers_tnr\n",
      "  26. Benchmark_Tiers_fpr\n",
      "  27. Benchmark_Tiers_fnr\n",
      "  28. Benchmark_Tiers_ppv\n",
      "  29. Benchmark_Tiers_npv\n",
      "  30. Benchmark_Tiers_f1\n",
      "  31. Benchmark_Tiers_auc\n",
      "  32. Summary_Statistics\n",
      "  33. Model_Comparison\n",
      "  34. Dataset_Statistics\n",
      "  35. Fairness_Assessment\n",
      "\n",
      "================================================================================\n",
      "CASE 2: Criminal Justice - Recidivism Risk\n",
      "================================================================================\n",
      "Generated criminal justice data: 8000 samples\n",
      "High risk prevalence: 0.240\n",
      "Region distribution:\n",
      "region\n",
      "EU                  0.252\n",
      "Africa              0.206\n",
      "Asia                0.150\n",
      "South America       0.149\n",
      "North America       0.102\n",
      "Arab/Middle East    0.092\n",
      "Oceania             0.049\n",
      "Name: proportion, dtype: float64\n",
      "GROUP METRICS TABLE (Baseline Logistic Regression):\n",
      "                  accuracy  selection_rate     tpr     tnr     fpr     fnr     ppv     npv      f1     auc\n",
      "Africa              0.7082          0.0101  0.0070  0.9887  0.0113  0.9930  0.2000  0.7134  0.0136  0.5620\n",
      "South America       0.7424          0.0083  0.0109  0.9926  0.0074  0.9891  0.3333  0.7458  0.0211  0.5868\n",
      "Asia                0.7255          0.0109  0.0198  0.9925  0.0075  0.9802  0.5000  0.7280  0.0381  0.6197\n",
      "EU                  0.8253          0.0133  0.0381  0.9919  0.0081  0.9619  0.5000  0.8297  0.0708  0.6065\n",
      "Oceania             0.7769          0.0077  0.0000  0.9902  0.0098  1.0000  0.0000  0.7829  0.0000  0.5886\n",
      "North America       0.7773          0.0091  0.0204  0.9942  0.0058  0.9796  0.5000  0.7798  0.0392  0.5619\n",
      "Arab/Middle East    0.7175          0.0269  0.0169  0.9695  0.0305  0.9831  0.1667  0.7327  0.0308  0.5931\n",
      "Group metrics saved to: fic_results_ALL_METRICS_EXCEL\\Case2_Criminal_Justice_-_Recidivism_Risk_Group_Metrics.csv\n",
      "GENERATING VISUALIZATIONS FOR ALL METRICS...\n",
      "\n",
      "============================================================\n",
      "ANALYZING METRIC: ACCURACY\n",
      "============================================================\n",
      "Summary for accuracy:\n",
      "\n",
      "============================================================\n",
      "ANALYZING METRIC: SELECTION_RATE\n",
      "============================================================\n",
      "Summary for selection_rate:\n",
      "\n",
      "============================================================\n",
      "ANALYZING METRIC: TPR\n",
      "============================================================\n",
      "Summary for tpr:\n",
      "\n",
      "============================================================\n",
      "ANALYZING METRIC: TNR\n",
      "============================================================\n",
      "Summary for tnr:\n",
      "\n",
      "============================================================\n",
      "ANALYZING METRIC: FPR\n",
      "============================================================\n",
      "Summary for fpr:\n",
      "\n",
      "============================================================\n",
      "ANALYZING METRIC: FNR\n",
      "============================================================\n",
      "Summary for fnr:\n",
      "\n",
      "============================================================\n",
      "ANALYZING METRIC: PPV\n",
      "============================================================\n",
      "Summary for ppv:\n",
      "\n",
      "============================================================\n",
      "ANALYZING METRIC: NPV\n",
      "============================================================\n",
      "Summary for npv:\n",
      "\n",
      "============================================================\n",
      "ANALYZING METRIC: F1\n",
      "============================================================\n",
      "Summary for f1:\n",
      "\n",
      "============================================================\n",
      "ANALYZING METRIC: AUC\n",
      "============================================================\n",
      "Summary for auc:\n",
      "FIC ANALYSIS TABLE (Accuracy):\n",
      "                      Group Pair              alphaF=0.05   Hypothesis alphaF=0.05               alphaF=0.1    Hypothesis alphaF=0.1             alphaF=0.15   Hypothesis alphaF=0.15              alphaF=0.2    Hypothesis alphaF=0.2\n",
      "       Africa - Arab/Middle East  omega=0.0092, FIC=0.815 Fail to reject H₀ (Fair)  omega=0.0092, FIC=0.908 Fail to reject H₀ (Fair) omega=0.0092, FIC=0.938 Fail to reject H₀ (Fair) omega=0.0092, FIC=0.954 Fail to reject H₀ (Fair)\n",
      "                   Africa - Asia  omega=0.0173, FIC=0.654 Fail to reject H₀ (Fair)  omega=0.0173, FIC=0.827 Fail to reject H₀ (Fair) omega=0.0173, FIC=0.885 Fail to reject H₀ (Fair) omega=0.0173, FIC=0.914 Fail to reject H₀ (Fair)\n",
      "                     Africa - EU omega=0.1170, FIC=-1.341       Reject H₀ (Unfair) omega=0.1170, FIC=-0.170       Reject H₀ (Unfair) omega=0.1170, FIC=0.220 Fail to reject H₀ (Fair) omega=0.1170, FIC=0.415 Fail to reject H₀ (Fair)\n",
      "          Africa - North America omega=0.0690, FIC=-0.380       Reject H₀ (Unfair)  omega=0.0690, FIC=0.310 Fail to reject H₀ (Fair) omega=0.0690, FIC=0.540 Fail to reject H₀ (Fair) omega=0.0690, FIC=0.655 Fail to reject H₀ (Fair)\n",
      "                Africa - Oceania omega=0.0687, FIC=-0.373       Reject H₀ (Unfair)  omega=0.0687, FIC=0.313 Fail to reject H₀ (Fair) omega=0.0687, FIC=0.542 Fail to reject H₀ (Fair) omega=0.0687, FIC=0.657 Fail to reject H₀ (Fair)\n",
      "          Africa - South America  omega=0.0341, FIC=0.317 Fail to reject H₀ (Fair)  omega=0.0341, FIC=0.659 Fail to reject H₀ (Fair) omega=0.0341, FIC=0.772 Fail to reject H₀ (Fair) omega=0.0341, FIC=0.829 Fail to reject H₀ (Fair)\n",
      "         Asia - Arab/Middle East  omega=0.0081, FIC=0.839 Fail to reject H₀ (Fair)  omega=0.0081, FIC=0.919 Fail to reject H₀ (Fair) omega=0.0081, FIC=0.946 Fail to reject H₀ (Fair) omega=0.0081, FIC=0.960 Fail to reject H₀ (Fair)\n",
      "                       Asia - EU omega=0.0997, FIC=-0.995       Reject H₀ (Unfair)  omega=0.0997, FIC=0.003 Fail to reject H₀ (Fair) omega=0.0997, FIC=0.335 Fail to reject H₀ (Fair) omega=0.0997, FIC=0.501 Fail to reject H₀ (Fair)\n",
      "            Asia - North America omega=0.0517, FIC=-0.035       Reject H₀ (Unfair)  omega=0.0517, FIC=0.483 Fail to reject H₀ (Fair) omega=0.0517, FIC=0.655 Fail to reject H₀ (Fair) omega=0.0517, FIC=0.741 Fail to reject H₀ (Fair)\n",
      "                  Asia - Oceania omega=0.0514, FIC=-0.028       Reject H₀ (Unfair)  omega=0.0514, FIC=0.486 Fail to reject H₀ (Fair) omega=0.0514, FIC=0.657 Fail to reject H₀ (Fair) omega=0.0514, FIC=0.743 Fail to reject H₀ (Fair)\n",
      "           EU - Arab/Middle East omega=0.1078, FIC=-1.156       Reject H₀ (Unfair) omega=0.1078, FIC=-0.078       Reject H₀ (Unfair) omega=0.1078, FIC=0.281 Fail to reject H₀ (Fair) omega=0.1078, FIC=0.461 Fail to reject H₀ (Fair)\n",
      "              EU - North America  omega=0.0480, FIC=0.040 Fail to reject H₀ (Fair)  omega=0.0480, FIC=0.520 Fail to reject H₀ (Fair) omega=0.0480, FIC=0.680 Fail to reject H₀ (Fair) omega=0.0480, FIC=0.760 Fail to reject H₀ (Fair)\n",
      "                    EU - Oceania  omega=0.0484, FIC=0.033 Fail to reject H₀ (Fair)  omega=0.0484, FIC=0.516 Fail to reject H₀ (Fair) omega=0.0484, FIC=0.678 Fail to reject H₀ (Fair) omega=0.0484, FIC=0.758 Fail to reject H₀ (Fair)\n",
      "North America - Arab/Middle East omega=0.0598, FIC=-0.196       Reject H₀ (Unfair)  omega=0.0598, FIC=0.402 Fail to reject H₀ (Fair) omega=0.0598, FIC=0.601 Fail to reject H₀ (Fair) omega=0.0598, FIC=0.701 Fail to reject H₀ (Fair)\n",
      "      Oceania - Arab/Middle East omega=0.0594, FIC=-0.189       Reject H₀ (Unfair)  omega=0.0594, FIC=0.406 Fail to reject H₀ (Fair) omega=0.0594, FIC=0.604 Fail to reject H₀ (Fair) omega=0.0594, FIC=0.703 Fail to reject H₀ (Fair)\n",
      "         Oceania - North America  omega=0.0003, FIC=0.993 Fail to reject H₀ (Fair)  omega=0.0003, FIC=0.997 Fail to reject H₀ (Fair) omega=0.0003, FIC=0.998 Fail to reject H₀ (Fair) omega=0.0003, FIC=0.998 Fail to reject H₀ (Fair)\n",
      "South America - Arab/Middle East  omega=0.0249, FIC=0.502 Fail to reject H₀ (Fair)  omega=0.0249, FIC=0.751 Fail to reject H₀ (Fair) omega=0.0249, FIC=0.834 Fail to reject H₀ (Fair) omega=0.0249, FIC=0.876 Fail to reject H₀ (Fair)\n",
      "            South America - Asia  omega=0.0168, FIC=0.663 Fail to reject H₀ (Fair)  omega=0.0168, FIC=0.832 Fail to reject H₀ (Fair) omega=0.0168, FIC=0.888 Fail to reject H₀ (Fair) omega=0.0168, FIC=0.916 Fail to reject H₀ (Fair)\n",
      "              South America - EU omega=0.0829, FIC=-0.658       Reject H₀ (Unfair)  omega=0.0829, FIC=0.171 Fail to reject H₀ (Fair) omega=0.0829, FIC=0.447 Fail to reject H₀ (Fair) omega=0.0829, FIC=0.585 Fail to reject H₀ (Fair)\n",
      "   South America - North America  omega=0.0349, FIC=0.302 Fail to reject H₀ (Fair)  omega=0.0349, FIC=0.651 Fail to reject H₀ (Fair) omega=0.0349, FIC=0.767 Fail to reject H₀ (Fair) omega=0.0349, FIC=0.826 Fail to reject H₀ (Fair)\n",
      "         South America - Oceania  omega=0.0345, FIC=0.309 Fail to reject H₀ (Fair)  omega=0.0345, FIC=0.655 Fail to reject H₀ (Fair) omega=0.0345, FIC=0.770 Fail to reject H₀ (Fair) omega=0.0345, FIC=0.827 Fail to reject H₀ (Fair)\n",
      "FIC analysis saved to: fic_results_ALL_METRICS_EXCEL\\Case2_Criminal_Justice_-_Recidivism_Risk_FIC_Analysis_accuracy.csv\n",
      "TIER CLASSIFICATION (Accuracy):\n",
      "\n",
      "For αF = 0.05:\n",
      "--------------------------------------------------\n",
      "Africa - South America: ω=0.0341, FIC=0.317 → Questionable\n",
      "Africa - Asia: ω=0.0173, FIC=0.654 → Acceptable\n",
      "Africa - EU: ω=0.1170, FIC=-1.341 → Unacceptable\n",
      "Africa - Oceania: ω=0.0687, FIC=-0.373 → Unacceptable\n",
      "Africa - North America: ω=0.0690, FIC=-0.380 → Unacceptable\n",
      "Africa - Arab/Middle East: ω=0.0092, FIC=0.815 → Optimum (omega_max < 0.0125)\n",
      "South America - Asia: ω=0.0168, FIC=0.663 → Acceptable\n",
      "South America - EU: ω=0.0829, FIC=-0.658 → Unacceptable\n",
      "South America - Oceania: ω=0.0345, FIC=0.309 → Questionable\n",
      "South America - North America: ω=0.0349, FIC=0.302 → Questionable\n",
      "South America - Arab/Middle East: ω=0.0249, FIC=0.502 → Acceptable\n",
      "Asia - EU: ω=0.0997, FIC=-0.995 → Unacceptable\n",
      "Asia - Oceania: ω=0.0514, FIC=-0.028 → Unacceptable\n",
      "Asia - North America: ω=0.0517, FIC=-0.035 → Unacceptable\n",
      "Asia - Arab/Middle East: ω=0.0081, FIC=0.839 → Optimum (omega_max < 0.0125)\n",
      "EU - Oceania: ω=0.0484, FIC=0.033 → Questionable\n",
      "EU - North America: ω=0.0480, FIC=0.040 → Questionable\n",
      "EU - Arab/Middle East: ω=0.1078, FIC=-1.156 → Unacceptable\n",
      "Oceania - North America: ω=0.0003, FIC=0.993 → Optimum (omega_max < 0.0125)\n",
      "Oceania - Arab/Middle East: ω=0.0594, FIC=-0.189 → Unacceptable\n",
      "North America - Arab/Middle East: ω=0.0598, FIC=-0.196 → Unacceptable\n",
      "\n",
      "For αF = 0.1:\n",
      "--------------------------------------------------\n",
      "Africa - South America: ω=0.0341, FIC=0.659 → Acceptable\n",
      "Africa - Asia: ω=0.0173, FIC=0.827 → Optimum (omega_max < 0.0250)\n",
      "Africa - EU: ω=0.1170, FIC=-0.170 → Unacceptable\n",
      "Africa - Oceania: ω=0.0687, FIC=0.313 → Questionable\n",
      "Africa - North America: ω=0.0690, FIC=0.310 → Questionable\n",
      "Africa - Arab/Middle East: ω=0.0092, FIC=0.908 → Optimum (omega_max < 0.0250)\n",
      "South America - Asia: ω=0.0168, FIC=0.832 → Optimum (omega_max < 0.0250)\n",
      "South America - EU: ω=0.0829, FIC=0.171 → Questionable\n",
      "South America - Oceania: ω=0.0345, FIC=0.655 → Acceptable\n",
      "South America - North America: ω=0.0349, FIC=0.651 → Acceptable\n",
      "South America - Arab/Middle East: ω=0.0249, FIC=0.751 → Optimum (omega_max < 0.0250)\n",
      "Asia - EU: ω=0.0997, FIC=0.003 → Questionable\n",
      "Asia - Oceania: ω=0.0514, FIC=0.486 → Questionable\n",
      "Asia - North America: ω=0.0517, FIC=0.483 → Questionable\n",
      "Asia - Arab/Middle East: ω=0.0081, FIC=0.919 → Optimum (omega_max < 0.0250)\n",
      "EU - Oceania: ω=0.0484, FIC=0.516 → Acceptable\n",
      "EU - North America: ω=0.0480, FIC=0.520 → Acceptable\n",
      "EU - Arab/Middle East: ω=0.1078, FIC=-0.078 → Unacceptable\n",
      "Oceania - North America: ω=0.0003, FIC=0.997 → Optimum (omega_max < 0.0250)\n",
      "Oceania - Arab/Middle East: ω=0.0594, FIC=0.406 → Questionable\n",
      "North America - Arab/Middle East: ω=0.0598, FIC=0.402 → Questionable\n",
      "\n",
      "For αF = 0.15:\n",
      "--------------------------------------------------\n",
      "Africa - South America: ω=0.0341, FIC=0.772 → Optimum (omega_max < 0.0375)\n",
      "Africa - Asia: ω=0.0173, FIC=0.885 → Optimum (omega_max < 0.0375)\n",
      "Africa - EU: ω=0.1170, FIC=0.220 → Questionable\n",
      "Africa - Oceania: ω=0.0687, FIC=0.542 → Acceptable\n",
      "Africa - North America: ω=0.0690, FIC=0.540 → Acceptable\n",
      "Africa - Arab/Middle East: ω=0.0092, FIC=0.938 → Optimum (omega_max < 0.0375)\n",
      "South America - Asia: ω=0.0168, FIC=0.888 → Optimum (omega_max < 0.0375)\n",
      "South America - EU: ω=0.0829, FIC=0.447 → Questionable\n",
      "South America - Oceania: ω=0.0345, FIC=0.770 → Optimum (omega_max < 0.0375)\n",
      "South America - North America: ω=0.0349, FIC=0.767 → Optimum (omega_max < 0.0375)\n",
      "South America - Arab/Middle East: ω=0.0249, FIC=0.834 → Optimum (omega_max < 0.0375)\n",
      "Asia - EU: ω=0.0997, FIC=0.335 → Questionable\n",
      "Asia - Oceania: ω=0.0514, FIC=0.657 → Acceptable\n",
      "Asia - North America: ω=0.0517, FIC=0.655 → Acceptable\n",
      "Asia - Arab/Middle East: ω=0.0081, FIC=0.946 → Optimum (omega_max < 0.0375)\n",
      "EU - Oceania: ω=0.0484, FIC=0.678 → Acceptable\n",
      "EU - North America: ω=0.0480, FIC=0.680 → Acceptable\n",
      "EU - Arab/Middle East: ω=0.1078, FIC=0.281 → Questionable\n",
      "Oceania - North America: ω=0.0003, FIC=0.998 → Optimum (omega_max < 0.0375)\n",
      "Oceania - Arab/Middle East: ω=0.0594, FIC=0.604 → Acceptable\n",
      "North America - Arab/Middle East: ω=0.0598, FIC=0.601 → Acceptable\n",
      "\n",
      "For αF = 0.2:\n",
      "--------------------------------------------------\n",
      "Africa - South America: ω=0.0341, FIC=0.829 → Optimum (omega_max < 0.0500)\n",
      "Africa - Asia: ω=0.0173, FIC=0.914 → Optimum (omega_max < 0.0500)\n",
      "Africa - EU: ω=0.1170, FIC=0.415 → Questionable\n",
      "Africa - Oceania: ω=0.0687, FIC=0.657 → Acceptable\n",
      "Africa - North America: ω=0.0690, FIC=0.655 → Acceptable\n",
      "Africa - Arab/Middle East: ω=0.0092, FIC=0.954 → Optimum (omega_max < 0.0500)\n",
      "South America - Asia: ω=0.0168, FIC=0.916 → Optimum (omega_max < 0.0500)\n",
      "South America - EU: ω=0.0829, FIC=0.585 → Acceptable\n",
      "South America - Oceania: ω=0.0345, FIC=0.827 → Optimum (omega_max < 0.0500)\n",
      "South America - North America: ω=0.0349, FIC=0.826 → Optimum (omega_max < 0.0500)\n",
      "South America - Arab/Middle East: ω=0.0249, FIC=0.876 → Optimum (omega_max < 0.0500)\n",
      "Asia - EU: ω=0.0997, FIC=0.501 → Acceptable\n",
      "Asia - Oceania: ω=0.0514, FIC=0.743 → Acceptable\n",
      "Asia - North America: ω=0.0517, FIC=0.741 → Acceptable\n",
      "Asia - Arab/Middle East: ω=0.0081, FIC=0.960 → Optimum (omega_max < 0.0500)\n",
      "EU - Oceania: ω=0.0484, FIC=0.758 → Optimum (omega_max < 0.0500)\n",
      "EU - North America: ω=0.0480, FIC=0.760 → Optimum (omega_max < 0.0500)\n",
      "EU - Arab/Middle East: ω=0.1078, FIC=0.461 → Questionable\n",
      "Oceania - North America: ω=0.0003, FIC=0.998 → Optimum (omega_max < 0.0500)\n",
      "Oceania - Arab/Middle East: ω=0.0594, FIC=0.703 → Acceptable\n",
      "North America - Arab/Middle East: ω=0.0598, FIC=0.701 → Acceptable\n",
      "✓ Tier classification saved to: fic_results_ALL_METRICS_EXCEL\\Case2_Criminal_Justice_-_Recidivism_Risk_Tier_Classification_accuracy.csv\n",
      "MODEL COMPARISON:\n",
      "   Model Overall Accuracy Avg FIC (αF=0.10) ω_max (αF=0.10)\n",
      "BASELINE           0.7562             0.503          0.1170\n",
      "      L1           0.7562             0.509          0.1150\n",
      "      L2           0.7562             0.503          0.1170\n",
      "Model comparison saved to: fic_results_ALL_METRICS_EXCEL\\Case2_Criminal_Justice_-_Recidivism_Risk_Model_Comparison.csv\n",
      "\n",
      "================================================================================\n",
      "CREATING COMPREHENSIVE EXCEL REPORT FOR CRIMINAL JUSTICE - RECIDIVISM RISK\n",
      "================================================================================\n",
      "1. Saving Group Metrics Table...\n",
      "2. Saving FIC Analysis Tables for all metrics...\n",
      "3. Saving Tier Classification Summary for all metrics...\n",
      "4. Saving Benchmarking Tiers Numerical Values...\n",
      "5. Saving Summary Statistics for each metric...\n",
      "6. Saving Model Comparison...\n",
      "7. Saving Dataset Statistics...\n",
      "8. Creating Fairness Assessment Matrix...\n",
      "  ✓ Excel file saved: Criminal_Justice_-_Recidivism_Risk_FIC_Complete_Analysis.xlsx\n",
      "\n",
      "✓ Excel report saved: fic_results_ALL_METRICS_EXCEL\\Excel_results\\Criminal_Justice_-_Recidivism_Risk_FIC_Complete_Analysis.xlsx\n",
      "  Total sheets: 35\n",
      "\n",
      "Excel sheets created:\n",
      "   1. Group_Metrics\n",
      "   2. FIC_Analysis_accuracy\n",
      "   3. FIC_Analysis_selection_rate\n",
      "   4. FIC_Analysis_tpr\n",
      "   5. FIC_Analysis_tnr\n",
      "   6. FIC_Analysis_fpr\n",
      "   7. FIC_Analysis_fnr\n",
      "   8. FIC_Analysis_ppv\n",
      "   9. FIC_Analysis_npv\n",
      "  10. FIC_Analysis_f1\n",
      "  11. FIC_Analysis_auc\n",
      "  12. Tier_Summary_accuracy\n",
      "  13. Tier_Summary_selection_rate\n",
      "  14. Tier_Summary_tpr\n",
      "  15. Tier_Summary_tnr\n",
      "  16. Tier_Summary_fpr\n",
      "  17. Tier_Summary_fnr\n",
      "  18. Tier_Summary_ppv\n",
      "  19. Tier_Summary_npv\n",
      "  20. Tier_Summary_f1\n",
      "  21. Tier_Summary_auc\n",
      "  22. Benchmark_Tiers_accuracy\n",
      "  23. Benchmark_Tiers_selection_rate\n",
      "  24. Benchmark_Tiers_tpr\n",
      "  25. Benchmark_Tiers_tnr\n",
      "  26. Benchmark_Tiers_fpr\n",
      "  27. Benchmark_Tiers_fnr\n",
      "  28. Benchmark_Tiers_ppv\n",
      "  29. Benchmark_Tiers_npv\n",
      "  30. Benchmark_Tiers_f1\n",
      "  31. Benchmark_Tiers_auc\n",
      "  32. Summary_Statistics\n",
      "  33. Model_Comparison\n",
      "  34. Dataset_Statistics\n",
      "  35. Fairness_Assessment\n",
      "\n",
      "================================================================================\n",
      "SUMMARY REPORT - SIMULATED DATASETS\n",
      "================================================================================\n",
      "CASE 1 - HEALTHCARE DATASET KEY FINDINGS:\n",
      "------------------------------------------------------------\n",
      "Total samples: 5000\n",
      "Depression prevalence: 0.300\n",
      "Gender distribution:\n",
      "  Male: 2303 (0.461)\n",
      "  Female: 2234 (0.447)\n",
      "  Non-binary: 463 (0.093)\n",
      "Depression by gender:\n",
      "  Female: 0.299\n",
      "  Male: 0.267\n",
      "  Non-binary: 0.469\n",
      "FIC ANALYSIS SUMMARY (Accuracy - Healthcare):\n",
      "------------------------------------------------------------\n",
      "alphaF=0.05:\n",
      "  omega range: [0.0636, 0.2133], avg: 0.1422\n",
      "  Most unfair pair: Male - Non-binary (ω=0.2133)\n",
      "  Most fair pair: Male - Female (ω=0.0636)\n",
      "  Tier distribution: {'Optimum': 0, 'Acceptable': 0, 'Questionable': 0, 'Unacceptable': 3}\n",
      "alphaF=0.1:\n",
      "  omega range: [0.0636, 0.2133], avg: 0.1422\n",
      "  Most unfair pair: Male - Non-binary (ω=0.2133)\n",
      "  Most fair pair: Male - Female (ω=0.0636)\n",
      "  Tier distribution: {'Optimum': 0, 'Acceptable': 0, 'Questionable': 1, 'Unacceptable': 2}\n",
      "alphaF=0.15:\n",
      "  omega range: [0.0636, 0.2133], avg: 0.1422\n",
      "  Most unfair pair: Male - Non-binary (ω=0.2133)\n",
      "  Most fair pair: Male - Female (ω=0.0636)\n",
      "  Tier distribution: {'Optimum': 0, 'Acceptable': 1, 'Questionable': 1, 'Unacceptable': 1}\n",
      "alphaF=0.2:\n",
      "  omega range: [0.0636, 0.2133], avg: 0.1422\n",
      "  Most unfair pair: Male - Non-binary (ω=0.2133)\n",
      "  Most fair pair: Male - Female (ω=0.0636)\n",
      "  Tier distribution: {'Optimum': 0, 'Acceptable': 1, 'Questionable': 1, 'Unacceptable': 1}\n",
      "CASE 2 - CRIMINAL JUSTICE DATASET KEY FINDINGS:\n",
      "------------------------------------------------------------\n",
      "Total samples: 8000\n",
      "High risk prevalence: 0.240\n",
      "Region distribution:\n",
      "  EU: 2013 (0.252)\n",
      "  Africa: 1652 (0.206)\n",
      "  Asia: 1198 (0.150)\n",
      "  South America: 1194 (0.149)\n",
      "  North America: 815 (0.102)\n",
      "  Arab/Middle East: 737 (0.092)\n",
      "  Oceania: 391 (0.049)\n",
      "FIC ANALYSIS SUMMARY (Accuracy - Criminal Justice):\n",
      "------------------------------------------------------------\n",
      "alphaF=0.05:\n",
      "  omega range: [0.0003, 0.1170], avg: 0.0497\n",
      "  Most unfair pair: Africa - EU (ω=0.1170)\n",
      "  Most fair pair: Oceania - North America (ω=0.0003)\n",
      "  Tier distribution: {'Optimum': 3, 'Acceptable': 3, 'Questionable': 5, 'Unacceptable': 10}\n",
      "alphaF=0.1:\n",
      "  omega range: [0.0003, 0.1170], avg: 0.0497\n",
      "  Most unfair pair: Africa - EU (ω=0.1170)\n",
      "  Most fair pair: Oceania - North America (ω=0.0003)\n",
      "  Tier distribution: {'Optimum': 6, 'Acceptable': 5, 'Questionable': 8, 'Unacceptable': 2}\n",
      "alphaF=0.15:\n",
      "  omega range: [0.0003, 0.1170], avg: 0.0497\n",
      "  Most unfair pair: Africa - EU (ω=0.1170)\n",
      "  Most fair pair: Oceania - North America (ω=0.0003)\n",
      "  Tier distribution: {'Optimum': 9, 'Acceptable': 8, 'Questionable': 4, 'Unacceptable': 0}\n",
      "alphaF=0.2:\n",
      "  omega range: [0.0003, 0.1170], avg: 0.0497\n",
      "  Most unfair pair: Africa - EU (ω=0.1170)\n",
      "  Most fair pair: Oceania - North America (ω=0.0003)\n",
      "  Tier distribution: {'Optimum': 11, 'Acceptable': 8, 'Questionable': 2, 'Unacceptable': 0}\n",
      "\n",
      "================================================================================\n",
      "ANALYSIS COMPLETE - ALL RESULTS SAVED\n",
      "================================================================================\n",
      "VISUALIZATIONS:\n",
      "  Generated plots for 2 cases × 10 metrics = 20 metric analyses\n",
      "  Each metric analysis has:\n",
      "    - 1 heatmap figure (2x2 grid for all alphaF values)\n",
      "    - 4 benchmarking tier plots (one for each alphaF: 0.05, 0.10, 0.15, 0.20)\n",
      "  Total plots: 100 PNG files + 100 PDF files = 200 total files\n",
      "NUMERICAL RESULTS:\n",
      "  CSV files saved in: fic_results_ALL_METRICS_EXCEL/\n",
      "  Comprehensive Excel reports:\n",
      "    - fic_results_ALL_METRICS_EXCEL\\Excel_results\\Healthcare_-_Depression_Diagnosis_FIC_Complete_Analysis.xlsx\n",
      "    - fic_results_ALL_METRICS_EXCEL\\Excel_results\\Criminal_Justice_-_Recidivism_Risk_FIC_Complete_Analysis.xlsx\n",
      "\n",
      "================================================================================\n",
      "ALL SIMULATED CASES ANALYSIS COMPLETED SUCCESSFULLY!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import warnings\n",
    "import os\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "from openpyxl.styles import PatternFill, Font, Alignment, Border, Side\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create output directory\n",
    "output_dir = \"fic_results_ALL_METRICS_EXCEL\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Also create PDF subdirectory\n",
    "pdf_dir = os.path.join(output_dir, \"PDF_plots\")\n",
    "os.makedirs(pdf_dir, exist_ok=True)\n",
    "\n",
    "# Create Excel subdirectory\n",
    "excel_dir = os.path.join(output_dir, \"Excel_results\")\n",
    "os.makedirs(excel_dir, exist_ok=True)\n",
    "\n",
    "# Set style for publication quality\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Global font settings for consistency\n",
    "plt.rcParams.update({\n",
    "    'font.size': 12,\n",
    "    'axes.titlesize': 16,\n",
    "    'axes.labelsize': 14,\n",
    "    'xtick.labelsize': 12,\n",
    "    'ytick.labelsize': 12,\n",
    "    'legend.fontsize': 12,\n",
    "})\n",
    "\n",
    "# ============================================\n",
    "# 1. DATA SIMULATION\n",
    "# ============================================\n",
    "\n",
    "def generate_healthcare_data(n=5000):\n",
    "    \"\"\"\n",
    "    Generate healthcare data for depression diagnosis\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Gender distribution with realistic proportions\n",
    "    gender = np.random.choice(['Male', 'Female', 'Non-binary'], \n",
    "                             size=n, \n",
    "                             p=[0.455, 0.449, 0.096])\n",
    "    \n",
    "    # Age and income with realistic distributions\n",
    "    age = np.clip(np.random.normal(loc=45, scale=15, size=n), 18, 85)\n",
    "    income = np.clip(np.random.lognormal(mean=10.5, sigma=0.8, size=n), \n",
    "                    20000, 200000)\n",
    "    \n",
    "    # Demographic variables\n",
    "    marital_status = np.random.choice(['Single', 'Married', 'Divorced', 'Widowed'], \n",
    "                                     size=n, \n",
    "                                     p=[0.3, 0.4, 0.2, 0.1])\n",
    "    \n",
    "    immigration_status = np.random.choice(['Citizen', 'Immigrant', 'Refugee'], \n",
    "                                         size=n, \n",
    "                                         p=[0.7, 0.25, 0.05])\n",
    "    \n",
    "    education = np.random.choice(['High School', 'College', 'Bachelor', 'Master', 'PhD'], \n",
    "                                size=n, \n",
    "                                p=[0.2, 0.3, 0.3, 0.15, 0.05])\n",
    "    \n",
    "    job_status = np.random.choice(['Employed', 'Unemployed', 'Student', 'Retired'], \n",
    "                                 size=n, \n",
    "                                 p=[0.6, 0.15, 0.15, 0.1])\n",
    "\n",
    "    # Generate depression probabilities with realistic biases\n",
    "    depression_prob = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        base = 0.15 if gender[i] == 'Male' else 0.20 if gender[i] == 'Female' else 0.35\n",
    "        \n",
    "        prob = base\n",
    "        if job_status[i] == 'Unemployed': \n",
    "            prob += 0.20\n",
    "        if income[i] < 30000: \n",
    "            prob += 0.15\n",
    "        if age[i] < 25 or age[i] > 65: \n",
    "            prob += 0.10\n",
    "        \n",
    "        depression_prob[i] = np.clip(prob, 0, 0.95)\n",
    "    \n",
    "    # Generate binary depression outcome\n",
    "    depression = np.random.binomial(1, depression_prob)\n",
    "\n",
    "    # Create DataFrame\n",
    "    data = pd.DataFrame({\n",
    "        'age': age, \n",
    "        'income': income, \n",
    "        'marital_status': marital_status,\n",
    "        'immigration_status': immigration_status, \n",
    "        'education': education,\n",
    "        'job_status': job_status, \n",
    "        'gender': gender, \n",
    "        'depression': depression\n",
    "    })\n",
    "    \n",
    "    print(f\"Generated healthcare data: {len(data)} samples\")\n",
    "    print(f\"Depression prevalence: {depression.mean():.3f}\")\n",
    "    print(f\"Gender distribution:\")\n",
    "    print(data['gender'].value_counts(normalize=True).round(3))\n",
    "    \n",
    "    return data\n",
    "\n",
    "def generate_criminal_justice_data(n=8000):\n",
    "    \"\"\"\n",
    "    Generate criminal justice data for recidivism risk prediction\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Region distribution\n",
    "    regions = ['Africa', 'EU', 'South America', 'North America', \n",
    "               'Arab/Middle East', 'Asia', 'Oceania']\n",
    "    region_weights = [0.20, 0.25, 0.15, 0.10, 0.10, 0.15, 0.05]\n",
    "    region = np.random.choice(regions, size=n, p=region_weights)\n",
    "    \n",
    "    # Demographic variables\n",
    "    gender = np.random.choice(['Male', 'Female'], size=n, p=[0.7, 0.3])\n",
    "    age = np.clip(np.random.normal(loc=35, scale=12, size=n), 18, 70)\n",
    "    income = np.clip(np.random.lognormal(mean=10.0, sigma=0.9, size=n), \n",
    "                    15000, 150000)\n",
    "    \n",
    "    prior_convictions = np.clip(np.random.poisson(lam=1.5, size=n), 0, 10)\n",
    "    \n",
    "    education = np.random.choice(['Less than HS', 'High School', 'Some College', \n",
    "                                 'College', 'Graduate'], \n",
    "                                size=n, \n",
    "                                p=[0.1, 0.3, 0.25, 0.25, 0.1])\n",
    "    \n",
    "    employment = np.random.choice(['Employed', 'Unemployed', 'Student', 'Other'], \n",
    "                                 size=n, \n",
    "                                 p=[0.5, 0.25, 0.15, 0.1])\n",
    "    \n",
    "    asylum_seeker = np.random.choice([0, 1], size=n, p=[0.85, 0.15])\n",
    "\n",
    "    # Generate high-risk probabilities with regional biases\n",
    "    high_risk_prob = np.zeros(n)\n",
    "    base_rates = {\n",
    "        'Africa': 0.25, \n",
    "        'EU': 0.10, \n",
    "        'South America': 0.20, \n",
    "        'North America': 0.15,\n",
    "        'Arab/Middle East': 0.22, \n",
    "        'Asia': 0.18, \n",
    "        'Oceania': 0.12\n",
    "    }\n",
    "    \n",
    "    for i in range(n):\n",
    "        base = base_rates[region[i]]\n",
    "        prob = base\n",
    "        if asylum_seeker[i] == 1: \n",
    "            prob += 0.15\n",
    "        if employment[i] == 'Unemployed': \n",
    "            prob += 0.12\n",
    "        if prior_convictions[i] > 3: \n",
    "            prob += 0.10\n",
    "        \n",
    "        high_risk_prob[i] = np.clip(prob, 0, 0.95)\n",
    "    \n",
    "    # Generate binary high-risk outcome\n",
    "    high_risk = np.random.binomial(1, high_risk_prob)\n",
    "\n",
    "    # Create DataFrame\n",
    "    data = pd.DataFrame({\n",
    "        'gender': gender, \n",
    "        'age': age, \n",
    "        'income': income, \n",
    "        'prior_convictions': prior_convictions,\n",
    "        'education': education, \n",
    "        'employment': employment, \n",
    "        'asylum_seeker': asylum_seeker,\n",
    "        'region': region, \n",
    "        'high_risk': high_risk\n",
    "    })\n",
    "    \n",
    "    print(f\"Generated criminal justice data: {len(data)} samples\")\n",
    "    print(f\"High risk prevalence: {high_risk.mean():.3f}\")\n",
    "    print(f\"Region distribution:\")\n",
    "    print(data['region'].value_counts(normalize=True).round(3))\n",
    "    \n",
    "    return data\n",
    "\n",
    "# ============================================\n",
    "# 2-3. MODEL & FIC\n",
    "# ============================================\n",
    "\n",
    "def compute_all_metrics(y_true, y_pred, y_prob):\n",
    "    \"\"\"\n",
    "    Compute comprehensive performance metrics\n",
    "    \"\"\"\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    \n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_true, y_pred),\n",
    "        'selection_rate': (tp + fp) / len(y_true),\n",
    "        'tpr': tp / (tp + fn) if (tp + fn) > 0 else 0,\n",
    "        'tnr': tn / (tn + fp) if (tn + fp) > 0 else 0,\n",
    "        'fpr': fp / (fp + tn) if (fp + tn) > 0 else 0,\n",
    "        'fnr': fn / (tp + fn) if (tp + fn) > 0 else 0,\n",
    "        'ppv': tp / (tp + fp) if (tp + fp) > 0 else 0,\n",
    "        'npv': tn / (tn + fn) if (tn + fn) > 0 else 0,\n",
    "        'f1': f1_score(y_true, y_pred),\n",
    "        'auc': roc_auc_score(y_true, y_prob) if len(np.unique(y_true)) > 1 else np.nan\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "def train_and_evaluate_models(data, target_col, protected_col, model_type='baseline'):\n",
    "    \"\"\"\n",
    "    Train and evaluate logistic regression models\n",
    "    \"\"\"\n",
    "    X = data.drop(columns=[target_col, protected_col])\n",
    "    y = data[target_col]\n",
    "    \n",
    "    categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "    numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "    # Preprocessing pipeline\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(drop='first'), categorical_cols)\n",
    "    ])\n",
    "\n",
    "    # Train-test split with stratification\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=42, stratify=y\n",
    "    )\n",
    "    protected_test = data.loc[X_test.index, protected_col]\n",
    "\n",
    "    # Preprocess data\n",
    "    X_train_processed = preprocessor.fit_transform(X_train)\n",
    "    X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "    # Model selection\n",
    "    if model_type == 'baseline':\n",
    "        model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "    elif model_type == 'l1':\n",
    "        model = LogisticRegression(penalty='l1', solver='liblinear', \n",
    "                                  random_state=42, max_iter=1000, C=1.0)\n",
    "    elif model_type == 'l2':\n",
    "        model = LogisticRegression(penalty='l2', random_state=42, \n",
    "                                  max_iter=1000, C=1.0)\n",
    "    else:\n",
    "        model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "    # Train model\n",
    "    model.fit(X_train_processed, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test_processed)\n",
    "    y_prob = model.predict_proba(X_test_processed)[:, 1]\n",
    "\n",
    "    # Compute group-wise metrics\n",
    "    group_metrics = {}\n",
    "    for group in protected_test.unique():\n",
    "        mask = protected_test == group\n",
    "        if mask.sum() > 0:\n",
    "            group_metrics[group] = compute_all_metrics(\n",
    "                y_test[mask], y_pred[mask], y_prob[mask]\n",
    "            )\n",
    "\n",
    "    return group_metrics, (X_test, y_test, protected_test, y_pred, y_prob)\n",
    "\n",
    "class FairnessInformationCriterion:\n",
    "    \"\"\"\n",
    "    Fairness Information Criterion (FIC) framework\n",
    "    \"\"\"\n",
    "    def __init__(self, alphaF_values=[0.05, 0.10, 0.15, 0.20]):\n",
    "        self.alphaF_values = alphaF_values\n",
    "\n",
    "    def compute_omega(self, metric1, metric2):\n",
    "        \"\"\"Compute unfairness magnitude (ω)\"\"\"\n",
    "        return abs(metric1 - metric2)\n",
    "\n",
    "    def compute_fic(self, omega, alphaF):\n",
    "        \"\"\"Compute FIC score\"\"\"\n",
    "        return 1 - (omega / alphaF)\n",
    "\n",
    "    def classify_tier(self, fic_score):\n",
    "        \"\"\"Classify FIC score into fairness tiers\"\"\"\n",
    "        if fic_score > 0.75:\n",
    "            return \"Optimum\"\n",
    "        elif fic_score > 0.50:\n",
    "            return \"Acceptable\"\n",
    "        elif fic_score > 0:\n",
    "            return \"Questionable\"\n",
    "        else:\n",
    "            return \"Unacceptable\"\n",
    "\n",
    "    def analyze_fairness(self, group_metrics, metric_name='accuracy'):\n",
    "        \"\"\"\n",
    "        Analyze fairness across all group pairs for all alphaF values\n",
    "        \"\"\"\n",
    "        results = {}\n",
    "        groups = list(group_metrics.keys())\n",
    "        \n",
    "        for alphaF in self.alphaF_values:\n",
    "            results[alphaF] = {}\n",
    "            for i, g1 in enumerate(groups):\n",
    "                for g2 in groups[i+1:]:\n",
    "                    pair = f\"{g1} - {g2}\"\n",
    "                    m1 = group_metrics[g1].get(metric_name, np.nan)\n",
    "                    m2 = group_metrics[g2].get(metric_name, np.nan)\n",
    "                    \n",
    "                    if not np.isnan(m1) and not np.isnan(m2):\n",
    "                        omega = self.compute_omega(m1, m2)\n",
    "                        fic_score = self.compute_fic(omega, alphaF)\n",
    "                        tier = self.classify_tier(fic_score)\n",
    "                        \n",
    "                        results[alphaF][pair] = {\n",
    "                            'omega': omega, \n",
    "                            'fic_score': fic_score, \n",
    "                            'tier': tier,\n",
    "                            'metric1': m1, \n",
    "                            'metric2': m2\n",
    "                        }\n",
    "        return results\n",
    "\n",
    "# ============================================\n",
    "# 4. EXCEL EXPORT FUNCTIONS\n",
    "# ============================================\n",
    "\n",
    "def save_to_excel_with_formatting(data_dict, filename, sheet_name_prefix=\"\"):\n",
    "    \"\"\"\n",
    "    Save multiple dataframes to Excel with formatting\n",
    "    \"\"\"\n",
    "    excel_path = os.path.join(excel_dir, filename)\n",
    "    \n",
    "    with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:\n",
    "        # Save each dataframe to a separate sheet\n",
    "        for sheet_name, df in data_dict.items():\n",
    "            # Create full sheet name\n",
    "            full_sheet_name = f\"{sheet_name_prefix}_{sheet_name}\" if sheet_name_prefix else sheet_name\n",
    "            \n",
    "            # Truncate sheet name if too long (Excel limit is 31 characters)\n",
    "            if len(full_sheet_name) > 31:\n",
    "                full_sheet_name = full_sheet_name[:31]\n",
    "            \n",
    "            # Write dataframe to Excel\n",
    "            df.to_excel(writer, sheet_name=full_sheet_name, index=False)\n",
    "            \n",
    "            # Get the worksheet for formatting\n",
    "            worksheet = writer.sheets[full_sheet_name]\n",
    "            \n",
    "            # Apply formatting\n",
    "            for column in worksheet.columns:\n",
    "                max_length = 0\n",
    "                column_letter = column[0].column_letter\n",
    "                for cell in column:\n",
    "                    try:\n",
    "                        if len(str(cell.value)) > max_length:\n",
    "                            max_length = len(str(cell.value))\n",
    "                    except:\n",
    "                        pass\n",
    "                adjusted_width = min(max_length + 2, 50)\n",
    "                worksheet.column_dimensions[column_letter].width = adjusted_width\n",
    "            \n",
    "            # Freeze the first row\n",
    "            worksheet.freeze_panes = 'A2'\n",
    "    \n",
    "    print(f\"  ✓ Excel file saved: {filename}\")\n",
    "    return excel_path\n",
    "\n",
    "def create_comprehensive_excel_report(results_dict, case_name, case_number, metrics_list):\n",
    "    \"\"\"\n",
    "    Create a comprehensive Excel report with all numerical values\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"CREATING COMPREHENSIVE EXCEL REPORT FOR {case_name.upper()}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    data_dict = {}\n",
    "    \n",
    "    # Extract results\n",
    "    baseline_metrics = results_dict['baseline_metrics']\n",
    "    all_fic_results = results_dict['all_fic_results']\n",
    "    data = results_dict['data']\n",
    "    \n",
    "    # 1. Group Metrics Table\n",
    "    print(\"1. Saving Group Metrics Table...\")\n",
    "    metrics_df = pd.DataFrame.from_dict(baseline_metrics, orient='index')\n",
    "    metrics_df = metrics_df[['accuracy', 'selection_rate', 'tpr', 'tnr', 'fpr', 'fnr', 'ppv', 'npv', 'f1', 'auc']]\n",
    "    data_dict['Group_Metrics'] = metrics_df.reset_index().rename(columns={'index': 'Protected_Group'})\n",
    "    \n",
    "    # 2. FIC Analysis Tables for all metrics\n",
    "    print(\"2. Saving FIC Analysis Tables for all metrics...\")\n",
    "    for metric in metrics_list:\n",
    "        if metric in all_fic_results:\n",
    "            fic_results = all_fic_results[metric]\n",
    "            \n",
    "            # Create comprehensive FIC table for this metric\n",
    "            fic_table = []\n",
    "            pairs = list(set(p for a in fic_results.values() for p in a.keys()))\n",
    "            \n",
    "            for pair in sorted(pairs):\n",
    "                row = {'Group_Pair': pair}\n",
    "                for af in [0.05, 0.10, 0.15, 0.20]:\n",
    "                    if af in fic_results and pair in fic_results[af]:\n",
    "                        d = fic_results[af][pair]\n",
    "                        row[f'omega_alphaF_{af}'] = d['omega']\n",
    "                        row[f'FIC_alphaF_{af}'] = d['fic_score']\n",
    "                        row[f'Tier_alphaF_{af}'] = d['tier']\n",
    "                        row[f'Metric1_{af}'] = d['metric1']\n",
    "                        row[f'Metric2_{af}'] = d['metric2']\n",
    "                    else:\n",
    "                        row[f'omega_alphaF_{af}'] = np.nan\n",
    "                        row[f'FIC_alphaF_{af}'] = np.nan\n",
    "                        row[f'Tier_alphaF_{af}'] = \"N/A\"\n",
    "                        row[f'Metric1_{af}'] = np.nan\n",
    "                        row[f'Metric2_{af}'] = np.nan\n",
    "                fic_table.append(row)\n",
    "            \n",
    "            if fic_table:\n",
    "                fic_df = pd.DataFrame(fic_table)\n",
    "                data_dict[f'FIC_Analysis_{metric}'] = fic_df\n",
    "    \n",
    "    # 3. Tier Classification Summary for all metrics\n",
    "    print(\"3. Saving Tier Classification Summary for all metrics...\")\n",
    "    for metric in metrics_list:\n",
    "        if metric in all_fic_results:\n",
    "            fic_results = all_fic_results[metric]\n",
    "            \n",
    "            tier_summary = []\n",
    "            for af in [0.05, 0.10, 0.15, 0.20]:\n",
    "                if af in fic_results and fic_results[af]:\n",
    "                    tiers = {'Optimum': 0, 'Acceptable': 0, 'Questionable': 0, 'Unacceptable': 0}\n",
    "                    fic_framework = FairnessInformationCriterion()\n",
    "                    for d in fic_results[af].values():\n",
    "                        tiers[fic_framework.classify_tier(d['fic_score'])] += 1\n",
    "                    \n",
    "                    total_pairs = sum(tiers.values())\n",
    "                    for tier_name, count in tiers.items():\n",
    "                        tier_summary.append({\n",
    "                            'Metric': metric,\n",
    "                            'alphaF': af,\n",
    "                            'Tier': tier_name,\n",
    "                            'Count': count,\n",
    "                            'Percentage': (count / total_pairs * 100) if total_pairs > 0 else 0\n",
    "                        })\n",
    "            \n",
    "            if tier_summary:\n",
    "                tier_summary_df = pd.DataFrame(tier_summary)\n",
    "                data_dict[f'Tier_Summary_{metric}'] = tier_summary_df\n",
    "    \n",
    "    # 4. Benchmarking Tiers Numerical Values\n",
    "    print(\"4. Saving Benchmarking Tiers Numerical Values...\")\n",
    "    for metric in metrics_list:\n",
    "        if metric in all_fic_results:\n",
    "            fic_results = all_fic_results[metric]\n",
    "            \n",
    "            benchmark_data = []\n",
    "            for af in [0.05, 0.10, 0.15, 0.20]:\n",
    "                if af in fic_results and fic_results[af]:\n",
    "                    for pair, d in fic_results[af].items():\n",
    "                        benchmark_data.append({\n",
    "                            'Metric': metric,\n",
    "                            'alphaF': af,\n",
    "                            'Group_Pair': pair,\n",
    "                            'FIC_Score': d['fic_score'],\n",
    "                            'Tier': d['tier'],\n",
    "                            'omega': d['omega'],\n",
    "                            'Metric_Value_Group1': d['metric1'],\n",
    "                            'Metric_Value_Group2': d['metric2']\n",
    "                        })\n",
    "            \n",
    "            if benchmark_data:\n",
    "                benchmark_df = pd.DataFrame(benchmark_data)\n",
    "                data_dict[f'Benchmark_Tiers_{metric}'] = benchmark_df\n",
    "    \n",
    "    # 5. Summary Statistics for each metric\n",
    "    print(\"5. Saving Summary Statistics for each metric...\")\n",
    "    summary_stats = []\n",
    "    for metric in metrics_list:\n",
    "        if metric in all_fic_results:\n",
    "            fic_results = all_fic_results[metric]\n",
    "            \n",
    "            for af in [0.05, 0.10, 0.15, 0.20]:\n",
    "                if af in fic_results and fic_results[af]:\n",
    "                    fic_scores = [d['fic_score'] for d in fic_results[af].values()]\n",
    "                    omegas = [d['omega'] for d in fic_results[af].values()]\n",
    "                    \n",
    "                    summary_stats.append({\n",
    "                        'Metric': metric,\n",
    "                        'alphaF': af,\n",
    "                        'FIC_Mean': np.mean(fic_scores),\n",
    "                        'FIC_Std': np.std(fic_scores),\n",
    "                        'FIC_Min': np.min(fic_scores),\n",
    "                        'FIC_Max': np.max(fic_scores),\n",
    "                        'omega_Mean': np.mean(omegas),\n",
    "                        'omega_Std': np.std(omegas),\n",
    "                        'omega_Min': np.min(omegas),\n",
    "                        'omega_Max': np.max(omegas),\n",
    "                        'Num_Pairs': len(fic_scores)\n",
    "                    })\n",
    "    \n",
    "    if summary_stats:\n",
    "        summary_df = pd.DataFrame(summary_stats)\n",
    "        data_dict['Summary_Statistics'] = summary_df\n",
    "    \n",
    "    # 6. Model Comparison\n",
    "    print(\"6. Saving Model Comparison...\")\n",
    "    if 'comparison_df' in results_dict:\n",
    "        data_dict['Model_Comparison'] = results_dict['comparison_df']\n",
    "    \n",
    "    # 7. Dataset Statistics\n",
    "    print(\"7. Saving Dataset Statistics...\")\n",
    "    dataset_stats_data = []\n",
    "    \n",
    "    # Basic statistics\n",
    "    dataset_stats_data.append({\n",
    "        'Statistic': 'Total_Samples',\n",
    "        'Value': len(data)\n",
    "    })\n",
    "    \n",
    "    # Target variable statistics\n",
    "    target_col = 'depression' if 'depression' in data.columns else 'high_risk'\n",
    "    dataset_stats_data.append({\n",
    "        'Statistic': f'{target_col.capitalize()}_Prevalence',\n",
    "        'Value': data[target_col].mean()\n",
    "    })\n",
    "    \n",
    "    # Protected attribute statistics\n",
    "    protected_col = 'gender' if 'gender' in data.columns else 'region'\n",
    "    for group in data[protected_col].unique():\n",
    "        count = (data[protected_col] == group).sum()\n",
    "        proportion = count / len(data)\n",
    "        dataset_stats_data.append({\n",
    "            'Statistic': f'{protected_col.capitalize()}_{group}_Count',\n",
    "            'Value': count\n",
    "        })\n",
    "        dataset_stats_data.append({\n",
    "            'Statistic': f'{protected_col.capitalize()}_{group}_Proportion',\n",
    "            'Value': proportion\n",
    "        })\n",
    "    \n",
    "    dataset_stats_df = pd.DataFrame(dataset_stats_data)\n",
    "    data_dict['Dataset_Statistics'] = dataset_stats_df\n",
    "    \n",
    "    # 8. Fairness Assessment Matrix\n",
    "    print(\"8. Creating Fairness Assessment Matrix...\")\n",
    "    fairness_matrix = []\n",
    "    for metric in metrics_list:\n",
    "        if metric in all_fic_results:\n",
    "            fic_results = all_fic_results[metric]\n",
    "            \n",
    "            for af in [0.05, 0.10, 0.15, 0.20]:\n",
    "                if af in fic_results and fic_results[af]:\n",
    "                    # Count pairs in each tier\n",
    "                    fic_framework = FairnessInformationCriterion()\n",
    "                    tiers = {'Optimum': 0, 'Acceptable': 0, 'Questionable': 0, 'Unacceptable': 0}\n",
    "                    for d in fic_results[af].values():\n",
    "                        tiers[fic_framework.classify_tier(d['fic_score'])] += 1\n",
    "                    \n",
    "                    # Determine overall fairness status\n",
    "                    if tiers['Unacceptable'] > 0:\n",
    "                        overall_status = \"Unfair\"\n",
    "                    elif tiers['Questionable'] > 0:\n",
    "                        overall_status = \"Questionable\"\n",
    "                    elif tiers['Acceptable'] > 0:\n",
    "                        overall_status = \"Acceptable\"\n",
    "                    else:\n",
    "                        overall_status = \"Optimum\"\n",
    "                    \n",
    "                    fairness_matrix.append({\n",
    "                        'Metric': metric,\n",
    "                        'alphaF': af,\n",
    "                        'Overall_Fairness': overall_status,\n",
    "                        'Optimum_Pairs': tiers['Optimum'],\n",
    "                        'Acceptable_Pairs': tiers['Acceptable'],\n",
    "                        'Questionable_Pairs': tiers['Questionable'],\n",
    "                        'Unacceptable_Pairs': tiers['Unacceptable'],\n",
    "                        'Total_Pairs': sum(tiers.values())\n",
    "                    })\n",
    "    \n",
    "    if fairness_matrix:\n",
    "        fairness_df = pd.DataFrame(fairness_matrix)\n",
    "        data_dict['Fairness_Assessment'] = fairness_df\n",
    "    \n",
    "    # Save all to Excel\n",
    "    excel_filename = f\"{case_name.replace(' ', '_')}_FIC_Complete_Analysis.xlsx\"\n",
    "    excel_file = save_to_excel_with_formatting(data_dict, excel_filename, f\"Case{case_number}\")\n",
    "    \n",
    "    print(f\"\\n✓ Excel report saved: {excel_file}\")\n",
    "    print(f\"  Total sheets: {len(data_dict)}\")\n",
    "    \n",
    "    # Print sheet names\n",
    "    print(\"\\nExcel sheets created:\")\n",
    "    for i, sheet_name in enumerate(data_dict.keys(), 1):\n",
    "        print(f\"  {i:2d}. {sheet_name}\")\n",
    "    \n",
    "    return excel_file\n",
    "\n",
    "# ============================================\n",
    "# 5. VISUALIZATIONS - UPDATED FOR PDF AND EXPANDED LEGEND\n",
    "# ============================================\n",
    "\n",
    "def plot_fic_heatmaps(fic_results, dataset_name, metric='accuracy'):\n",
    "    \"\"\"\n",
    "    Create FIC heatmaps for all alphaF values\n",
    "    \"\"\"\n",
    "    alphaF_values = sorted(fic_results.keys())\n",
    "    if not alphaF_values:\n",
    "        return\n",
    "\n",
    "    pairs = list(fic_results[alphaF_values[0]].keys())\n",
    "    all_groups = sorted(set(g for p in pairs for g in p.split(' - ')))\n",
    "\n",
    "    # Larger figure\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(20, 16))\n",
    "    fig.suptitle(f'{dataset_name}: FIC Heatmaps for Different αF Values ({metric})',\n",
    "                 fontsize=20, fontweight='bold', y=0.98)\n",
    "\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for idx, alphaF in enumerate(alphaF_values):\n",
    "        ax = axes[idx]\n",
    "        n = len(all_groups)\n",
    "        mat = np.full((n, n), np.nan)\n",
    "        group_idx = {g: i for i, g in enumerate(all_groups)}\n",
    "\n",
    "        # Fill matrix with FIC scores\n",
    "        for pair, d in fic_results[alphaF].items():\n",
    "            g1, g2 = pair.split(' - ')\n",
    "            i, j = group_idx[g1], group_idx[g2]\n",
    "            mat[i, j] = mat[j, i] = d['fic_score']\n",
    "\n",
    "        # Create heatmap\n",
    "        im = ax.imshow(mat, cmap='RdYlGn', vmin=-1, vmax=1, aspect='equal')\n",
    "\n",
    "        # Add value labels inside cells\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                if i != j and not np.isnan(mat[i, j]):\n",
    "                    text = ax.text(j, i, f'{mat[i,j]:.2f}',\n",
    "                                   ha='center', va='center',\n",
    "                                   fontsize=14, fontweight='bold',\n",
    "                                   color='white' if abs(mat[i,j]) > 0.5 else 'black')\n",
    "\n",
    "        # Customize axes\n",
    "        ax.set_xticks(range(n))\n",
    "        ax.set_yticks(range(n))\n",
    "        ax.set_xticklabels(all_groups, rotation=45, ha='right', fontsize=13, fontweight='bold')\n",
    "        ax.set_yticklabels(all_groups, fontsize=13, fontweight='bold')\n",
    "        ax.set_title(f'αF = {alphaF}', fontsize=18, fontweight='bold', pad=20)\n",
    "        \n",
    "        # Add grid\n",
    "        ax.set_xticks(np.arange(-.5, n, 1), minor=True)\n",
    "        ax.set_yticks(np.arange(-.5, n, 1), minor=True)\n",
    "        ax.grid(which='minor', color='gray', linestyle='-', linewidth=0.5, alpha=0.3)\n",
    "\n",
    "    # Add comprehensive colorbar with tier labels\n",
    "    cbar_ax = fig.add_axes([0.78, 0.15, 0.02, 0.7])\n",
    "    cbar = fig.colorbar(im, cax=cbar_ax)\n",
    "    cbar.set_label('FIC Score', fontsize=14, fontweight='bold', labelpad=15)\n",
    "    cbar.ax.tick_params(labelsize=12)\n",
    "    \n",
    "    # Bold colorbar tick labels\n",
    "    for label in cbar.ax.get_yticklabels():\n",
    "        label.set_fontweight('bold')\n",
    "    \n",
    "    # Add tier annotations on colorbar\n",
    "    cbar.ax.text(1.6, 0.90, 'Optimum', transform=cbar.ax.transAxes, \n",
    "                 fontsize=14, fontweight='bold', va='center', ha='left', color='darkgreen')\n",
    "    cbar.ax.text(1.6, 0.60, 'Acceptable', transform=cbar.ax.transAxes, \n",
    "                 fontsize=14, fontweight='bold', va='center', ha='left', color='goldenrod')\n",
    "    cbar.ax.text(1.6, 0.350, 'Questionable', transform=cbar.ax.transAxes, \n",
    "                 fontsize=14, fontweight='bold', va='center', ha='left', color='darkorange')\n",
    "    cbar.ax.text(1.6, 0.100, 'Unacceptable', transform=cbar.ax.transAxes, \n",
    "                 fontsize=14, fontweight='bold', va='center', ha='left', color='darkred')\n",
    "    \n",
    "    # Add tier threshold lines on colorbar\n",
    "    cbar.ax.axhline(0.75, color='darkgreen', linestyle='--', linewidth=3, xmax=0.6)\n",
    "    cbar.ax.axhline(0.50, color='goldenrod', linestyle='--', linewidth=3, xmax=0.6)\n",
    "    cbar.ax.axhline(0.00, color='darkred', linestyle='--', linewidth=3, xmax=0.6)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 0.78, 0.95])\n",
    "    \n",
    "    # Save as PNG and PDF\n",
    "    plt.savefig(os.path.join(output_dir, f'{dataset_name}_FIC_Heatmaps_{metric}.png'), \n",
    "                dpi=400, bbox_inches='tight')\n",
    "    plt.savefig(os.path.join(pdf_dir, f'{dataset_name}_FIC_Heatmaps_{metric}.pdf'), \n",
    "                format='pdf', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_benchmarking_tiers(fic_results, dataset_name, metric='accuracy'):\n",
    "    \"\"\"\n",
    "    Create benchmarking tier plots for each alphaF value\n",
    "    \"\"\"\n",
    "    alphaF_values = sorted(fic_results.keys())\n",
    "    \n",
    "    # Define colors for tiers\n",
    "    colors = {\n",
    "        'Optimum': '#2E8B57', \n",
    "        'Acceptable': '#FFD700', \n",
    "        'Questionable': '#FF8C00', \n",
    "        'Unacceptable': '#DC143C'\n",
    "    }\n",
    "    \n",
    "    for alphaF in alphaF_values:\n",
    "        if alphaF not in fic_results or not fic_results[alphaF]:\n",
    "            continue\n",
    "        \n",
    "        # Create figure with expanded width for legend\n",
    "        fig, ax = plt.subplots(figsize=(20, 8))\n",
    "        \n",
    "        data = fic_results[alphaF]\n",
    "        pairs = list(data.keys())\n",
    "        fic_scores = [data[p]['fic_score'] for p in pairs]\n",
    "        tiers = [data[p]['tier'] for p in pairs]\n",
    "        \n",
    "        # Find dynamic y-axis limits\n",
    "        max_positive = max(fic_scores) if fic_scores else 1.0\n",
    "        min_negative = min(fic_scores) if fic_scores else -0.25\n",
    "        \n",
    "        # Add padding\n",
    "        y_max = max_positive * 1.10 if max_positive > 0 else 0.10\n",
    "        y_min = min_negative * 1.10 if min_negative < 0 else -0.10\n",
    "        \n",
    "        # Ensure minimum range\n",
    "        if y_max - y_min < 0.5:\n",
    "            center = (max_positive + min_negative) / 2\n",
    "            y_max = center + 0.25\n",
    "            y_min = center - 0.25\n",
    "        \n",
    "        # Create bars\n",
    "        bar_colors = [colors[t] for t in tiers]\n",
    "        bars = ax.bar(range(len(pairs)), fic_scores, color=bar_colors, \n",
    "                      edgecolor='black', linewidth=1.2, width=0.6)\n",
    "        \n",
    "        # Add tier threshold lines\n",
    "        ax.axhline(0.75, color='darkgreen', linestyle='--', linewidth=2.0, alpha=0.7)\n",
    "        ax.axhline(0.50, color='goldenrod', linestyle='--', linewidth=2.0, alpha=0.7)\n",
    "        ax.axhline(0.00, color='darkred', linestyle='--', linewidth=2.0, alpha=0.7)\n",
    "        \n",
    "        # Customize axes\n",
    "        ax.set_xlabel('Inter-Group', fontsize=14, fontweight='bold', labelpad=10)\n",
    "        ax.set_ylabel('FIC Score', fontsize=14, fontweight='bold', labelpad=10)\n",
    "        ax.set_title(f'{dataset_name}\\nFIC Benchmarking Tiers ({metric}, αF = {alphaF})',\n",
    "                    fontsize=16, fontweight='bold', pad=15)\n",
    "        \n",
    "        # Set x-ticks\n",
    "        ax.set_xticks(range(len(pairs)))\n",
    "        ax.set_xticklabels(pairs, rotation=45, ha='right', fontsize=11, fontweight='bold')\n",
    "        \n",
    "        # Set y-axis limits\n",
    "        ax.set_ylim(y_min, y_max)\n",
    "        \n",
    "        # Format y-tick labels\n",
    "        y_ticks = ax.get_yticks()\n",
    "        ax.set_yticklabels([f'{tick:.2f}' for tick in y_ticks], fontsize=11, fontweight='bold')\n",
    "        \n",
    "        # Add grid\n",
    "        ax.grid(True, axis='y', alpha=0.3, linestyle='-', linewidth=0.5)\n",
    "        \n",
    "        # Create tier legend\n",
    "        from matplotlib.patches import Patch\n",
    "        legend_elements = [\n",
    "            Patch(facecolor=colors['Optimum'], edgecolor='black', \n",
    "                  label='Optimum (FIC > 0.75)'),\n",
    "            Patch(facecolor=colors['Acceptable'], edgecolor='black', \n",
    "                  label='Acceptable (0.50 < FIC ≤ 0.75)'),\n",
    "            Patch(facecolor=colors['Questionable'], edgecolor='black', \n",
    "                  label='Questionable (0 < FIC ≤ 0.50)'),\n",
    "            Patch(facecolor=colors['Unacceptable'], edgecolor='black', \n",
    "                  label='Unacceptable (FIC ≤ 0)')\n",
    "        ]\n",
    "        \n",
    "        # Create threshold line legend\n",
    "        from matplotlib.lines import Line2D\n",
    "        line_legend_elements = [\n",
    "            Line2D([0], [0], color='darkgreen', linestyle='--', linewidth=2, \n",
    "                   label='Optimum Threshold (0.75)'),\n",
    "            Line2D([0], [0], color='goldenrod', linestyle='--', linewidth=2, \n",
    "                   label='Acceptable Threshold (0.50)'),\n",
    "            Line2D([0], [0], color='darkred', linestyle='--', linewidth=2, \n",
    "                   label='Unacceptable Threshold (0.00)')\n",
    "        ]\n",
    "        \n",
    "        # Place tier legend\n",
    "        tier_legend = ax.legend(handles=legend_elements, fontsize=10, \n",
    "                                loc='upper left', bbox_to_anchor=(1.05, 1.0),\n",
    "                                frameon=True, framealpha=0.9, edgecolor='black',\n",
    "                                title='FIC Tiers', title_fontsize=11)\n",
    "        tier_legend.get_title().set_fontweight('bold')\n",
    "        ax.add_artist(tier_legend)\n",
    "        \n",
    "        # Place threshold legend\n",
    "        threshold_legend = ax.legend(handles=line_legend_elements, fontsize=9, \n",
    "                                     loc='upper left', bbox_to_anchor=(1.05, 0.65),\n",
    "                                     frameon=True, framealpha=0.9, edgecolor='black',\n",
    "                                     title='Thresholds', title_fontsize=10)\n",
    "        threshold_legend.get_title().set_fontweight('bold')\n",
    "        \n",
    "        # Add annotation for alphaF interpretation\n",
    "        annotation_text = f'αF = {alphaF}\\nFIC = 1 - (ω/αF)\\nω = |M₁ - M₂|'\n",
    "        ax.text(0.02, 0.98, annotation_text, transform=ax.transAxes,\n",
    "                fontsize=9, verticalalignment='top', fontweight='bold',\n",
    "                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
    "        \n",
    "        # Adjust layout\n",
    "        plt.tight_layout(rect=[0, 0, 0.80, 1])\n",
    "        \n",
    "        # Save figures\n",
    "        png_filename = f'{dataset_name}_Benchmarking_Tiers_alphaF_{alphaF}_{metric}.png'\n",
    "        pdf_filename = f'{dataset_name}_Benchmarking_Tiers_alphaF_{alphaF}_{metric}.pdf'\n",
    "        \n",
    "        plt.savefig(os.path.join(output_dir, png_filename), \n",
    "                    dpi=400, bbox_inches='tight')\n",
    "        plt.savefig(os.path.join(pdf_dir, pdf_filename), \n",
    "                    format='pdf', bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "# ============================================\n",
    "# 6. ANALYSIS FUNCTIONS - UPDATED FOR ALL METRICS\n",
    "# ============================================\n",
    "\n",
    "def analyze_simulated_dataset(dataset_name, data_generator, target_col, protected_col, \n",
    "                            case_number=1, model_types=['baseline', 'l1', 'l2']):\n",
    "    \"\"\"\n",
    "    Complete analysis for a simulated dataset\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"CASE {case_number}: {dataset_name}\")\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "    # Generate data\n",
    "    data = data_generator()\n",
    "    fic_framework = FairnessInformationCriterion()\n",
    "\n",
    "    # Train baseline model\n",
    "    baseline_metrics, _ = train_and_evaluate_models(data, target_col, protected_col, 'baseline')\n",
    "\n",
    "    # Create metrics table\n",
    "    metrics_df = pd.DataFrame.from_dict(baseline_metrics, orient='index')\n",
    "    metrics_df = metrics_df[['accuracy', 'selection_rate', 'tpr', 'tnr', \n",
    "                            'fpr', 'fnr', 'ppv', 'npv', 'f1', 'auc']]\n",
    "    \n",
    "    print(\"GROUP METRICS TABLE (Baseline Logistic Regression):\")\n",
    "    print(metrics_df.round(4).to_string())\n",
    "    \n",
    "    # Save metrics to CSV\n",
    "    metrics_csv_path = os.path.join(output_dir, f'Case{case_number}_{dataset_name.replace(\" \", \"_\")}_Group_Metrics.csv')\n",
    "    metrics_df.to_csv(metrics_csv_path)\n",
    "    print(f\"Group metrics saved to: {metrics_csv_path}\")\n",
    "\n",
    "    print(\"GENERATING VISUALIZATIONS FOR ALL METRICS...\")\n",
    "    \n",
    "    # List of all metrics to analyze\n",
    "    all_metrics = ['accuracy', 'selection_rate', 'tpr', 'tnr', \n",
    "                  'fpr', 'fnr', 'ppv', 'npv', 'f1', 'auc']\n",
    "    \n",
    "    # Dictionary to store all FIC results\n",
    "    all_fic_results = {}\n",
    "    \n",
    "    # Dictionary to store metric summaries\n",
    "    metric_summaries = {}\n",
    "    \n",
    "    for metric in all_metrics:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"ANALYZING METRIC: {metric.upper()}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # Analyze fairness for this metric\n",
    "        fic_results = fic_framework.analyze_fairness(baseline_metrics, metric)\n",
    "        all_fic_results[metric] = fic_results\n",
    "        \n",
    "        # Generate heatmaps for this metric\n",
    "        plot_fic_heatmaps(fic_results, f'Case{case_number}_{dataset_name}_{metric}', metric)\n",
    "        \n",
    "        # Generate benchmarking tiers for this metric\n",
    "        plot_benchmarking_tiers(fic_results, f'Case{case_number}_{dataset_name}_{metric}', metric)\n",
    "        \n",
    "        # Store summary for this metric\n",
    "        metric_summary = {}\n",
    "        for af in fic_framework.alphaF_values:\n",
    "            if af in fic_results and fic_results[af]:\n",
    "                omegas = [d['omega'] for d in fic_results[af].values()]\n",
    "                fic_scores = [d['fic_score'] for d in fic_results[af].values()]\n",
    "                tiers = {'Optimum': 0, 'Acceptable': 0, 'Questionable': 0, 'Unacceptable': 0}\n",
    "                fic = FairnessInformationCriterion()\n",
    "                for d in fic_results[af].values():\n",
    "                    tiers[fic.classify_tier(d['fic_score'])] += 1\n",
    "                \n",
    "                metric_summary[f'alphaF_{af}'] = {\n",
    "                    'omega_max': max(omegas),\n",
    "                    'omega_avg': np.mean(omegas),\n",
    "                    'omega_min': min(omegas),\n",
    "                    'fic_max': max(fic_scores),\n",
    "                    'fic_avg': np.mean(fic_scores),\n",
    "                    'fic_min': min(fic_scores),\n",
    "                    'tiers': tiers\n",
    "                }\n",
    "        \n",
    "        metric_summaries[metric] = metric_summary\n",
    "        \n",
    "        # Print summary for this metric\n",
    "        print(f\"Summary for {metric}:\")\n",
    "        for af in fic_framework.alphaF_values:\n",
    "            if af in metric_summary:\n",
    "                summary = metric_summary[f'alphaF_{af}']\n",
    "                print(f\"  αF={af}: ω_max={summary['omega_max']:.4f}, ω_avg={summary['omega_avg']:.4f}, \"\n",
    "                      f\"FIC_avg={summary['fic_avg']:.3f}, Tiers={summary['tiers']}\")\n",
    "\n",
    "    # Store FIC results for accuracy (original metric)\n",
    "    fic_results = all_fic_results['accuracy']\n",
    "    \n",
    "    # FIC table for accuracy\n",
    "    fic_table = []\n",
    "    for pair in sorted(set(p for a in fic_results.values() for p in a.keys())):\n",
    "        row = {'Group Pair': pair}\n",
    "        for af in fic_framework.alphaF_values:\n",
    "            if af in fic_results and pair in fic_results[af]:\n",
    "                d = fic_results[af][pair]\n",
    "                row[f'alphaF={af}'] = f\"omega={d['omega']:.4f}, FIC={d['fic_score']:.3f}\"\n",
    "                row[f'Hypothesis alphaF={af}'] = \"Fail to reject H₀ (Fair)\" if d['omega'] <= af else \"Reject H₀ (Unfair)\"\n",
    "            else:\n",
    "                row[f'alphaF={af}'] = \"N/A\"\n",
    "                row[f'Hypothesis alphaF={af}'] = \"N/A\"\n",
    "        fic_table.append(row)\n",
    "    \n",
    "    fic_df = pd.DataFrame(fic_table)\n",
    "    print(\"FIC ANALYSIS TABLE (Accuracy):\")\n",
    "    print(fic_df.to_string(index=False))\n",
    "    \n",
    "    # Save FIC analysis to CSV\n",
    "    fic_csv_path = os.path.join(output_dir, f'Case{case_number}_{dataset_name.replace(\" \", \"_\")}_FIC_Analysis_accuracy.csv')\n",
    "    fic_df.to_csv(fic_csv_path, index=False)\n",
    "    print(f\"FIC analysis saved to: {fic_csv_path}\")\n",
    "\n",
    "    # Tier classification for accuracy\n",
    "    tier_data = []\n",
    "    print(\"TIER CLASSIFICATION (Accuracy):\")\n",
    "    for af in fic_framework.alphaF_values:\n",
    "        print(f\"\\nFor αF = {af}:\")\n",
    "        print(\"-\" * 50)\n",
    "        if af in fic_results:\n",
    "            for pair, d in fic_results[af].items():\n",
    "                tier = fic_framework.classify_tier(d['fic_score'])\n",
    "                msg = tier if d['fic_score'] <= 0.75 else f\"{tier} (omega_max < {0.25*af:.4f})\"\n",
    "                print(f\"{pair}: ω={d['omega']:.4f}, FIC={d['fic_score']:.3f} → {msg}\")\n",
    "                tier_data.append({'alphaF': af, 'Group Pair': pair, 'ω': d['omega'], 'FIC': d['fic_score'], 'Tier': tier})\n",
    "    \n",
    "    tier_df = pd.DataFrame(tier_data)\n",
    "    \n",
    "    # Save tier classification to CSV\n",
    "    tier_csv_path = os.path.join(output_dir, f'Case{case_number}_{dataset_name.replace(\" \", \"_\")}_Tier_Classification_accuracy.csv')\n",
    "    tier_df.to_csv(tier_csv_path, index=False)\n",
    "    print(f\"✓ Tier classification saved to: {tier_csv_path}\")\n",
    "\n",
    "    # Model comparison\n",
    "    print(\"MODEL COMPARISON:\")\n",
    "    comparison = []\n",
    "    for mt in model_types:\n",
    "        mets, test_data = train_and_evaluate_models(data, target_col, protected_col, mt)\n",
    "        model_fic = fic_framework.analyze_fairness(mets, 'accuracy')\n",
    "        avg_fic = np.mean([d['fic_score'] for d in model_fic[0.10].values()]) if 0.10 in model_fic and model_fic[0.10] else np.nan\n",
    "        max_omega = max([d['omega'] for d in model_fic[0.10].values()]) if 0.10 in model_fic and model_fic[0.10] else np.nan\n",
    "        _, y_test, _, y_pred, _ = test_data\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        comparison.append({\n",
    "            'Model': mt.upper(),\n",
    "            'Overall Accuracy': f\"{acc:.4f}\",\n",
    "            'Avg FIC (αF=0.10)': f\"{avg_fic:.3f}\" if not np.isnan(avg_fic) else \"N/A\",\n",
    "            'ω_max (αF=0.10)': f\"{max_omega:.4f}\" if not np.isnan(max_omega) else \"N/A\"\n",
    "        })\n",
    "    \n",
    "    comparison_df = pd.DataFrame(comparison)\n",
    "    print(comparison_df.to_string(index=False))\n",
    "    \n",
    "    # Save model comparison to CSV\n",
    "    comparison_csv_path = os.path.join(output_dir, f'Case{case_number}_{dataset_name.replace(\" \", \"_\")}_Model_Comparison.csv')\n",
    "    comparison_df.to_csv(comparison_csv_path, index=False)\n",
    "    print(f\"Model comparison saved to: {comparison_csv_path}\")\n",
    "\n",
    "    # Create comprehensive Excel report\n",
    "    excel_file = create_comprehensive_excel_report(\n",
    "        {\n",
    "            'data': data,\n",
    "            'baseline_metrics': baseline_metrics,\n",
    "            'all_fic_results': all_fic_results,\n",
    "            'metrics_df': metrics_df,\n",
    "            'comparison_df': comparison_df\n",
    "        },\n",
    "        dataset_name,\n",
    "        case_number,\n",
    "        all_metrics\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        'data': data,\n",
    "        'baseline_metrics': baseline_metrics,\n",
    "        'all_fic_results': all_fic_results,\n",
    "        'metrics_df': metrics_df,\n",
    "        'fic_df': fic_df,\n",
    "        'tier_df': tier_df,\n",
    "        'comparison_df': comparison_df,\n",
    "        'excel_file': excel_file,\n",
    "        'metric_summaries': metric_summaries\n",
    "    }\n",
    "\n",
    "# ============================================\n",
    "# 7. MAIN ANALYSIS\n",
    "# ============================================\n",
    "\n",
    "def run_complete_simulated_analysis():\n",
    "    \"\"\"\n",
    "    Run complete FIC analysis for simulated datasets\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"FAIRNESS INFORMATION CRITERION (FIC) ANALYSIS - SIMULATED DATASETS\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Output directory: {output_dir}\")\n",
    "    print(f\"PDF directory: {pdf_dir}\")\n",
    "    print(f\"Excel directory: {excel_dir}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ANALYZING SIMULATED DATASETS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Case 1: Healthcare Dataset\n",
    "    healthcare_results = analyze_simulated_dataset(\n",
    "        dataset_name=\"Healthcare - Depression Diagnosis\",\n",
    "        data_generator=lambda: generate_healthcare_data(5000),\n",
    "        target_col='depression',\n",
    "        protected_col='gender',\n",
    "        case_number=1\n",
    "    )\n",
    "    \n",
    "    # Case 2: Criminal Justice Dataset\n",
    "    criminal_results = analyze_simulated_dataset(\n",
    "        dataset_name=\"Criminal Justice - Recidivism Risk\",\n",
    "        data_generator=lambda: generate_criminal_justice_data(8000),\n",
    "        target_col='high_risk',\n",
    "        protected_col='region',\n",
    "        case_number=2\n",
    "    )\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"SUMMARY REPORT - SIMULATED DATASETS\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    print(\"CASE 1 - HEALTHCARE DATASET KEY FINDINGS:\")\n",
    "    print(\"-\" * 60)\n",
    "    data = healthcare_results['data']\n",
    "    print(f\"Total samples: {len(data)}\")\n",
    "    print(f\"Depression prevalence: {data['depression'].mean():.3f}\")\n",
    "    print(f\"Gender distribution:\")\n",
    "    gender_dist = data['gender'].value_counts()\n",
    "    for gender, count in gender_dist.items():\n",
    "        prop = count / len(data)\n",
    "        print(f\"  {gender}: {count} ({prop:.3f})\")\n",
    "    \n",
    "    print(\"Depression by gender:\")\n",
    "    for gender in sorted(data['gender'].unique()):\n",
    "        subset = data[data['gender'] == gender]\n",
    "        depression_prop = subset['depression'].mean()\n",
    "        print(f\"  {gender}: {depression_prop:.3f}\")\n",
    "\n",
    "    print(\"FIC ANALYSIS SUMMARY (Accuracy - Healthcare):\")\n",
    "    print(\"-\" * 60)\n",
    "    fic_results = healthcare_results['all_fic_results']['accuracy']\n",
    "    for af in [0.05, 0.10, 0.15, 0.20]:\n",
    "        if af in fic_results and fic_results[af]:\n",
    "            items = list(fic_results[af].items())\n",
    "            max_o = max(d['omega'] for _, d in items)\n",
    "            min_o = min(d['omega'] for _, d in items)\n",
    "            avg_o = np.mean([d['omega'] for _, d in items])\n",
    "            worst_pair = max(items, key=lambda x: x[1]['omega'])[0]\n",
    "            best_pair = min(items, key=lambda x: x[1]['omega'])[0]\n",
    "            print(f\"alphaF={af}:\")\n",
    "            print(f\"  omega range: [{min_o:.4f}, {max_o:.4f}], avg: {avg_o:.4f}\")\n",
    "            print(f\"  Most unfair pair: {worst_pair} (ω={max_o:.4f})\")\n",
    "            print(f\"  Most fair pair: {best_pair} (ω={min_o:.4f})\")\n",
    "            \n",
    "            # Tier distribution\n",
    "            fic = FairnessInformationCriterion()\n",
    "            tiers = {'Optimum': 0, 'Acceptable': 0, 'Questionable': 0, 'Unacceptable': 0}\n",
    "            for d in fic_results[af].values():\n",
    "                tiers[fic.classify_tier(d['fic_score'])] += 1\n",
    "            print(f\"  Tier distribution: {tiers}\")\n",
    "\n",
    "    print(\"CASE 2 - CRIMINAL JUSTICE DATASET KEY FINDINGS:\")\n",
    "    print(\"-\" * 60)\n",
    "    data = criminal_results['data']\n",
    "    print(f\"Total samples: {len(data)}\")\n",
    "    print(f\"High risk prevalence: {data['high_risk'].mean():.3f}\")\n",
    "    print(f\"Region distribution:\")\n",
    "    region_dist = data['region'].value_counts()\n",
    "    for region, count in region_dist.items():\n",
    "        prop = count / len(data)\n",
    "        print(f\"  {region}: {count} ({prop:.3f})\")\n",
    "\n",
    "    print(\"FIC ANALYSIS SUMMARY (Accuracy - Criminal Justice):\")\n",
    "    print(\"-\" * 60)\n",
    "    fic_results = criminal_results['all_fic_results']['accuracy']\n",
    "    for af in [0.05, 0.10, 0.15, 0.20]:\n",
    "        if af in fic_results and fic_results[af]:\n",
    "            items = list(fic_results[af].items())\n",
    "            max_o = max(d['omega'] for _, d in items)\n",
    "            min_o = min(d['omega'] for _, d in items)\n",
    "            avg_o = np.mean([d['omega'] for _, d in items])\n",
    "            worst_pair = max(items, key=lambda x: x[1]['omega'])[0]\n",
    "            best_pair = min(items, key=lambda x: x[1]['omega'])[0]\n",
    "            print(f\"alphaF={af}:\")\n",
    "            print(f\"  omega range: [{min_o:.4f}, {max_o:.4f}], avg: {avg_o:.4f}\")\n",
    "            print(f\"  Most unfair pair: {worst_pair} (ω={max_o:.4f})\")\n",
    "            print(f\"  Most fair pair: {best_pair} (ω={min_o:.4f})\")\n",
    "            \n",
    "            # Tier distribution\n",
    "            fic = FairnessInformationCriterion()\n",
    "            tiers = {'Optimum': 0, 'Acceptable': 0, 'Questionable': 0, 'Unacceptable': 0}\n",
    "            for d in fic_results[af].values():\n",
    "                tiers[fic.classify_tier(d['fic_score'])] += 1\n",
    "            print(f\"  Tier distribution: {tiers}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ANALYSIS COMPLETE - ALL RESULTS SAVED\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(f\"VISUALIZATIONS:\")\n",
    "    print(f\"  Generated plots for 2 cases × 10 metrics = 20 metric analyses\")\n",
    "    print(f\"  Each metric analysis has:\")\n",
    "    print(f\"    - 1 heatmap figure (2x2 grid for all alphaF values)\")\n",
    "    print(f\"    - 4 benchmarking tier plots (one for each alphaF: 0.05, 0.10, 0.15, 0.20)\")\n",
    "    print(f\"  Total plots: {2 * (10 + 40)} PNG files + {2 * (10 + 40)} PDF files = {200} total files\")\n",
    "    \n",
    "    print(f\"NUMERICAL RESULTS:\")\n",
    "    print(f\"  CSV files saved in: {output_dir}/\")\n",
    "    print(f\"  Comprehensive Excel reports:\")\n",
    "    print(f\"    - {healthcare_results['excel_file']}\")\n",
    "    print(f\"    - {criminal_results['excel_file']}\")\n",
    "       \n",
    "    return healthcare_results, criminal_results\n",
    "\n",
    "# ============================================\n",
    "# 8. EXECUTION\n",
    "# ============================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run the complete analysis for simulated datasets\n",
    "    healthcare_results, criminal_results = run_complete_simulated_analysis()\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ALL SIMULATED CASES ANALYSIS COMPLETED SUCCESSFULLY!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6314d9a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d7c26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#..................................................................................................#\n",
    "#..........................        REAL-LIFE COMPAS        .........................................#\n",
    "#...................................................................................................#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4aa3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#.... First try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c2ad828d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FAIRNESS INFORMATION CRITERION (FIC) ANALYSIS - COMPAS DATASET\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "CASE 1: COMPAS - Recidivism Risk Prediction\n",
      "================================================================================\n",
      "Loaded COMPAS dataset from local file\n",
      "Original dataset shape: (7214, 53)\n",
      "Processed dataset shape: (7214, 8)\n",
      "Target distribution (high_risk):\n",
      "high_risk\n",
      "0    0.634599\n",
      "1    0.365401\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Race group distribution:\n",
      "race_group\n",
      "African_American    0.512337\n",
      "Caucasian           0.340172\n",
      "Hispanic            0.088301\n",
      "Other_Race          0.059190\n",
      "Name: proportion, dtype: float64\n",
      "GROUP METRICS TABLE (Baseline Logistic Regression):\n",
      "                  accuracy  selection_rate     tpr     tnr     fpr     fnr     ppv     npv      f1     auc\n",
      "African_American    0.6993          0.3501  0.5498  0.8460  0.1540  0.4502  0.7781  0.6568  0.6443  0.7555\n",
      "Caucasian           0.7976          0.1787  0.4531  0.9139  0.0861  0.5469  0.6397  0.8320  0.5305  0.8210\n",
      "Hispanic            0.8305          0.1525  0.4615  0.9348  0.0652  0.5385  0.6667  0.8600  0.5455  0.8443\n",
      "Other_Race          0.8647          0.1353  0.5000  0.9217  0.0783  0.5000  0.5000  0.9217  0.5000  0.8565\n",
      "FIC ANALYSIS TABLE:\n",
      "                   Group Pair              alphaF=0.05   Hypothesis alphaF=0.05               alphaF=0.1    Hypothesis alphaF=0.1              alphaF=0.15   Hypothesis alphaF=0.15              alphaF=0.2    Hypothesis alphaF=0.2\n",
      " African_American - Caucasian omega=0.0984, FIC=-0.967       Reject H₀ (Unfair)  omega=0.0984, FIC=0.016 Fail to reject Ho (Fair)  omega=0.0984, FIC=0.344 Fail to reject Ho (Fair) omega=0.0984, FIC=0.508 Fail to reject Ho (Fair)\n",
      "  African_American - Hispanic omega=0.1312, FIC=-1.625       Reject H₀ (Unfair) omega=0.1312, FIC=-0.312       Reject H₀ (Unfair)  omega=0.1312, FIC=0.125 Fail to reject Ho (Fair) omega=0.1312, FIC=0.344 Fail to reject Ho (Fair)\n",
      "African_American - Other_Race omega=0.1654, FIC=-2.308       Reject H₀ (Unfair) omega=0.1654, FIC=-0.654       Reject H₀ (Unfair) omega=0.1654, FIC=-0.103       Reject H₀ (Unfair) omega=0.1654, FIC=0.173 Fail to reject Ho (Fair)\n",
      "         Caucasian - Hispanic  omega=0.0329, FIC=0.343 Fail to reject Ho (Fair)  omega=0.0329, FIC=0.671 Fail to reject Ho (Fair)  omega=0.0329, FIC=0.781 Fail to reject Ho (Fair) omega=0.0329, FIC=0.836 Fail to reject Ho (Fair)\n",
      "       Caucasian - Other_Race omega=0.0670, FIC=-0.341       Reject H₀ (Unfair)  omega=0.0670, FIC=0.330 Fail to reject Ho (Fair)  omega=0.0670, FIC=0.553 Fail to reject Ho (Fair) omega=0.0670, FIC=0.665 Fail to reject Ho (Fair)\n",
      "        Hispanic - Other_Race  omega=0.0342, FIC=0.317 Fail to reject Ho (Fair)  omega=0.0342, FIC=0.658 Fail to reject Ho (Fair)  omega=0.0342, FIC=0.772 Fail to reject Ho (Fair) omega=0.0342, FIC=0.829 Fail to reject Ho (Fair)\n",
      "TIER CLASSIFICATION:\n",
      "\n",
      "For αF = 0.05:\n",
      "--------------------------------------------------\n",
      "African_American - Caucasian: ω=0.0984, FIC=-0.967 → Unacceptable\n",
      "African_American - Hispanic: ω=0.1312, FIC=-1.625 → Unacceptable\n",
      "African_American - Other_Race: ω=0.1654, FIC=-2.308 → Unacceptable\n",
      "Caucasian - Hispanic: ω=0.0329, FIC=0.343 → Questionable\n",
      "Caucasian - Other_Race: ω=0.0670, FIC=-0.341 → Unacceptable\n",
      "Hispanic - Other_Race: ω=0.0342, FIC=0.317 → Questionable\n",
      "\n",
      "For αF = 0.1:\n",
      "--------------------------------------------------\n",
      "African_American - Caucasian: ω=0.0984, FIC=0.016 → Questionable\n",
      "African_American - Hispanic: ω=0.1312, FIC=-0.312 → Unacceptable\n",
      "African_American - Other_Race: ω=0.1654, FIC=-0.654 → Unacceptable\n",
      "Caucasian - Hispanic: ω=0.0329, FIC=0.671 → Acceptable\n",
      "Caucasian - Other_Race: ω=0.0670, FIC=0.330 → Questionable\n",
      "Hispanic - Other_Race: ω=0.0342, FIC=0.658 → Acceptable\n",
      "\n",
      "For αF = 0.15:\n",
      "--------------------------------------------------\n",
      "African_American - Caucasian: ω=0.0984, FIC=0.344 → Questionable\n",
      "African_American - Hispanic: ω=0.1312, FIC=0.125 → Questionable\n",
      "African_American - Other_Race: ω=0.1654, FIC=-0.103 → Unacceptable\n",
      "Caucasian - Hispanic: ω=0.0329, FIC=0.781 → Optimum (omega_max < 0.0375)\n",
      "Caucasian - Other_Race: ω=0.0670, FIC=0.553 → Acceptable\n",
      "Hispanic - Other_Race: ω=0.0342, FIC=0.772 → Optimum (omega_max < 0.0375)\n",
      "\n",
      "For αF = 0.2:\n",
      "--------------------------------------------------\n",
      "African_American - Caucasian: ω=0.0984, FIC=0.508 → Acceptable\n",
      "African_American - Hispanic: ω=0.1312, FIC=0.344 → Questionable\n",
      "African_American - Other_Race: ω=0.1654, FIC=0.173 → Questionable\n",
      "Caucasian - Hispanic: ω=0.0329, FIC=0.836 → Optimum (omega_max < 0.0500)\n",
      "Caucasian - Other_Race: ω=0.0670, FIC=0.665 → Acceptable\n",
      "Hispanic - Other_Race: ω=0.0342, FIC=0.829 → Optimum (omega_max < 0.0500)\n",
      "GENERATING VISUALIZATIONS...\n",
      "  Saved benchmarking tiers plot for alphaF=0.05\n",
      "  Saved benchmarking tiers plot for alphaF=0.1\n",
      "  Saved benchmarking tiers plot for alphaF=0.15\n",
      "  Saved benchmarking tiers plot for alphaF=0.2\n",
      "MODEL COMPARISON:\n",
      "   Model Overall Accuracy Avg FIC alphaF=0.10) ω_max (alphaF=0.10)\n",
      "BASELINE           0.7547                0.118              0.1654\n",
      "      L1           0.7547                0.118              0.1654\n",
      "      L2           0.7547                0.118              0.1654\n",
      "\n",
      "================================================================================\n",
      "SUMMARY REPORT - COMPAS DATASET\n",
      "================================================================================\n",
      "COMPAS DATASET KEY FINDINGS:\n",
      "------------------------------------------------------------\n",
      "Total samples: 7214\n",
      "High risk proportion: 0.365\n",
      "\n",
      "Race group distribution:\n",
      "  African_American: 3696 (0.512)\n",
      "  Caucasian: 2454 (0.340)\n",
      "  Hispanic: 637 (0.088)\n",
      "  Other_Race: 427 (0.059)\n",
      "\n",
      "High risk by race group:\n",
      "  African_American: 0.489\n",
      "  Caucasian: 0.250\n",
      "  Hispanic: 0.217\n",
      "  Other_Race: 0.178\n",
      "\n",
      "FIC ANALYSIS SUMMARY:\n",
      "------------------------------------------------------------\n",
      "alphaF=0.05:\n",
      "  omega range: [0.0329, 0.1654], avg: 0.0882\n",
      "  Most unfair pair: African_American - Other_Race (ω=0.1654)\n",
      "  Most fair pair: Caucasian - Hispanic (ω=0.0329)\n",
      "  Tier distribution: {'Optimum': 0, 'Acceptable': 0, 'Questionable': 2, 'Unacceptable': 4}\n",
      "alphaF=0.1:\n",
      "  omega range: [0.0329, 0.1654], avg: 0.0882\n",
      "  Most unfair pair: African_American - Other_Race (ω=0.1654)\n",
      "  Most fair pair: Caucasian - Hispanic (ω=0.0329)\n",
      "  Tier distribution: {'Optimum': 0, 'Acceptable': 2, 'Questionable': 2, 'Unacceptable': 2}\n",
      "alphaF=0.15:\n",
      "  omega range: [0.0329, 0.1654], avg: 0.0882\n",
      "  Most unfair pair: African_American - Other_Race (ω=0.1654)\n",
      "  Most fair pair: Caucasian - Hispanic (ω=0.0329)\n",
      "  Tier distribution: {'Optimum': 2, 'Acceptable': 1, 'Questionable': 2, 'Unacceptable': 1}\n",
      "alphaF=0.2:\n",
      "  omega range: [0.0329, 0.1654], avg: 0.0882\n",
      "  Most unfair pair: African_American - Other_Race (ω=0.1654)\n",
      "  Most fair pair: Caucasian - Hispanic (ω=0.0329)\n",
      "  Tier distribution: {'Optimum': 2, 'Acceptable': 2, 'Questionable': 2, 'Unacceptable': 0}\n",
      "\n",
      "================================================================================\n",
      "ANALYSIS COMPLETE - HIGH-QUALITY PLOTS SAVED\n",
      "================================================================================\n",
      "\n",
      "All analysis completed!\n",
      "Results saved to: compas_fic_results/\n",
      "Files include:\n",
      "  - Group metrics (CSV)\n",
      "  - FIC analysis tables (CSV)\n",
      "  - Tier classification (CSV)\n",
      "  - Model comparison (CSV)\n",
      "  - FIC heatmaps (PNG)\n",
      "  - Benchmarking tiers for all alphaF values (PNG)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create output directory\n",
    "output_dir = \"compas_fic_results\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Set style for publication quality\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Global font settings for consistency\n",
    "plt.rcParams.update({\n",
    "    'font.size': 12,\n",
    "    'axes.titlesize': 16,\n",
    "    'axes.labelsize': 14,\n",
    "    'xtick.labelsize': 12,\n",
    "    'ytick.labelsize': 12,\n",
    "    'legend.fontsize': 12,\n",
    "})\n",
    "\n",
    "# ============================================\n",
    "# 1. LOAD AND PREPROCESS COMPAS DATASET\n",
    "# ============================================\n",
    "\n",
    "def load_compas_data():\n",
    "    \"\"\"\n",
    "    Load and preprocess COMPAS ProPublica dataset\n",
    "    Source: https://github.com/propublica/compas-analysis\n",
    "    \"\"\"\n",
    "    # Try to load from local file first\n",
    "    try:\n",
    "        compas_df = pd.read_csv(\"compas-scores-two-years.csv\")\n",
    "        print(\"Loaded COMPAS dataset from local file\")\n",
    "    except:\n",
    "        # If local file doesn't exist, download from GitHub\n",
    "        print(\"Downloading COMPAS dataset from GitHub...\")\n",
    "        import requests\n",
    "        url = \"https://raw.githubusercontent.com/propublica/compas-analysis/master/compas-scores-two-years.csv\"\n",
    "        response = requests.get(url)\n",
    "        with open(\"compas-scores-two-years.csv\", \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "        compas_df = pd.read_csv(\"compas-scores-two-years.csv\")\n",
    "        print(\"COMPAS dataset downloaded and loaded\")\n",
    "    \n",
    "    # Basic preprocessing\n",
    "    print(f\"Original dataset shape: {compas_df.shape}\")\n",
    "    \n",
    "    # Filter relevant columns\n",
    "    relevant_columns = [\n",
    "        'age', 'sex', 'race', 'priors_count', 'c_charge_degree',\n",
    "        'juv_fel_count', 'juv_misd_count', 'juv_other_count',\n",
    "        'decile_score', 'two_year_recid'\n",
    "    ]\n",
    "    \n",
    "    # Check which columns exist in the dataset\n",
    "    available_columns = [col for col in relevant_columns if col in compas_df.columns]\n",
    "    compas_df = compas_df[available_columns].copy()\n",
    "    \n",
    "    # Drop rows with missing values\n",
    "    compas_df = compas_df.dropna()\n",
    "    \n",
    "    # Create high_risk target: 0-5 as low risk, 6-10 as high risk\n",
    "    compas_df['high_risk'] = (compas_df['decile_score'] >= 6).astype(int)\n",
    "    \n",
    "    # Consolidate race categories\n",
    "    def consolidate_race(race):\n",
    "        race = str(race).strip().lower()\n",
    "        if 'african' in race or 'black' in race:\n",
    "            return 'African_American'\n",
    "        elif 'caucasian' in race or 'white' in race:\n",
    "            return 'Caucasian'\n",
    "        elif 'hispanic' in race or 'latino' in race:\n",
    "            return 'Hispanic'\n",
    "        elif 'asian' in race or 'arab' in race or 'native' in race or 'other' in race:\n",
    "            return 'Other_Race'\n",
    "        else:\n",
    "            return 'Other_Race'\n",
    "    \n",
    "    compas_df['race_group'] = compas_df['race'].apply(consolidate_race)\n",
    "    \n",
    "    # Filter to keep only our target race groups\n",
    "    target_races = ['African_American', 'Caucasian', 'Hispanic', 'Other_Race']\n",
    "    compas_df = compas_df[compas_df['race_group'].isin(target_races)].copy()\n",
    "    \n",
    "    # Create additional features for better prediction\n",
    "    compas_df['total_juvenile_charges'] = compas_df['juv_fel_count'] + compas_df['juv_misd_count'] + compas_df['juv_other_count']\n",
    "    compas_df['is_felony'] = (compas_df['c_charge_degree'] == 'F').astype(int)\n",
    "    compas_df['age_group'] = pd.cut(compas_df['age'], \n",
    "                                     bins=[0, 25, 35, 45, 55, 100],\n",
    "                                     labels=['18-25', '26-35', '36-45', '46-55', '56+'])\n",
    "    \n",
    "    # Select final columns for analysis\n",
    "    final_columns = [\n",
    "        'age', 'sex', 'race_group', 'priors_count', 'is_felony',\n",
    "        'total_juvenile_charges', 'age_group', 'high_risk'\n",
    "    ]\n",
    "    \n",
    "    # Ensure all columns exist\n",
    "    final_columns = [col for col in final_columns if col in compas_df.columns]\n",
    "    compas_df = compas_df[final_columns]\n",
    "    \n",
    "    print(f\"Processed dataset shape: {compas_df.shape}\")\n",
    "    print(f\"Target distribution (high_risk):\")\n",
    "    print(compas_df['high_risk'].value_counts(normalize=True))\n",
    "    print(f\"\\nRace group distribution:\")\n",
    "    print(compas_df['race_group'].value_counts(normalize=True))\n",
    "    \n",
    "    return compas_df\n",
    "\n",
    "def generate_compas_data(n_samples=None):\n",
    "    \"\"\"\n",
    "    Wrapper function to load COMPAS data\n",
    "    n_samples parameter is kept for compatibility but not used\n",
    "    \"\"\"\n",
    "    data = load_compas_data()\n",
    "    \n",
    "    # If n_samples is specified and smaller than dataset, sample it\n",
    "    if n_samples and n_samples < len(data):\n",
    "        data = data.sample(n=n_samples, random_state=42)\n",
    "    \n",
    "    return data\n",
    "\n",
    "# ============================================\n",
    "# 2-3. MODEL & FIC (unchanged)\n",
    "# ============================================\n",
    "\n",
    "def compute_all_metrics(y_true, y_pred, y_prob):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_true, y_pred),\n",
    "        'selection_rate': (tp + fp) / len(y_true),\n",
    "        'tpr': tp / (tp + fn) if (tp + fn) > 0 else 0,\n",
    "        'tnr': tn / (tn + fp) if (tn + fp) > 0 else 0,\n",
    "        'fpr': fp / (fp + tn) if (fp + tn) > 0 else 0,\n",
    "        'fnr': fn / (tp + fn) if (tp + fn) > 0 else 0,\n",
    "        'ppv': tp / (tp + fp) if (tp + fp) > 0 else 0,\n",
    "        'npv': tn / (tn + fn) if (tn + fn) > 0 else 0,\n",
    "        'f1': f1_score(y_true, y_pred),\n",
    "        'auc': roc_auc_score(y_true, y_prob) if len(np.unique(y_true)) > 1 else np.nan\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "def train_and_evaluate_models(data, target_col, protected_col, model_type='baseline'):\n",
    "    X = data.drop(columns=[target_col, protected_col])\n",
    "    y = data[target_col]\n",
    "    categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "    numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(drop='first'), categorical_cols)\n",
    "    ])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "    protected_test = data.loc[X_test.index, protected_col]\n",
    "\n",
    "    X_train_processed = preprocessor.fit_transform(X_train)\n",
    "    X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "    if model_type == 'baseline':\n",
    "        model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "    elif model_type == 'l1':\n",
    "        model = LogisticRegression(penalty='l1', solver='liblinear', random_state=42, max_iter=1000, C=1.0)\n",
    "    elif model_type == 'l2':\n",
    "        model = LogisticRegression(penalty='l2', random_state=42, max_iter=1000, C=1.0)\n",
    "    else:\n",
    "        model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "    model.fit(X_train_processed, y_train)\n",
    "    y_pred = model.predict(X_test_processed)\n",
    "    y_prob = model.predict_proba(X_test_processed)[:, 1]\n",
    "\n",
    "    group_metrics = {}\n",
    "    for group in protected_test.unique():\n",
    "        mask = protected_test == group\n",
    "        if mask.sum() > 0:\n",
    "            group_metrics[group] = compute_all_metrics(y_test[mask], y_pred[mask], y_prob[mask])\n",
    "\n",
    "    return group_metrics, (X_test, y_test, protected_test, y_pred, y_prob)\n",
    "\n",
    "class FairnessInformationCriterion:\n",
    "    def __init__(self, alphaF_values=[0.05, 0.10, 0.15, 0.20]):\n",
    "        self.alphaF_values = alphaF_values\n",
    "\n",
    "    def compute_omega(self, metric1, metric2):\n",
    "        return abs(metric1 - metric2)\n",
    "\n",
    "    def compute_fic(self, omega, alphaF):\n",
    "        return 1 - (omega / alphaF)\n",
    "\n",
    "    def classify_tier(self, fic_score):\n",
    "        if fic_score > 0.75:\n",
    "            return \"Optimum\"\n",
    "        elif fic_score > 0.50:\n",
    "            return \"Acceptable\"\n",
    "        elif fic_score > 0:\n",
    "            return \"Questionable\"\n",
    "        else:\n",
    "            return \"Unacceptable\"\n",
    "\n",
    "    def analyze_fairness(self, group_metrics, metric_name='accuracy'):\n",
    "        results = {}\n",
    "        groups = list(group_metrics.keys())\n",
    "        for alphaF in self.alphaF_values:\n",
    "            results[alphaF] = {}\n",
    "            for i, g1 in enumerate(groups):\n",
    "                for g2 in groups[i+1:]:\n",
    "                    pair = f\"{g1} - {g2}\"\n",
    "                    m1 = group_metrics[g1].get(metric_name, np.nan)\n",
    "                    m2 = group_metrics[g2].get(metric_name, np.nan)\n",
    "                    if not np.isnan(m1) and not np.isnan(m2):\n",
    "                        omega = self.compute_omega(m1, m2)\n",
    "                        fic_score = self.compute_fic(omega, alphaF)\n",
    "                        tier = self.classify_tier(fic_score)\n",
    "                        results[alphaF][pair] = {\n",
    "                            'omega': omega, 'fic_score': fic_score, 'tier': tier,\n",
    "                            'metric1': m1, 'metric2': m2\n",
    "                        }\n",
    "        return results\n",
    "\n",
    "# ============================================\n",
    "# 4. VISUALIZATIONS\n",
    "# ============================================\n",
    "\n",
    "def plot_fic_heatmaps(fic_results, dataset_name, metric='accuracy'):\n",
    "    alphaF_values = sorted(fic_results.keys())\n",
    "    if not alphaF_values:\n",
    "        return\n",
    "\n",
    "    pairs = list(fic_results[alphaF_values[0]].keys())\n",
    "    all_groups = sorted(set(g for p in pairs for g in p.split(' - ')))\n",
    "\n",
    "    # Larger figure\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(20, 16))\n",
    "    fig.suptitle(f'{dataset_name}: FIC Heatmaps for Different alphaF Values ({metric})',\n",
    "                 fontsize=20, fontweight='bold', y=0.98)\n",
    "\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for idx, alphaF in enumerate(alphaF_values):\n",
    "        ax = axes[idx]\n",
    "        n = len(all_groups)\n",
    "        mat = np.full((n, n), np.nan)\n",
    "        group_idx = {g: i for i, g in enumerate(all_groups)}\n",
    "\n",
    "        for pair, d in fic_results[alphaF].items():\n",
    "            g1, g2 = pair.split(' - ')\n",
    "            i, j = group_idx[g1], group_idx[g2]\n",
    "            mat[i, j] = mat[j, i] = d['fic_score']\n",
    "\n",
    "        im = ax.imshow(mat, cmap='RdYlGn', vmin=-1, vmax=1, aspect='equal')\n",
    "\n",
    "        # Colorbar\n",
    "        cbar = fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "        cbar.set_label('FIC Score', fontsize=14, fontweight='bold')\n",
    "        cbar.ax.tick_params(labelsize=12)\n",
    "\n",
    "        # Bold text inside cells\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                if i != j and not np.isnan(mat[i, j]):\n",
    "                    text = ax.text(j, i, f'{mat[i,j]:.3f}',\n",
    "                                   ha='center', va='center',\n",
    "                                   fontsize=14, fontweight='bold',\n",
    "                                   color='white' if abs(mat[i,j]) > 0.5 else 'black')\n",
    "\n",
    "        ax.set_xticks(range(n))\n",
    "        ax.set_yticks(range(n))\n",
    "        ax.set_xticklabels(all_groups, rotation=45, ha='right', fontsize=13, fontweight='bold')\n",
    "        ax.set_yticklabels(all_groups, fontsize=13, fontweight='bold')\n",
    "        ax.set_title(f'αF = {alphaF}', fontsize=18, fontweight='bold', pad=20)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.savefig(os.path.join(output_dir, f'{dataset_name}_FIC_Heatmaps_{metric}.png'), dpi=400, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def plot_benchmarking_tiers(fic_results, dataset_name, metric='accuracy'):\n",
    "    # Sort alphaF values to ensure consistent order\n",
    "    alphaF_values = sorted(fic_results.keys())\n",
    "    \n",
    "    # Define colors for tiers\n",
    "    colors = {'Optimum': '#2E8B57', 'Acceptable': '#FFD700', \n",
    "              'Questionable': '#FF8C00', 'Unacceptable': '#DC143C'}\n",
    "    \n",
    "    for alphaF in alphaF_values:\n",
    "        if alphaF not in fic_results or not fic_results[alphaF]:\n",
    "            print(f\"No data for alphaF={alphaF} in benchmarking tiers\")\n",
    "            continue\n",
    "        \n",
    "        # Create a more compact figure\n",
    "        fig, ax = plt.subplots(figsize=(14, 8))\n",
    "        \n",
    "        data = fic_results[alphaF]\n",
    "        pairs = list(data.keys())\n",
    "        fic_scores = [data[p]['fic_score'] for p in pairs]\n",
    "        tiers = [data[p]['tier'] for p in pairs]\n",
    "        \n",
    "        # Create bar colors based on tiers\n",
    "        bar_colors = [colors[t] for t in tiers]\n",
    "        \n",
    "        # Create bars with smaller width for more compact look\n",
    "        bars = ax.bar(range(len(pairs)), fic_scores, color=bar_colors, \n",
    "                      edgecolor='black', linewidth=1.2, width=0.6)\n",
    "        \n",
    "        # Add tier threshold lines with better styling\n",
    "        ax.axhline(0.75, color='darkgreen', linestyle='--', linewidth=2.0, \n",
    "                   alpha=0.7, label='Optimum (FIC > 0.75)')\n",
    "        ax.axhline(0.50, color='goldenrod', linestyle='--', linewidth=2.0, \n",
    "                   alpha=0.7, label='Acceptable (FIC > 0.50)')\n",
    "        ax.axhline(0.00, color='darkred', linestyle='--', linewidth=2.0, \n",
    "                   alpha=0.7, label='Unacceptable (FIC ≤ 0)')\n",
    "        \n",
    "        # Add value and tier labels on bars - more compact\n",
    "        for bar, score, tier in zip(bars, fic_scores, tiers):\n",
    "            height = bar.get_height()\n",
    "            # Position text based on bar height\n",
    "            if height >= 0:\n",
    "                ax.text(bar.get_x() + bar.get_width()/2, height + 0.015,\n",
    "                        f'{score:.2f}',\n",
    "                        ha='center', va='bottom',\n",
    "                        fontsize=10, fontweight='bold', color='black')\n",
    "                # Add tier label at the bottom of positive bars\n",
    "                ax.text(bar.get_x() + bar.get_width()/2, -0.05,\n",
    "                        f'{tier[:3]}',  # Show first 3 letters of tier\n",
    "                        ha='center', va='top',\n",
    "                        fontsize=9, fontweight='bold', color='black',\n",
    "                        rotation=90)\n",
    "            else:\n",
    "                ax.text(bar.get_x() + bar.get_width()/2, height - 0.03,\n",
    "                        f'{score:.2f}',\n",
    "                        ha='center', va='top',\n",
    "                        fontsize=10, fontweight='bold', color='black')\n",
    "        \n",
    "        # Customize axes with better labels\n",
    "        ax.set_xlabel('Group Pairs', fontsize=14, fontweight='bold', labelpad=10)\n",
    "        ax.set_ylabel('FIC Score', fontsize=14, fontweight='bold', labelpad=10)\n",
    "        ax.set_title(f'{dataset_name}\\nFIC Benchmarking Tiers ({metric}, αF = {alphaF})',\n",
    "                    fontsize=16, fontweight='bold', pad=15)\n",
    "        \n",
    "        # Set x-ticks with rotation for readability\n",
    "        ax.set_xticks(range(len(pairs)))\n",
    "        # Shorten pair labels if they're too long\n",
    "        shortened_pairs = []\n",
    "        for pair in pairs:\n",
    "            if len(pair) > 15:\n",
    "                # Take first part of each group name\n",
    "                g1, g2 = pair.split(' - ')\n",
    "                g1_short = g1[:3] if len(g1) > 3 else g1\n",
    "                g2_short = g2[:3] if len(g2) > 3 else g2\n",
    "                shortened_pairs.append(f'{g1_short}-{g2_short}')\n",
    "            else:\n",
    "                shortened_pairs.append(pair)\n",
    "        \n",
    "        ax.set_xticklabels(shortened_pairs, rotation=45, ha='right', fontsize=11, fontweight='bold')\n",
    "        \n",
    "        # Set consistent y-axis limits\n",
    "        ax.set_ylim(-0.25, 1.05)\n",
    "        \n",
    "        # Add grid with lighter style\n",
    "        ax.grid(True, axis='y', alpha=0.3, linestyle='-', linewidth=0.5)\n",
    "        ax.grid(True, axis='x', alpha=0.1, linestyle='-', linewidth=0.5)\n",
    "        \n",
    "        # Add better legend\n",
    "        # Create custom legend for tier colors\n",
    "        from matplotlib.patches import Patch\n",
    "        legend_elements = [\n",
    "            Patch(facecolor=colors['Optimum'], edgecolor='black', label='Optimum'),\n",
    "            Patch(facecolor=colors['Acceptable'], edgecolor='black', label='Acceptable'),\n",
    "            Patch(facecolor=colors['Questionable'], edgecolor='black', label='Questionable'),\n",
    "            Patch(facecolor=colors['Unacceptable'], edgecolor='black', label='Unacceptable'),\n",
    "            plt.Line2D([0], [0], color='darkgreen', linestyle='--', linewidth=2, label='Optimum Threshold'),\n",
    "            plt.Line2D([0], [0], color='goldenrod', linestyle='--', linewidth=2, label='Acceptable Threshold'),\n",
    "            plt.Line2D([0], [0], color='darkred', linestyle='--', linewidth=2, label='Unacceptable Threshold')\n",
    "        ]\n",
    "        \n",
    "        # Place legend outside the plot\n",
    "        ax.legend(handles=legend_elements, fontsize=10, \n",
    "                  loc='center left', bbox_to_anchor=(1.02, 0.5),\n",
    "                  frameon=True, framealpha=0.9, edgecolor='black')\n",
    "        \n",
    "        # Add annotation for alphaF interpretation\n",
    "        annotation_text = f'αF = {alphaF}\\nFIC = 1 - (ω/αF)\\nω = |metric₁ - metric₂|'\n",
    "        ax.text(0.02, 0.98, annotation_text, transform=ax.transAxes,\n",
    "                fontsize=9, verticalalignment='top',\n",
    "                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
    "        \n",
    "        # Adjust layout to make room for legend\n",
    "        plt.tight_layout(rect=[0, 0, 0.85, 1])\n",
    "        \n",
    "        # Save the figure with alphaF in the filename\n",
    "        plt.savefig(os.path.join(output_dir, f'{dataset_name}_Benchmarking_Tiers_alphaF_{alphaF}_{metric}.png'), \n",
    "                    dpi=400, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        print(f\"  Saved benchmarking tiers plot for alphaF={alphaF}\")\n",
    "\n",
    "# ============================================\n",
    "# 5. ANALYSIS FUNCTIONS\n",
    "# ============================================\n",
    "\n",
    "def analyze_dataset(dataset_name, data_generator, target_col, protected_col, case_number=1, model_types=['baseline', 'l1', 'l2']):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"CASE {case_number}: {dataset_name}\")\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "    data = data_generator()\n",
    "    fic_framework = FairnessInformationCriterion()\n",
    "\n",
    "    baseline_metrics, _ = train_and_evaluate_models(data, target_col, protected_col, 'baseline')\n",
    "\n",
    "    metrics_df = pd.DataFrame.from_dict(baseline_metrics, orient='index')\n",
    "    metrics_df = metrics_df[['accuracy', 'selection_rate', 'tpr', 'tnr', 'fpr', 'fnr', 'ppv', 'npv', 'f1', 'auc']]\n",
    "    print(\"GROUP METRICS TABLE (Baseline Logistic Regression):\")\n",
    "    print(metrics_df.round(4).to_string())\n",
    "    metrics_df.to_csv(os.path.join(output_dir, f'Case{case_number}_Group_Metrics.csv'))\n",
    "\n",
    "    fic_results = fic_framework.analyze_fairness(baseline_metrics, 'accuracy')\n",
    "\n",
    "    # FIC table\n",
    "    fic_table = []\n",
    "    for pair in sorted(set(p for a in fic_results.values() for p in a.keys())):\n",
    "        row = {'Group Pair': pair}\n",
    "        for af in fic_framework.alphaF_values:\n",
    "            if af in fic_results and pair in fic_results[af]:\n",
    "                d = fic_results[af][pair]\n",
    "                row[f'alphaF={af}'] = f\"omega={d['omega']:.4f}, FIC={d['fic_score']:.3f}\"\n",
    "                row[f'Hypothesis alphaF={af}'] = \"Fail to reject Ho (Fair)\" if d['omega'] <= af else \"Reject H₀ (Unfair)\"\n",
    "            else:\n",
    "                row[f'alphaF={af}'] = \"N/A\"; row[f'Hypothesis alphaF={af}'] = \"N/A\"\n",
    "        fic_table.append(row)\n",
    "    fic_df = pd.DataFrame(fic_table)\n",
    "    print(\"FIC ANALYSIS TABLE:\")\n",
    "    print(fic_df.to_string(index=False))\n",
    "    fic_df.to_csv(os.path.join(output_dir, f'Case{case_number}_FIC_Analysis.csv'), index=False)\n",
    "\n",
    "    # Tier classification\n",
    "    tier_data = []\n",
    "    print(\"TIER CLASSIFICATION:\")\n",
    "    for af in fic_framework.alphaF_values:\n",
    "        print(f\"\\nFor αF = {af}:\")\n",
    "        print(\"-\" * 50)\n",
    "        if af in fic_results:\n",
    "            for pair, d in fic_results[af].items():\n",
    "                tier = fic_framework.classify_tier(d['fic_score'])\n",
    "                msg = tier if d['fic_score'] <= 0.75 else f\"{tier} (omega_max < {0.25*af:.4f})\"\n",
    "                print(f\"{pair}: ω={d['omega']:.4f}, FIC={d['fic_score']:.3f} → {msg}\")\n",
    "                tier_data.append({'alphaF': af, 'Group Pair': pair, 'ω': d['omega'], 'FIC': d['fic_score'], 'Tier': tier})\n",
    "    tier_df = pd.DataFrame(tier_data)\n",
    "    tier_df.to_csv(os.path.join(output_dir, f'Case{case_number}_Tier_Classification.csv'), index=False)\n",
    "\n",
    "    print(\"GENERATING VISUALIZATIONS...\")\n",
    "    plot_fic_heatmaps(fic_results, f'Case{case_number}_{dataset_name}')\n",
    "    plot_benchmarking_tiers(fic_results, f'Case{case_number}_{dataset_name}')\n",
    "\n",
    "    # Model comparison\n",
    "    print(\"MODEL COMPARISON:\")\n",
    "    comparison = []\n",
    "    for mt in model_types:\n",
    "        mets, test_data = train_and_evaluate_models(data, target_col, protected_col, mt)\n",
    "        model_fic = fic_framework.analyze_fairness(mets, 'accuracy')\n",
    "        avg_fic = np.mean([d['fic_score'] for d in model_fic[0.10].values()]) if 0.10 in model_fic and model_fic[0.10] else np.nan\n",
    "        max_omega = max([d['omega'] for d in model_fic[0.10].values()]) if 0.10 in model_fic and model_fic[0.10] else np.nan\n",
    "        _, y_test, _, y_pred, _ = test_data\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        comparison.append({\n",
    "            'Model': mt.upper(),\n",
    "            'Overall Accuracy': f\"{acc:.4f}\",\n",
    "            'Avg FIC alphaF=0.10)': f\"{avg_fic:.3f}\" if not np.isnan(avg_fic) else \"N/A\",\n",
    "            'ω_max (alphaF=0.10)': f\"{max_omega:.4f}\" if not np.isnan(max_omega) else \"N/A\"\n",
    "        })\n",
    "    comparison_df = pd.DataFrame(comparison)\n",
    "    print(comparison_df.to_string(index=False))\n",
    "    comparison_df.to_csv(os.path.join(output_dir, f'Case{case_number}_Model_Comparison.csv'), index=False)\n",
    "\n",
    "    return {\n",
    "        'data': data,\n",
    "        'baseline_metrics': baseline_metrics,\n",
    "        'fic_results': fic_results,\n",
    "        'metrics_df': metrics_df,\n",
    "        'fic_df': fic_df,\n",
    "        'tier_df': tier_df,\n",
    "        'comparison_df': comparison_df\n",
    "    }\n",
    "\n",
    "# ============================================\n",
    "# 6. MAIN ANALYSIS\n",
    "# ============================================\n",
    "\n",
    "def run_complete_analysis():\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"FAIRNESS INFORMATION CRITERION (FIC) ANALYSIS - COMPAS DATASET\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    compas_results = analyze_dataset(\n",
    "        dataset_name=\"COMPAS - Recidivism Risk Prediction\",\n",
    "        data_generator=lambda: generate_compas_data(8000),\n",
    "        target_col='high_risk',\n",
    "        protected_col='race_group',\n",
    "        case_number=1\n",
    "    )\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"SUMMARY REPORT - COMPAS DATASET\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    print(\"COMPAS DATASET KEY FINDINGS:\")\n",
    "    print(\"-\" * 60)\n",
    "    data = compas_results['data']\n",
    "    print(f\"Total samples: {len(data)}\")\n",
    "    print(f\"High risk proportion: {data['high_risk'].mean():.3f}\")\n",
    "    print(\"\\nRace group distribution:\")\n",
    "    race_dist = data['race_group'].value_counts()\n",
    "    for race, count in race_dist.items():\n",
    "        prop = count / len(data)\n",
    "        print(f\"  {race}: {count} ({prop:.3f})\")\n",
    "    \n",
    "    print(\"\\nHigh risk by race group:\")\n",
    "    for race in sorted(data['race_group'].unique()):\n",
    "        subset = data[data['race_group'] == race]\n",
    "        risk_prop = subset['high_risk'].mean()\n",
    "        print(f\"  {race}: {risk_prop:.3f}\")\n",
    "\n",
    "    print(\"\\nFIC ANALYSIS SUMMARY:\")\n",
    "    print(\"-\" * 60)\n",
    "    for af in [0.05, 0.10, 0.15, 0.20]:\n",
    "        if af in compas_results['fic_results'] and compas_results['fic_results'][af]:\n",
    "            items = list(compas_results['fic_results'][af].items())\n",
    "            max_o = max(d['omega'] for _, d in items)\n",
    "            min_o = min(d['omega'] for _, d in items)\n",
    "            avg_o = np.mean([d['omega'] for _, d in items])\n",
    "            worst_pair = max(items, key=lambda x: x[1]['omega'])[0]\n",
    "            best_pair = min(items, key=lambda x: x[1]['omega'])[0]\n",
    "            print(f\"alphaF={af}:\")\n",
    "            print(f\"  omega range: [{min_o:.4f}, {max_o:.4f}], avg: {avg_o:.4f}\")\n",
    "            print(f\"  Most unfair pair: {worst_pair} (ω={max_o:.4f})\")\n",
    "            print(f\"  Most fair pair: {best_pair} (ω={min_o:.4f})\")\n",
    "            \n",
    "            # Tier distribution\n",
    "            fic = FairnessInformationCriterion()\n",
    "            tiers = {'Optimum': 0, 'Acceptable': 0, 'Questionable': 0, 'Unacceptable': 0}\n",
    "            for d in compas_results['fic_results'][af].values():\n",
    "                tiers[fic.classify_tier(d['fic_score'])] += 1\n",
    "            print(f\"  Tier distribution: {tiers}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ANALYSIS COMPLETE - HIGH-QUALITY PLOTS SAVED\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    return compas_results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Check if dataset exists or download it\n",
    "    compas_results = run_complete_analysis()\n",
    "\n",
    "    print(\"\\nAll analysis completed!\")\n",
    "    print(f\"Results saved to: {output_dir}/\")\n",
    "    print(\"Files include:\")\n",
    "    print(\"  - Group metrics (CSV)\")\n",
    "    print(\"  - FIC analysis tables (CSV)\")\n",
    "    print(\"  - Tier classification (CSV)\")\n",
    "    print(\"  - Model comparison (CSV)\")\n",
    "    print(\"  - FIC heatmaps (PNG)\")\n",
    "    print(\"  - Benchmarking tiers for all alphaF values (PNG)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c27a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#.... Better visual and legends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7bb45f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FAIRNESS INFORMATION CRITERION (FIC) ANALYSIS - COMPAS DATASET\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "CASE 1: COMPAS - Recidivism Risk Prediction\n",
      "================================================================================\n",
      "Loaded COMPAS dataset from local file\n",
      "Original dataset shape: (7214, 53)\n",
      "Processed dataset shape: (7214, 8)\n",
      "Target distribution (high_risk):\n",
      "high_risk\n",
      "0    0.634599\n",
      "1    0.365401\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Race group distribution:\n",
      "race_group\n",
      "African_American    0.512337\n",
      "Caucasian           0.340172\n",
      "Hispanic            0.088301\n",
      "Other_Race          0.059190\n",
      "Name: proportion, dtype: float64\n",
      "GROUP METRICS TABLE (Baseline Logistic Regression):\n",
      "                  accuracy  selection_rate     tpr     tnr     fpr     fnr     ppv     npv      f1     auc\n",
      "African_American    0.6993          0.3501  0.5498  0.8460  0.1540  0.4502  0.7781  0.6568  0.6443  0.7555\n",
      "Caucasian           0.7976          0.1787  0.4531  0.9139  0.0861  0.5469  0.6397  0.8320  0.5305  0.8210\n",
      "Hispanic            0.8305          0.1525  0.4615  0.9348  0.0652  0.5385  0.6667  0.8600  0.5455  0.8443\n",
      "Other_Race          0.8647          0.1353  0.5000  0.9217  0.0783  0.5000  0.5000  0.9217  0.5000  0.8565\n",
      "FIC ANALYSIS TABLE:\n",
      "                   Group Pair              alphaF=0.05   Hypothesis alphaF=0.05               alphaF=0.1    Hypothesis alphaF=0.1              alphaF=0.15   Hypothesis alphaF=0.15              alphaF=0.2    Hypothesis alphaF=0.2\n",
      " African_American - Caucasian omega=0.0984, FIC=-0.967       Reject H₀ (Unfair)  omega=0.0984, FIC=0.016 Fail to reject Ho (Fair)  omega=0.0984, FIC=0.344 Fail to reject Ho (Fair) omega=0.0984, FIC=0.508 Fail to reject Ho (Fair)\n",
      "  African_American - Hispanic omega=0.1312, FIC=-1.625       Reject H₀ (Unfair) omega=0.1312, FIC=-0.312       Reject H₀ (Unfair)  omega=0.1312, FIC=0.125 Fail to reject Ho (Fair) omega=0.1312, FIC=0.344 Fail to reject Ho (Fair)\n",
      "African_American - Other_Race omega=0.1654, FIC=-2.308       Reject H₀ (Unfair) omega=0.1654, FIC=-0.654       Reject H₀ (Unfair) omega=0.1654, FIC=-0.103       Reject H₀ (Unfair) omega=0.1654, FIC=0.173 Fail to reject Ho (Fair)\n",
      "         Caucasian - Hispanic  omega=0.0329, FIC=0.343 Fail to reject Ho (Fair)  omega=0.0329, FIC=0.671 Fail to reject Ho (Fair)  omega=0.0329, FIC=0.781 Fail to reject Ho (Fair) omega=0.0329, FIC=0.836 Fail to reject Ho (Fair)\n",
      "       Caucasian - Other_Race omega=0.0670, FIC=-0.341       Reject H₀ (Unfair)  omega=0.0670, FIC=0.330 Fail to reject Ho (Fair)  omega=0.0670, FIC=0.553 Fail to reject Ho (Fair) omega=0.0670, FIC=0.665 Fail to reject Ho (Fair)\n",
      "        Hispanic - Other_Race  omega=0.0342, FIC=0.317 Fail to reject Ho (Fair)  omega=0.0342, FIC=0.658 Fail to reject Ho (Fair)  omega=0.0342, FIC=0.772 Fail to reject Ho (Fair) omega=0.0342, FIC=0.829 Fail to reject Ho (Fair)\n",
      "TIER CLASSIFICATION:\n",
      "\n",
      "For αF = 0.05:\n",
      "--------------------------------------------------\n",
      "African_American - Caucasian: ω=0.0984, FIC=-0.967 → Unacceptable\n",
      "African_American - Hispanic: ω=0.1312, FIC=-1.625 → Unacceptable\n",
      "African_American - Other_Race: ω=0.1654, FIC=-2.308 → Unacceptable\n",
      "Caucasian - Hispanic: ω=0.0329, FIC=0.343 → Questionable\n",
      "Caucasian - Other_Race: ω=0.0670, FIC=-0.341 → Unacceptable\n",
      "Hispanic - Other_Race: ω=0.0342, FIC=0.317 → Questionable\n",
      "\n",
      "For αF = 0.1:\n",
      "--------------------------------------------------\n",
      "African_American - Caucasian: ω=0.0984, FIC=0.016 → Questionable\n",
      "African_American - Hispanic: ω=0.1312, FIC=-0.312 → Unacceptable\n",
      "African_American - Other_Race: ω=0.1654, FIC=-0.654 → Unacceptable\n",
      "Caucasian - Hispanic: ω=0.0329, FIC=0.671 → Acceptable\n",
      "Caucasian - Other_Race: ω=0.0670, FIC=0.330 → Questionable\n",
      "Hispanic - Other_Race: ω=0.0342, FIC=0.658 → Acceptable\n",
      "\n",
      "For αF = 0.15:\n",
      "--------------------------------------------------\n",
      "African_American - Caucasian: ω=0.0984, FIC=0.344 → Questionable\n",
      "African_American - Hispanic: ω=0.1312, FIC=0.125 → Questionable\n",
      "African_American - Other_Race: ω=0.1654, FIC=-0.103 → Unacceptable\n",
      "Caucasian - Hispanic: ω=0.0329, FIC=0.781 → Optimum (omega_max < 0.0375)\n",
      "Caucasian - Other_Race: ω=0.0670, FIC=0.553 → Acceptable\n",
      "Hispanic - Other_Race: ω=0.0342, FIC=0.772 → Optimum (omega_max < 0.0375)\n",
      "\n",
      "For αF = 0.2:\n",
      "--------------------------------------------------\n",
      "African_American - Caucasian: ω=0.0984, FIC=0.508 → Acceptable\n",
      "African_American - Hispanic: ω=0.1312, FIC=0.344 → Questionable\n",
      "African_American - Other_Race: ω=0.1654, FIC=0.173 → Questionable\n",
      "Caucasian - Hispanic: ω=0.0329, FIC=0.836 → Optimum (omega_max < 0.0500)\n",
      "Caucasian - Other_Race: ω=0.0670, FIC=0.665 → Acceptable\n",
      "Hispanic - Other_Race: ω=0.0342, FIC=0.829 → Optimum (omega_max < 0.0500)\n",
      "GENERATING VISUALIZATIONS...\n",
      "Saved benchmarking tiers plot for alphaF=0.05\n",
      "Saved benchmarking tiers plot for alphaF=0.1\n",
      "Saved benchmarking tiers plot for alphaF=0.15\n",
      "Saved benchmarking tiers plot for alphaF=0.2\n",
      "MODEL COMPARISON:\n",
      "   Model Overall Accuracy Avg FIC alphaF=0.10) ω_max (alphaF=0.10)\n",
      "BASELINE           0.7547                0.118              0.1654\n",
      "      L1           0.7547                0.118              0.1654\n",
      "      L2           0.7547                0.118              0.1654\n",
      "\n",
      "================================================================================\n",
      "SUMMARY REPORT - COMPAS DATASET\n",
      "================================================================================\n",
      "COMPAS DATASET KEY FINDINGS:\n",
      "------------------------------------------------------------\n",
      "Total samples: 7214\n",
      "High risk proportion: 0.365\n",
      "\n",
      "Race group distribution:\n",
      "  African_American: 3696 (0.512)\n",
      "  Caucasian: 2454 (0.340)\n",
      "  Hispanic: 637 (0.088)\n",
      "  Other_Race: 427 (0.059)\n",
      "\n",
      "High risk by race group:\n",
      "  African_American: 0.489\n",
      "  Caucasian: 0.250\n",
      "  Hispanic: 0.217\n",
      "  Other_Race: 0.178\n",
      "\n",
      "FIC ANALYSIS SUMMARY:\n",
      "------------------------------------------------------------\n",
      "alphaF=0.05:\n",
      "  omega range: [0.0329, 0.1654], avg: 0.0882\n",
      "  Most unfair pair: African_American - Other_Race (ω=0.1654)\n",
      "  Most fair pair: Caucasian - Hispanic (ω=0.0329)\n",
      "  Tier distribution: {'Optimum': 0, 'Acceptable': 0, 'Questionable': 2, 'Unacceptable': 4}\n",
      "alphaF=0.1:\n",
      "  omega range: [0.0329, 0.1654], avg: 0.0882\n",
      "  Most unfair pair: African_American - Other_Race (ω=0.1654)\n",
      "  Most fair pair: Caucasian - Hispanic (ω=0.0329)\n",
      "  Tier distribution: {'Optimum': 0, 'Acceptable': 2, 'Questionable': 2, 'Unacceptable': 2}\n",
      "alphaF=0.15:\n",
      "  omega range: [0.0329, 0.1654], avg: 0.0882\n",
      "  Most unfair pair: African_American - Other_Race (ω=0.1654)\n",
      "  Most fair pair: Caucasian - Hispanic (ω=0.0329)\n",
      "  Tier distribution: {'Optimum': 2, 'Acceptable': 1, 'Questionable': 2, 'Unacceptable': 1}\n",
      "alphaF=0.2:\n",
      "  omega range: [0.0329, 0.1654], avg: 0.0882\n",
      "  Most unfair pair: African_American - Other_Race (ω=0.1654)\n",
      "  Most fair pair: Caucasian - Hispanic (ω=0.0329)\n",
      "  Tier distribution: {'Optimum': 2, 'Acceptable': 2, 'Questionable': 2, 'Unacceptable': 0}\n",
      "\n",
      "================================================================================\n",
      "ANALYSIS COMPLETE - HIGH-QUALITY PLOTS SAVED\n",
      "================================================================================\n",
      "\n",
      "All analysis completed!\n",
      "Results saved to: compas_fic_results/\n",
      "Files include:\n",
      "  - Group metrics (CSV)\n",
      "  - FIC analysis tables (CSV)\n",
      "  - Tier classification (CSV)\n",
      "  - Model comparison (CSV)\n",
      "  - FIC heatmaps (PNG)\n",
      "  - Benchmarking tiers for all alphaF values (PNG)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create output directory\n",
    "output_dir = \"compas_fic_results\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Set style for publication quality\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Global font settings for consistency\n",
    "plt.rcParams.update({\n",
    "    'font.size': 12,\n",
    "    'axes.titlesize': 16,\n",
    "    'axes.labelsize': 14,\n",
    "    'xtick.labelsize': 12,\n",
    "    'ytick.labelsize': 12,\n",
    "    'legend.fontsize': 12,\n",
    "})\n",
    "\n",
    "# ============================================\n",
    "# 1. LOAD AND PREPROCESS COMPAS DATASET\n",
    "# ============================================\n",
    "\n",
    "def load_compas_data():\n",
    "    \"\"\"\n",
    "    Load and preprocess COMPAS ProPublica dataset\n",
    "    Source: https://github.com/propublica/compas-analysis\n",
    "    \"\"\"\n",
    "    # Try to load from local file first\n",
    "    try:\n",
    "        compas_df = pd.read_csv(\"compas-scores-two-years.csv\")\n",
    "        print(\"Loaded COMPAS dataset from local file\")\n",
    "    except:\n",
    "        # If local file doesn't exist, download from GitHub\n",
    "        print(\"Downloading COMPAS dataset from GitHub...\")\n",
    "        import requests\n",
    "        url = \"https://raw.githubusercontent.com/propublica/compas-analysis/master/compas-scores-two-years.csv\"\n",
    "        response = requests.get(url)\n",
    "        with open(\"compas-scores-two-years.csv\", \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "        compas_df = pd.read_csv(\"compas-scores-two-years.csv\")\n",
    "        print(\"COMPAS dataset downloaded and loaded\")\n",
    "    \n",
    "    # Basic preprocessing\n",
    "    print(f\"Original dataset shape: {compas_df.shape}\")\n",
    "    \n",
    "    # Filter relevant columns\n",
    "    relevant_columns = [\n",
    "        'age', 'sex', 'race', 'priors_count', 'c_charge_degree',\n",
    "        'juv_fel_count', 'juv_misd_count', 'juv_other_count',\n",
    "        'decile_score', 'two_year_recid'\n",
    "    ]\n",
    "    \n",
    "    # Check which columns exist in the dataset\n",
    "    available_columns = [col for col in relevant_columns if col in compas_df.columns]\n",
    "    compas_df = compas_df[available_columns].copy()\n",
    "    \n",
    "    # Drop rows with missing values\n",
    "    compas_df = compas_df.dropna()\n",
    "    \n",
    "    # Create high_risk target: 0-5 as low risk, 6-10 as high risk\n",
    "    compas_df['high_risk'] = (compas_df['decile_score'] >= 6).astype(int)\n",
    "    \n",
    "    # Consolidate race categories\n",
    "    def consolidate_race(race):\n",
    "        race = str(race).strip().lower()\n",
    "        if 'african' in race or 'black' in race:\n",
    "            return 'African_American'\n",
    "        elif 'caucasian' in race or 'white' in race:\n",
    "            return 'Caucasian'\n",
    "        elif 'hispanic' in race or 'latino' in race:\n",
    "            return 'Hispanic'\n",
    "        elif 'asian' in race or 'arab' in race or 'native' in race or 'other' in race:\n",
    "            return 'Other_Race'\n",
    "        else:\n",
    "            return 'Other_Race'\n",
    "    \n",
    "    compas_df['race_group'] = compas_df['race'].apply(consolidate_race)\n",
    "    \n",
    "    # Filter to keep only our target race groups\n",
    "    target_races = ['African_American', 'Caucasian', 'Hispanic', 'Other_Race']\n",
    "    compas_df = compas_df[compas_df['race_group'].isin(target_races)].copy()\n",
    "    \n",
    "    # Create additional features for better prediction\n",
    "    compas_df['total_juvenile_charges'] = compas_df['juv_fel_count'] + compas_df['juv_misd_count'] + compas_df['juv_other_count']\n",
    "    compas_df['is_felony'] = (compas_df['c_charge_degree'] == 'F').astype(int)\n",
    "    compas_df['age_group'] = pd.cut(compas_df['age'], \n",
    "                                     bins=[0, 25, 35, 45, 55, 100],\n",
    "                                     labels=['18-25', '26-35', '36-45', '46-55', '56+'])\n",
    "    \n",
    "    # Select final columns for analysis\n",
    "    final_columns = [\n",
    "        'age', 'sex', 'race_group', 'priors_count', 'is_felony',\n",
    "        'total_juvenile_charges', 'age_group', 'high_risk'\n",
    "    ]\n",
    "    \n",
    "    # Ensure all columns exist\n",
    "    final_columns = [col for col in final_columns if col in compas_df.columns]\n",
    "    compas_df = compas_df[final_columns]\n",
    "    \n",
    "    print(f\"Processed dataset shape: {compas_df.shape}\")\n",
    "    print(f\"Target distribution (high_risk):\")\n",
    "    print(compas_df['high_risk'].value_counts(normalize=True))\n",
    "    print(f\"\\nRace group distribution:\")\n",
    "    print(compas_df['race_group'].value_counts(normalize=True))\n",
    "    \n",
    "    return compas_df\n",
    "\n",
    "def generate_compas_data(n_samples=None):\n",
    "    \"\"\"\n",
    "    Wrapper function to load COMPAS data\n",
    "    n_samples parameter is kept for compatibility but not used\n",
    "    \"\"\"\n",
    "    data = load_compas_data()\n",
    "    \n",
    "    # If n_samples is specified and smaller than dataset, sample it\n",
    "    if n_samples and n_samples < len(data):\n",
    "        data = data.sample(n=n_samples, random_state=42)\n",
    "    \n",
    "    return data\n",
    "\n",
    "# ============================================\n",
    "# 2-3. MODEL & FIC (unchanged)\n",
    "# ============================================\n",
    "\n",
    "def compute_all_metrics(y_true, y_pred, y_prob):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_true, y_pred),\n",
    "        'selection_rate': (tp + fp) / len(y_true),\n",
    "        'tpr': tp / (tp + fn) if (tp + fn) > 0 else 0,\n",
    "        'tnr': tn / (tn + fp) if (tn + fp) > 0 else 0,\n",
    "        'fpr': fp / (fp + tn) if (fp + tn) > 0 else 0,\n",
    "        'fnr': fn / (tp + fn) if (tp + fn) > 0 else 0,\n",
    "        'ppv': tp / (tp + fp) if (tp + fp) > 0 else 0,\n",
    "        'npv': tn / (tn + fn) if (tn + fn) > 0 else 0,\n",
    "        'f1': f1_score(y_true, y_pred),\n",
    "        'auc': roc_auc_score(y_true, y_prob) if len(np.unique(y_true)) > 1 else np.nan\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "def train_and_evaluate_models(data, target_col, protected_col, model_type='baseline'):\n",
    "    X = data.drop(columns=[target_col, protected_col])\n",
    "    y = data[target_col]\n",
    "    categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "    numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(drop='first'), categorical_cols)\n",
    "    ])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "    protected_test = data.loc[X_test.index, protected_col]\n",
    "\n",
    "    X_train_processed = preprocessor.fit_transform(X_train)\n",
    "    X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "    if model_type == 'baseline':\n",
    "        model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "    elif model_type == 'l1':\n",
    "        model = LogisticRegression(penalty='l1', solver='liblinear', random_state=42, max_iter=1000, C=1.0)\n",
    "    elif model_type == 'l2':\n",
    "        model = LogisticRegression(penalty='l2', random_state=42, max_iter=1000, C=1.0)\n",
    "    else:\n",
    "        model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "    model.fit(X_train_processed, y_train)\n",
    "    y_pred = model.predict(X_test_processed)\n",
    "    y_prob = model.predict_proba(X_test_processed)[:, 1]\n",
    "\n",
    "    group_metrics = {}\n",
    "    for group in protected_test.unique():\n",
    "        mask = protected_test == group\n",
    "        if mask.sum() > 0:\n",
    "            group_metrics[group] = compute_all_metrics(y_test[mask], y_pred[mask], y_prob[mask])\n",
    "\n",
    "    return group_metrics, (X_test, y_test, protected_test, y_pred, y_prob)\n",
    "\n",
    "class FairnessInformationCriterion:\n",
    "    def __init__(self, alphaF_values=[0.05, 0.10, 0.15, 0.20]):\n",
    "        self.alphaF_values = alphaF_values\n",
    "\n",
    "    def compute_omega(self, metric1, metric2):\n",
    "        return abs(metric1 - metric2)\n",
    "\n",
    "    def compute_fic(self, omega, alphaF):\n",
    "        return 1 - (omega / alphaF)\n",
    "\n",
    "    def classify_tier(self, fic_score):\n",
    "        if fic_score > 0.75:\n",
    "            return \"Optimum\"\n",
    "        elif fic_score > 0.50:\n",
    "            return \"Acceptable\"\n",
    "        elif fic_score > 0:\n",
    "            return \"Questionable\"\n",
    "        else:\n",
    "            return \"Unacceptable\"\n",
    "\n",
    "    def analyze_fairness(self, group_metrics, metric_name='accuracy'):\n",
    "        results = {}\n",
    "        groups = list(group_metrics.keys())\n",
    "        for alphaF in self.alphaF_values:\n",
    "            results[alphaF] = {}\n",
    "            for i, g1 in enumerate(groups):\n",
    "                for g2 in groups[i+1:]:\n",
    "                    pair = f\"{g1} - {g2}\"\n",
    "                    m1 = group_metrics[g1].get(metric_name, np.nan)\n",
    "                    m2 = group_metrics[g2].get(metric_name, np.nan)\n",
    "                    if not np.isnan(m1) and not np.isnan(m2):\n",
    "                        omega = self.compute_omega(m1, m2)\n",
    "                        fic_score = self.compute_fic(omega, alphaF)\n",
    "                        tier = self.classify_tier(fic_score)\n",
    "                        results[alphaF][pair] = {\n",
    "                            'omega': omega, 'fic_score': fic_score, 'tier': tier,\n",
    "                            'metric1': m1, 'metric2': m2\n",
    "                        }\n",
    "        return results\n",
    "\n",
    "# ============================================\n",
    "# 4. VISUALIZATIONS\n",
    "# ============================================\n",
    "\n",
    "def plot_fic_heatmaps(fic_results, dataset_name, metric='accuracy'):\n",
    "    alphaF_values = sorted(fic_results.keys())\n",
    "    if not alphaF_values:\n",
    "        return\n",
    "\n",
    "    pairs = list(fic_results[alphaF_values[0]].keys())\n",
    "    all_groups = sorted(set(g for p in pairs for g in p.split(' - ')))\n",
    "\n",
    "    # Larger figure\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(20, 16))\n",
    "    fig.suptitle(f'{dataset_name}: FIC Heatmaps for Different alphaF Values ({metric})',\n",
    "                 fontsize=20, fontweight='bold', y=0.98)\n",
    "\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for idx, alphaF in enumerate(alphaF_values):\n",
    "        ax = axes[idx]\n",
    "        n = len(all_groups)\n",
    "        mat = np.full((n, n), np.nan)\n",
    "        group_idx = {g: i for i, g in enumerate(all_groups)}\n",
    "\n",
    "        for pair, d in fic_results[alphaF].items():\n",
    "            g1, g2 = pair.split(' - ')\n",
    "            i, j = group_idx[g1], group_idx[g2]\n",
    "            mat[i, j] = mat[j, i] = d['fic_score']\n",
    "\n",
    "        im = ax.imshow(mat, cmap='RdYlGn', vmin=-1, vmax=1, aspect='equal')\n",
    "\n",
    "        # Add value labels inside cells (optional - can comment out if too busy)\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                if i != j and not np.isnan(mat[i, j]):\n",
    "                    text = ax.text(j, i, f'{mat[i,j]:.2f}',\n",
    "                                   ha='center', va='center',\n",
    "                                   fontsize=12, fontweight='bold',\n",
    "                                   color='white' if abs(mat[i,j]) > 0.5 else 'black')\n",
    "\n",
    "        ax.set_xticks(range(n))\n",
    "        ax.set_yticks(range(n))\n",
    "        ax.set_xticklabels(all_groups, rotation=45, ha='right', fontsize=13, fontweight='bold')\n",
    "        ax.set_yticklabels(all_groups, fontsize=13, fontweight='bold')\n",
    "        ax.set_title(f'αF = {alphaF}', fontsize=18, fontweight='bold', pad=20)\n",
    "        \n",
    "        # Add grid\n",
    "        ax.set_xticks(np.arange(-.5, n, 1), minor=True)\n",
    "        ax.set_yticks(np.arange(-.5, n, 1), minor=True)\n",
    "        ax.grid(which='minor', color='gray', linestyle='-', linewidth=0.5, alpha=0.3)\n",
    "\n",
    "    # Add a single comprehensive colorbar with tier labels\n",
    "    cbar_ax = fig.add_axes([0.92, 0.15, 0.02, 0.7])  # [left, bottom, width, height]\n",
    "    cbar = fig.colorbar(im, cax=cbar_ax)\n",
    "    cbar.set_label('FIC Score', fontsize=14, fontweight='bold', labelpad=15)\n",
    "    cbar.ax.tick_params(labelsize=12)\n",
    "    \n",
    "    # Add tier annotations on the colorbar\n",
    "    cbar.ax.text(1.5, 0.875, 'Optimum', transform=cbar.ax.transAxes, \n",
    "                 fontsize=11, fontweight='bold', va='center', ha='left', color='darkgreen')\n",
    "    cbar.ax.text(1.5, 0.625, 'Acceptable', transform=cbar.ax.transAxes, \n",
    "                 fontsize=11, fontweight='bold', va='center', ha='left', color='goldenrod')\n",
    "    cbar.ax.text(1.5, 0.375, 'Questionable', transform=cbar.ax.transAxes, \n",
    "                 fontsize=11, fontweight='bold', va='center', ha='left', color='darkorange')\n",
    "    cbar.ax.text(1.5, 0.125, 'Unacceptable', transform=cbar.ax.transAxes, \n",
    "                 fontsize=11, fontweight='bold', va='center', ha='left', color='darkred')\n",
    "    \n",
    "    # Add tier threshold lines on colorbar\n",
    "    cbar.ax.axhline(0.75, color='darkgreen', linestyle='--', linewidth=2, xmax=0.8)\n",
    "    cbar.ax.axhline(0.50, color='goldenrod', linestyle='--', linewidth=2, xmax=0.8)\n",
    "    cbar.ax.axhline(0.00, color='darkred', linestyle='--', linewidth=2, xmax=0.8)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 0.9, 0.95])\n",
    "    plt.savefig(os.path.join(output_dir, f'{dataset_name}_FIC_Heatmaps_{metric}.png'), dpi=400, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def plot_benchmarking_tiers(fic_results, dataset_name, metric='accuracy'):\n",
    "    # Sort alphaF values to ensure consistent order\n",
    "    alphaF_values = sorted(fic_results.keys())\n",
    "    \n",
    "    # Define colors for tiers\n",
    "    colors = {'Optimum': '#2E8B57', 'Acceptable': '#FFD700', \n",
    "              'Questionable': '#FF8C00', 'Unacceptable': '#DC143C'}\n",
    "    \n",
    "    for alphaF in alphaF_values:\n",
    "        if alphaF not in fic_results or not fic_results[alphaF]:\n",
    "            print(f\"No data for alphaF={alphaF} in benchmarking tiers\")\n",
    "            continue\n",
    "        \n",
    "        # Create a more compact figure\n",
    "        fig, ax = plt.subplots(figsize=(14, 8))\n",
    "        \n",
    "        data = fic_results[alphaF]\n",
    "        pairs = list(data.keys())\n",
    "        fic_scores = [data[p]['fic_score'] for p in pairs]\n",
    "        tiers = [data[p]['tier'] for p in pairs]\n",
    "        \n",
    "        # Create bar colors based on tiers\n",
    "        bar_colors = [colors[t] for t in tiers]\n",
    "        \n",
    "        # Create bars with smaller width for more compact look\n",
    "        bars = ax.bar(range(len(pairs)), fic_scores, color=bar_colors, \n",
    "                      edgecolor='black', linewidth=1.2, width=0.6)\n",
    "        \n",
    "        # Add tier threshold lines with better styling\n",
    "       # ax.axhline(0.75, color='darkgreen', linestyle='--', linewidth=2.0, \n",
    "       #            alpha=0.7, label='Optimum Threshold')\n",
    "       # ax.axhline(0.50, color='goldenrod', linestyle='--', linewidth=2.0, \n",
    "       #            alpha=0.7, label='Acceptable Threshold')\n",
    "       # ax.axhline(0.00, color='darkred', linestyle='--', linewidth=2.0, \n",
    "       #            alpha=0.7, label='Unacceptable Threshold')\n",
    "        \n",
    "        # REMOVED value labels on bars as requested\n",
    "        # Only show tier labels at the bottom\n",
    "        for bar, tier in zip(bars, tiers):\n",
    "            ax.text(bar.get_x() + bar.get_width()/2, -0.05,\n",
    "                    tier[:4],  # Show first 4 letters of tier\n",
    "                    ha='center', va='top',\n",
    "                    fontsize=10, fontweight='bold', color='black',\n",
    "                    rotation=45)\n",
    "        \n",
    "        # Customize axes with better labels\n",
    "        ax.set_xlabel('Group Pairs', fontsize=14, fontweight='bold', labelpad=10)\n",
    "        ax.set_ylabel('FIC Score', fontsize=14, fontweight='bold', labelpad=10)\n",
    "        ax.set_title(f'{dataset_name}\\nFIC Benchmarking Tiers ({metric}, αF = {alphaF})',\n",
    "                    fontsize=16, fontweight='bold', pad=15)\n",
    "        \n",
    "        # Set x-ticks with rotation for readability\n",
    "        ax.set_xticks(range(len(pairs)))\n",
    "        ax.set_xticklabels(pairs, rotation=45, ha='right', fontsize=11, fontweight='bold')\n",
    "        \n",
    "        # Set consistent y-axis limits\n",
    "        ax.set_ylim(-0.25, 1.05)\n",
    "        \n",
    "        # Add grid with lighter style\n",
    "        ax.grid(True, axis='y', alpha=0.3, linestyle='-', linewidth=0.5)\n",
    "        ax.grid(True, axis='x', alpha=0.1, linestyle='-', linewidth=0.5)\n",
    "        \n",
    "        # Add better legend\n",
    "        # Create custom legend for tier colors\n",
    "        from matplotlib.patches import Patch\n",
    "        legend_elements = [\n",
    "            Patch(facecolor=colors['Optimum'], edgecolor='black', label='Optimum (FIC > 0.75)'),\n",
    "            Patch(facecolor=colors['Acceptable'], edgecolor='black', label='Acceptable (0.50 < FIC ≤ 0.75)'),\n",
    "            Patch(facecolor=colors['Questionable'], edgecolor='black', label='Questionable (0 < FIC ≤ 0.50)'),\n",
    "            Patch(facecolor=colors['Unacceptable'], edgecolor='black', label='Unacceptable (FIC ≤ 0)'),\n",
    "            plt.Line2D([0], [0], color='darkgreen', linestyle='--', linewidth=2, label='Optimum Threshold'),\n",
    "            plt.Line2D([0], [0], color='goldenrod', linestyle='--', linewidth=2, label='Acceptable Threshold'),\n",
    "            plt.Line2D([0], [0], color='darkred', linestyle='--', linewidth=2, label='Unacceptable Threshold')\n",
    "        ]\n",
    "        \n",
    "        # Place legend outside the plot\n",
    "        ax.legend(handles=legend_elements, fontsize=9, \n",
    "                  loc='center left', bbox_to_anchor=(1.02, 0.5),\n",
    "                  frameon=True, framealpha=0.9, edgecolor='black',\n",
    "                  title='FIC Tiers', title_fontsize=10)\n",
    "        \n",
    "        # Add annotation for alphaF interpretation\n",
    "        annotation_text = f'αF = {alphaF}\\nFIC = 1 - (ω/αF)\\nω = |metric₁ - metric₂|'\n",
    "        ax.text(0.02, 0.98, annotation_text, transform=ax.transAxes,\n",
    "                fontsize=9, verticalalignment='top',\n",
    "                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
    "        \n",
    "        # Adjust layout to make room for legend\n",
    "        plt.tight_layout(rect=[0, 0, 0.85, 1])\n",
    "        \n",
    "        # Save the figure with alphaF in the filename\n",
    "        plt.savefig(os.path.join(output_dir, f'{dataset_name}_Benchmarking_Tiers_alphaF_{alphaF}_{metric}.png'), \n",
    "                    dpi=400, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        print(f\"Saved benchmarking tiers plot for alphaF={alphaF}\")\n",
    "\n",
    "# ============================================\n",
    "# 5. ANALYSIS FUNCTIONS\n",
    "# ============================================\n",
    "\n",
    "def analyze_dataset(dataset_name, data_generator, target_col, protected_col, case_number=1, model_types=['baseline', 'l1', 'l2']):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"CASE {case_number}: {dataset_name}\")\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "    data = data_generator()\n",
    "    fic_framework = FairnessInformationCriterion()\n",
    "\n",
    "    baseline_metrics, _ = train_and_evaluate_models(data, target_col, protected_col, 'baseline')\n",
    "\n",
    "    metrics_df = pd.DataFrame.from_dict(baseline_metrics, orient='index')\n",
    "    metrics_df = metrics_df[['accuracy', 'selection_rate', 'tpr', 'tnr', 'fpr', 'fnr', 'ppv', 'npv', 'f1', 'auc']]\n",
    "    print(\"GROUP METRICS TABLE (Baseline Logistic Regression):\")\n",
    "    print(metrics_df.round(4).to_string())\n",
    "    metrics_df.to_csv(os.path.join(output_dir, f'Case{case_number}_Group_Metrics.csv'))\n",
    "\n",
    "    fic_results = fic_framework.analyze_fairness(baseline_metrics, 'accuracy')\n",
    "\n",
    "    # FIC table\n",
    "    fic_table = []\n",
    "    for pair in sorted(set(p for a in fic_results.values() for p in a.keys())):\n",
    "        row = {'Group Pair': pair}\n",
    "        for af in fic_framework.alphaF_values:\n",
    "            if af in fic_results and pair in fic_results[af]:\n",
    "                d = fic_results[af][pair]\n",
    "                row[f'alphaF={af}'] = f\"omega={d['omega']:.4f}, FIC={d['fic_score']:.3f}\"\n",
    "                row[f'Hypothesis alphaF={af}'] = \"Fail to reject Ho (Fair)\" if d['omega'] <= af else \"Reject H₀ (Unfair)\"\n",
    "            else:\n",
    "                row[f'alphaF={af}'] = \"N/A\"; row[f'Hypothesis alphaF={af}'] = \"N/A\"\n",
    "        fic_table.append(row)\n",
    "    fic_df = pd.DataFrame(fic_table)\n",
    "    print(\"FIC ANALYSIS TABLE:\")\n",
    "    print(fic_df.to_string(index=False))\n",
    "    fic_df.to_csv(os.path.join(output_dir, f'Case{case_number}_FIC_Analysis.csv'), index=False)\n",
    "\n",
    "    # Tier classification\n",
    "    tier_data = []\n",
    "    print(\"TIER CLASSIFICATION:\")\n",
    "    for af in fic_framework.alphaF_values:\n",
    "        print(f\"\\nFor αF = {af}:\")\n",
    "        print(\"-\" * 50)\n",
    "        if af in fic_results:\n",
    "            for pair, d in fic_results[af].items():\n",
    "                tier = fic_framework.classify_tier(d['fic_score'])\n",
    "                msg = tier if d['fic_score'] <= 0.75 else f\"{tier} (omega_max < {0.25*af:.4f})\"\n",
    "                print(f\"{pair}: ω={d['omega']:.4f}, FIC={d['fic_score']:.3f} → {msg}\")\n",
    "                tier_data.append({'alphaF': af, 'Group Pair': pair, 'ω': d['omega'], 'FIC': d['fic_score'], 'Tier': tier})\n",
    "    tier_df = pd.DataFrame(tier_data)\n",
    "    tier_df.to_csv(os.path.join(output_dir, f'Case{case_number}_Tier_Classification.csv'), index=False)\n",
    "\n",
    "    print(\"GENERATING VISUALIZATIONS...\")\n",
    "    plot_fic_heatmaps(fic_results, f'Case{case_number}_{dataset_name}')\n",
    "    plot_benchmarking_tiers(fic_results, f'Case{case_number}_{dataset_name}')\n",
    "\n",
    "    # Model comparison\n",
    "    print(\"MODEL COMPARISON:\")\n",
    "    comparison = []\n",
    "    for mt in model_types:\n",
    "        mets, test_data = train_and_evaluate_models(data, target_col, protected_col, mt)\n",
    "        model_fic = fic_framework.analyze_fairness(mets, 'accuracy')\n",
    "        avg_fic = np.mean([d['fic_score'] for d in model_fic[0.10].values()]) if 0.10 in model_fic and model_fic[0.10] else np.nan\n",
    "        max_omega = max([d['omega'] for d in model_fic[0.10].values()]) if 0.10 in model_fic and model_fic[0.10] else np.nan\n",
    "        _, y_test, _, y_pred, _ = test_data\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        comparison.append({\n",
    "            'Model': mt.upper(),\n",
    "            'Overall Accuracy': f\"{acc:.4f}\",\n",
    "            'Avg FIC alphaF=0.10)': f\"{avg_fic:.3f}\" if not np.isnan(avg_fic) else \"N/A\",\n",
    "            'ω_max (alphaF=0.10)': f\"{max_omega:.4f}\" if not np.isnan(max_omega) else \"N/A\"\n",
    "        })\n",
    "    comparison_df = pd.DataFrame(comparison)\n",
    "    print(comparison_df.to_string(index=False))\n",
    "    comparison_df.to_csv(os.path.join(output_dir, f'Case{case_number}_Model_Comparison.csv'), index=False)\n",
    "\n",
    "    return {\n",
    "        'data': data,\n",
    "        'baseline_metrics': baseline_metrics,\n",
    "        'fic_results': fic_results,\n",
    "        'metrics_df': metrics_df,\n",
    "        'fic_df': fic_df,\n",
    "        'tier_df': tier_df,\n",
    "        'comparison_df': comparison_df\n",
    "    }\n",
    "\n",
    "# ============================================\n",
    "# 6. MAIN ANALYSIS\n",
    "# ============================================\n",
    "\n",
    "def run_complete_analysis():\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"FAIRNESS INFORMATION CRITERION (FIC) ANALYSIS - COMPAS DATASET\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    compas_results = analyze_dataset(\n",
    "        dataset_name=\"COMPAS - Recidivism Risk Prediction\",\n",
    "        data_generator=lambda: generate_compas_data(8000),\n",
    "        target_col='high_risk',\n",
    "        protected_col='race_group',\n",
    "        case_number=1\n",
    "    )\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"SUMMARY REPORT - COMPAS DATASET\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    print(\"COMPAS DATASET KEY FINDINGS:\")\n",
    "    print(\"-\" * 60)\n",
    "    data = compas_results['data']\n",
    "    print(f\"Total samples: {len(data)}\")\n",
    "    print(f\"High risk proportion: {data['high_risk'].mean():.3f}\")\n",
    "    print(\"\\nRace group distribution:\")\n",
    "    race_dist = data['race_group'].value_counts()\n",
    "    for race, count in race_dist.items():\n",
    "        prop = count / len(data)\n",
    "        print(f\"  {race}: {count} ({prop:.3f})\")\n",
    "    \n",
    "    print(\"\\nHigh risk by race group:\")\n",
    "    for race in sorted(data['race_group'].unique()):\n",
    "        subset = data[data['race_group'] == race]\n",
    "        risk_prop = subset['high_risk'].mean()\n",
    "        print(f\"  {race}: {risk_prop:.3f}\")\n",
    "\n",
    "    print(\"\\nFIC ANALYSIS SUMMARY:\")\n",
    "    print(\"-\" * 60)\n",
    "    for af in [0.05, 0.10, 0.15, 0.20]:\n",
    "        if af in compas_results['fic_results'] and compas_results['fic_results'][af]:\n",
    "            items = list(compas_results['fic_results'][af].items())\n",
    "            max_o = max(d['omega'] for _, d in items)\n",
    "            min_o = min(d['omega'] for _, d in items)\n",
    "            avg_o = np.mean([d['omega'] for _, d in items])\n",
    "            worst_pair = max(items, key=lambda x: x[1]['omega'])[0]\n",
    "            best_pair = min(items, key=lambda x: x[1]['omega'])[0]\n",
    "            print(f\"alphaF={af}:\")\n",
    "            print(f\"  omega range: [{min_o:.4f}, {max_o:.4f}], avg: {avg_o:.4f}\")\n",
    "            print(f\"  Most unfair pair: {worst_pair} (ω={max_o:.4f})\")\n",
    "            print(f\"  Most fair pair: {best_pair} (ω={min_o:.4f})\")\n",
    "            \n",
    "            # Tier distribution\n",
    "            fic = FairnessInformationCriterion()\n",
    "            tiers = {'Optimum': 0, 'Acceptable': 0, 'Questionable': 0, 'Unacceptable': 0}\n",
    "            for d in compas_results['fic_results'][af].values():\n",
    "                tiers[fic.classify_tier(d['fic_score'])] += 1\n",
    "            print(f\"  Tier distribution: {tiers}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ANALYSIS COMPLETE - HIGH-QUALITY PLOTS SAVED\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    return compas_results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Check if dataset exists or download it\n",
    "    compas_results = run_complete_analysis()\n",
    "\n",
    "    print(\"\\nAll analysis completed!\")\n",
    "    print(f\"Results saved to: {output_dir}/\")\n",
    "    print(\"Files include:\")\n",
    "    print(\"  - Group metrics (CSV)\")\n",
    "    print(\"  - FIC analysis tables (CSV)\")\n",
    "    print(\"  - Tier classification (CSV)\")\n",
    "    print(\"  - Model comparison (CSV)\")\n",
    "    print(\"  - FIC heatmaps (PNG)\")\n",
    "    print(\"  - Benchmarking tiers for all alphaF values (PNG)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c68aff4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8d05bee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FAIRNESS INFORMATION CRITERION (FIC) ANALYSIS - COMPAS DATASET\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "CASE 1: COMPAS - Recidivism Risk Prediction\n",
      "================================================================================\n",
      "Loaded COMPAS dataset from local file\n",
      "Original dataset shape: (7214, 53)\n",
      "Processed dataset shape: (7214, 8)\n",
      "Target distribution (high_risk):\n",
      "high_risk\n",
      "0    0.634599\n",
      "1    0.365401\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Race group distribution:\n",
      "race_group\n",
      "African_American    0.512337\n",
      "Caucasian           0.340172\n",
      "Hispanic            0.088301\n",
      "Other_Race          0.059190\n",
      "Name: proportion, dtype: float64\n",
      "GROUP METRICS TABLE (Baseline Logistic Regression):\n",
      "                  accuracy  selection_rate     tpr     tnr     fpr     fnr     ppv     npv      f1     auc\n",
      "African_American    0.6993          0.3501  0.5498  0.8460  0.1540  0.4502  0.7781  0.6568  0.6443  0.7555\n",
      "Caucasian           0.7976          0.1787  0.4531  0.9139  0.0861  0.5469  0.6397  0.8320  0.5305  0.8210\n",
      "Hispanic            0.8305          0.1525  0.4615  0.9348  0.0652  0.5385  0.6667  0.8600  0.5455  0.8443\n",
      "Other_Race          0.8647          0.1353  0.5000  0.9217  0.0783  0.5000  0.5000  0.9217  0.5000  0.8565\n",
      "FIC ANALYSIS TABLE:\n",
      "                   Group Pair              alphaF=0.05   Hypothesis alphaF=0.05               alphaF=0.1    Hypothesis alphaF=0.1              alphaF=0.15   Hypothesis alphaF=0.15              alphaF=0.2    Hypothesis alphaF=0.2\n",
      " African_American - Caucasian omega=0.0984, FIC=-0.967       Reject H₀ (Unfair)  omega=0.0984, FIC=0.016 Fail to reject Ho (Fair)  omega=0.0984, FIC=0.344 Fail to reject Ho (Fair) omega=0.0984, FIC=0.508 Fail to reject Ho (Fair)\n",
      "  African_American - Hispanic omega=0.1312, FIC=-1.625       Reject H₀ (Unfair) omega=0.1312, FIC=-0.312       Reject H₀ (Unfair)  omega=0.1312, FIC=0.125 Fail to reject Ho (Fair) omega=0.1312, FIC=0.344 Fail to reject Ho (Fair)\n",
      "African_American - Other_Race omega=0.1654, FIC=-2.308       Reject H₀ (Unfair) omega=0.1654, FIC=-0.654       Reject H₀ (Unfair) omega=0.1654, FIC=-0.103       Reject H₀ (Unfair) omega=0.1654, FIC=0.173 Fail to reject Ho (Fair)\n",
      "         Caucasian - Hispanic  omega=0.0329, FIC=0.343 Fail to reject Ho (Fair)  omega=0.0329, FIC=0.671 Fail to reject Ho (Fair)  omega=0.0329, FIC=0.781 Fail to reject Ho (Fair) omega=0.0329, FIC=0.836 Fail to reject Ho (Fair)\n",
      "       Caucasian - Other_Race omega=0.0670, FIC=-0.341       Reject H₀ (Unfair)  omega=0.0670, FIC=0.330 Fail to reject Ho (Fair)  omega=0.0670, FIC=0.553 Fail to reject Ho (Fair) omega=0.0670, FIC=0.665 Fail to reject Ho (Fair)\n",
      "        Hispanic - Other_Race  omega=0.0342, FIC=0.317 Fail to reject Ho (Fair)  omega=0.0342, FIC=0.658 Fail to reject Ho (Fair)  omega=0.0342, FIC=0.772 Fail to reject Ho (Fair) omega=0.0342, FIC=0.829 Fail to reject Ho (Fair)\n",
      "TIER CLASSIFICATION:\n",
      "\n",
      "For αF = 0.05:\n",
      "--------------------------------------------------\n",
      "African_American - Caucasian: ω=0.0984, FIC=-0.967 → Unacceptable\n",
      "African_American - Hispanic: ω=0.1312, FIC=-1.625 → Unacceptable\n",
      "African_American - Other_Race: ω=0.1654, FIC=-2.308 → Unacceptable\n",
      "Caucasian - Hispanic: ω=0.0329, FIC=0.343 → Questionable\n",
      "Caucasian - Other_Race: ω=0.0670, FIC=-0.341 → Unacceptable\n",
      "Hispanic - Other_Race: ω=0.0342, FIC=0.317 → Questionable\n",
      "\n",
      "For αF = 0.1:\n",
      "--------------------------------------------------\n",
      "African_American - Caucasian: ω=0.0984, FIC=0.016 → Questionable\n",
      "African_American - Hispanic: ω=0.1312, FIC=-0.312 → Unacceptable\n",
      "African_American - Other_Race: ω=0.1654, FIC=-0.654 → Unacceptable\n",
      "Caucasian - Hispanic: ω=0.0329, FIC=0.671 → Acceptable\n",
      "Caucasian - Other_Race: ω=0.0670, FIC=0.330 → Questionable\n",
      "Hispanic - Other_Race: ω=0.0342, FIC=0.658 → Acceptable\n",
      "\n",
      "For αF = 0.15:\n",
      "--------------------------------------------------\n",
      "African_American - Caucasian: ω=0.0984, FIC=0.344 → Questionable\n",
      "African_American - Hispanic: ω=0.1312, FIC=0.125 → Questionable\n",
      "African_American - Other_Race: ω=0.1654, FIC=-0.103 → Unacceptable\n",
      "Caucasian - Hispanic: ω=0.0329, FIC=0.781 → Optimum (omega_max < 0.0375)\n",
      "Caucasian - Other_Race: ω=0.0670, FIC=0.553 → Acceptable\n",
      "Hispanic - Other_Race: ω=0.0342, FIC=0.772 → Optimum (omega_max < 0.0375)\n",
      "\n",
      "For αF = 0.2:\n",
      "--------------------------------------------------\n",
      "African_American - Caucasian: ω=0.0984, FIC=0.508 → Acceptable\n",
      "African_American - Hispanic: ω=0.1312, FIC=0.344 → Questionable\n",
      "African_American - Other_Race: ω=0.1654, FIC=0.173 → Questionable\n",
      "Caucasian - Hispanic: ω=0.0329, FIC=0.836 → Optimum (omega_max < 0.0500)\n",
      "Caucasian - Other_Race: ω=0.0670, FIC=0.665 → Acceptable\n",
      "Hispanic - Other_Race: ω=0.0342, FIC=0.829 → Optimum (omega_max < 0.0500)\n",
      "GENERATING VISUALIZATIONS...\n",
      "Saved benchmarking tiers plot for alphaF=0.05\n",
      "Saved benchmarking tiers plot for alphaF=0.1\n",
      "Saved benchmarking tiers plot for alphaF=0.15\n",
      "Saved benchmarking tiers plot for alphaF=0.2\n",
      "MODEL COMPARISON:\n",
      "   Model Overall Accuracy Avg FIC alphaF=0.10) ω_max (alphaF=0.10)\n",
      "BASELINE           0.7547                0.118              0.1654\n",
      "      L1           0.7547                0.118              0.1654\n",
      "      L2           0.7547                0.118              0.1654\n",
      "\n",
      "================================================================================\n",
      "SUMMARY REPORT - COMPAS DATASET\n",
      "================================================================================\n",
      "COMPAS DATASET KEY FINDINGS:\n",
      "------------------------------------------------------------\n",
      "Total samples: 7214\n",
      "High risk proportion: 0.365\n",
      "\n",
      "Race group distribution:\n",
      "  African_American: 3696 (0.512)\n",
      "  Caucasian: 2454 (0.340)\n",
      "  Hispanic: 637 (0.088)\n",
      "  Other_Race: 427 (0.059)\n",
      "\n",
      "High risk by race group:\n",
      "  African_American: 0.489\n",
      "  Caucasian: 0.250\n",
      "  Hispanic: 0.217\n",
      "  Other_Race: 0.178\n",
      "\n",
      "FIC ANALYSIS SUMMARY:\n",
      "------------------------------------------------------------\n",
      "alphaF=0.05:\n",
      "  omega range: [0.0329, 0.1654], avg: 0.0882\n",
      "  Most unfair pair: African_American - Other_Race (ω=0.1654)\n",
      "  Most fair pair: Caucasian - Hispanic (ω=0.0329)\n",
      "  Tier distribution: {'Optimum': 0, 'Acceptable': 0, 'Questionable': 2, 'Unacceptable': 4}\n",
      "alphaF=0.1:\n",
      "  omega range: [0.0329, 0.1654], avg: 0.0882\n",
      "  Most unfair pair: African_American - Other_Race (ω=0.1654)\n",
      "  Most fair pair: Caucasian - Hispanic (ω=0.0329)\n",
      "  Tier distribution: {'Optimum': 0, 'Acceptable': 2, 'Questionable': 2, 'Unacceptable': 2}\n",
      "alphaF=0.15:\n",
      "  omega range: [0.0329, 0.1654], avg: 0.0882\n",
      "  Most unfair pair: African_American - Other_Race (ω=0.1654)\n",
      "  Most fair pair: Caucasian - Hispanic (ω=0.0329)\n",
      "  Tier distribution: {'Optimum': 2, 'Acceptable': 1, 'Questionable': 2, 'Unacceptable': 1}\n",
      "alphaF=0.2:\n",
      "  omega range: [0.0329, 0.1654], avg: 0.0882\n",
      "  Most unfair pair: African_American - Other_Race (ω=0.1654)\n",
      "  Most fair pair: Caucasian - Hispanic (ω=0.0329)\n",
      "  Tier distribution: {'Optimum': 2, 'Acceptable': 2, 'Questionable': 2, 'Unacceptable': 0}\n",
      "\n",
      "================================================================================\n",
      "ANALYSIS COMPLETE - HIGH-QUALITY PLOTS SAVED\n",
      "================================================================================\n",
      "\n",
      "All analysis completed!\n",
      "Results saved to: compas_fic_results_BOLD/\n",
      "Files include:\n",
      "  - Group metrics (CSV)\n",
      "  - FIC analysis tables (CSV)\n",
      "  - Tier classification (CSV)\n",
      "  - Model comparison (CSV)\n",
      "  - FIC heatmaps (PNG)\n",
      "  - Benchmarking tiers for all alphaF values (PNG)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create output directory\n",
    "output_dir = \"compas_fic_results_BOLD\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Set style for publication quality\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Global font settings for consistency\n",
    "plt.rcParams.update({\n",
    "    'font.size': 12,\n",
    "    'axes.titlesize': 16,\n",
    "    'axes.labelsize': 14,\n",
    "    'xtick.labelsize': 12,\n",
    "    'ytick.labelsize': 12,\n",
    "    'legend.fontsize': 12,\n",
    "})\n",
    "\n",
    "# ============================================\n",
    "# 1. LOAD AND PREPROCESS COMPAS DATASET\n",
    "# ============================================\n",
    "\n",
    "def load_compas_data():\n",
    "    \"\"\"\n",
    "    Load and preprocess COMPAS ProPublica dataset\n",
    "    Source: https://github.com/propublica/compas-analysis\n",
    "    \"\"\"\n",
    "    # Try to load from local file first\n",
    "    try:\n",
    "        compas_df = pd.read_csv(\"compas-scores-two-years.csv\")\n",
    "        print(\"Loaded COMPAS dataset from local file\")\n",
    "    except:\n",
    "        # If local file doesn't exist, download from GitHub\n",
    "        print(\"Downloading COMPAS dataset from GitHub...\")\n",
    "        import requests\n",
    "        url = \"https://raw.githubusercontent.com/propublica/compas-analysis/master/compas-scores-two-years.csv\"\n",
    "        response = requests.get(url)\n",
    "        with open(\"compas-scores-two-years.csv\", \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "        compas_df = pd.read_csv(\"compas-scores-two-years.csv\")\n",
    "        print(\"COMPAS dataset downloaded and loaded\")\n",
    "    \n",
    "    # Basic preprocessing\n",
    "    print(f\"Original dataset shape: {compas_df.shape}\")\n",
    "    \n",
    "    # Filter relevant columns\n",
    "    relevant_columns = [\n",
    "        'age', 'sex', 'race', 'priors_count', 'c_charge_degree',\n",
    "        'juv_fel_count', 'juv_misd_count', 'juv_other_count',\n",
    "        'decile_score', 'two_year_recid'\n",
    "    ]\n",
    "    \n",
    "    # Check which columns exist in the dataset\n",
    "    available_columns = [col for col in relevant_columns if col in compas_df.columns]\n",
    "    compas_df = compas_df[available_columns].copy()\n",
    "    \n",
    "    # Drop rows with missing values\n",
    "    compas_df = compas_df.dropna()\n",
    "    \n",
    "    # Create high_risk target: 0-5 as low risk, 6-10 as high risk\n",
    "    compas_df['high_risk'] = (compas_df['decile_score'] >= 6).astype(int)\n",
    "    \n",
    "    # Consolidate race categories\n",
    "    def consolidate_race(race):\n",
    "        race = str(race).strip().lower()\n",
    "        if 'african' in race or 'black' in race:\n",
    "            return 'African_American'\n",
    "        elif 'caucasian' in race or 'white' in race:\n",
    "            return 'Caucasian'\n",
    "        elif 'hispanic' in race or 'latino' in race:\n",
    "            return 'Hispanic'\n",
    "        elif 'asian' in race or 'arab' in race or 'native' in race or 'other' in race:\n",
    "            return 'Other_Race'\n",
    "        else:\n",
    "            return 'Other_Race'\n",
    "    \n",
    "    compas_df['race_group'] = compas_df['race'].apply(consolidate_race)\n",
    "    \n",
    "    # Filter to keep only our target race groups\n",
    "    target_races = ['African_American', 'Caucasian', 'Hispanic', 'Other_Race']\n",
    "    compas_df = compas_df[compas_df['race_group'].isin(target_races)].copy()\n",
    "    \n",
    "    # Create additional features for better prediction\n",
    "    compas_df['total_juvenile_charges'] = compas_df['juv_fel_count'] + compas_df['juv_misd_count'] + compas_df['juv_other_count']\n",
    "    compas_df['is_felony'] = (compas_df['c_charge_degree'] == 'F').astype(int)\n",
    "    compas_df['age_group'] = pd.cut(compas_df['age'], \n",
    "                                     bins=[0, 25, 35, 45, 55, 100],\n",
    "                                     labels=['18-25', '26-35', '36-45', '46-55', '56+'])\n",
    "    \n",
    "    # Select final columns for analysis\n",
    "    final_columns = [\n",
    "        'age', 'sex', 'race_group', 'priors_count', 'is_felony',\n",
    "        'total_juvenile_charges', 'age_group', 'high_risk'\n",
    "    ]\n",
    "    \n",
    "    # Ensure all columns exist\n",
    "    final_columns = [col for col in final_columns if col in compas_df.columns]\n",
    "    compas_df = compas_df[final_columns]\n",
    "    \n",
    "    print(f\"Processed dataset shape: {compas_df.shape}\")\n",
    "    print(f\"Target distribution (high_risk):\")\n",
    "    print(compas_df['high_risk'].value_counts(normalize=True))\n",
    "    print(f\"\\nRace group distribution:\")\n",
    "    print(compas_df['race_group'].value_counts(normalize=True))\n",
    "    \n",
    "    return compas_df\n",
    "\n",
    "def generate_compas_data(n_samples=None):\n",
    "    \"\"\"\n",
    "    Wrapper function to load COMPAS data\n",
    "    n_samples parameter is kept for compatibility but not used\n",
    "    \"\"\"\n",
    "    data = load_compas_data()\n",
    "    \n",
    "    # If n_samples is specified and smaller than dataset, sample it\n",
    "    if n_samples and n_samples < len(data):\n",
    "        data = data.sample(n=n_samples, random_state=42)\n",
    "    \n",
    "    return data\n",
    "\n",
    "# ============================================\n",
    "# 2-3. MODEL & FIC (unchanged)\n",
    "# ============================================\n",
    "\n",
    "def compute_all_metrics(y_true, y_pred, y_prob):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_true, y_pred),\n",
    "        'selection_rate': (tp + fp) / len(y_true),\n",
    "        'tpr': tp / (tp + fn) if (tp + fn) > 0 else 0,\n",
    "        'tnr': tn / (tn + fp) if (tn + fp) > 0 else 0,\n",
    "        'fpr': fp / (fp + tn) if (fp + tn) > 0 else 0,\n",
    "        'fnr': fn / (tp + fn) if (tp + fn) > 0 else 0,\n",
    "        'ppv': tp / (tp + fp) if (tp + fp) > 0 else 0,\n",
    "        'npv': tn / (tn + fn) if (tn + fn) > 0 else 0,\n",
    "        'f1': f1_score(y_true, y_pred),\n",
    "        'auc': roc_auc_score(y_true, y_prob) if len(np.unique(y_true)) > 1 else np.nan\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "def train_and_evaluate_models(data, target_col, protected_col, model_type='baseline'):\n",
    "    X = data.drop(columns=[target_col, protected_col])\n",
    "    y = data[target_col]\n",
    "    categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "    numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(drop='first'), categorical_cols)\n",
    "    ])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "    protected_test = data.loc[X_test.index, protected_col]\n",
    "\n",
    "    X_train_processed = preprocessor.fit_transform(X_train)\n",
    "    X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "    if model_type == 'baseline':\n",
    "        model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "    elif model_type == 'l1':\n",
    "        model = LogisticRegression(penalty='l1', solver='liblinear', random_state=42, max_iter=1000, C=1.0)\n",
    "    elif model_type == 'l2':\n",
    "        model = LogisticRegression(penalty='l2', random_state=42, max_iter=1000, C=1.0)\n",
    "    else:\n",
    "        model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "    model.fit(X_train_processed, y_train)\n",
    "    y_pred = model.predict(X_test_processed)\n",
    "    y_prob = model.predict_proba(X_test_processed)[:, 1]\n",
    "\n",
    "    group_metrics = {}\n",
    "    for group in protected_test.unique():\n",
    "        mask = protected_test == group\n",
    "        if mask.sum() > 0:\n",
    "            group_metrics[group] = compute_all_metrics(y_test[mask], y_pred[mask], y_prob[mask])\n",
    "\n",
    "    return group_metrics, (X_test, y_test, protected_test, y_pred, y_prob)\n",
    "\n",
    "class FairnessInformationCriterion:\n",
    "    def __init__(self, alphaF_values=[0.05, 0.10, 0.15, 0.20]):\n",
    "        self.alphaF_values = alphaF_values\n",
    "\n",
    "    def compute_omega(self, metric1, metric2):\n",
    "        return abs(metric1 - metric2)\n",
    "\n",
    "    def compute_fic(self, omega, alphaF):\n",
    "        return 1 - (omega / alphaF)\n",
    "\n",
    "    def classify_tier(self, fic_score):\n",
    "        if fic_score > 0.75:\n",
    "            return \"Optimum\"\n",
    "        elif fic_score > 0.50:\n",
    "            return \"Acceptable\"\n",
    "        elif fic_score > 0:\n",
    "            return \"Questionable\"\n",
    "        else:\n",
    "            return \"Unacceptable\"\n",
    "\n",
    "    def analyze_fairness(self, group_metrics, metric_name='accuracy'):\n",
    "        results = {}\n",
    "        groups = list(group_metrics.keys())\n",
    "        for alphaF in self.alphaF_values:\n",
    "            results[alphaF] = {}\n",
    "            for i, g1 in enumerate(groups):\n",
    "                for g2 in groups[i+1:]:\n",
    "                    pair = f\"{g1} - {g2}\"\n",
    "                    m1 = group_metrics[g1].get(metric_name, np.nan)\n",
    "                    m2 = group_metrics[g2].get(metric_name, np.nan)\n",
    "                    if not np.isnan(m1) and not np.isnan(m2):\n",
    "                        omega = self.compute_omega(m1, m2)\n",
    "                        fic_score = self.compute_fic(omega, alphaF)\n",
    "                        tier = self.classify_tier(fic_score)\n",
    "                        results[alphaF][pair] = {\n",
    "                            'omega': omega, 'fic_score': fic_score, 'tier': tier,\n",
    "                            'metric1': m1, 'metric2': m2\n",
    "                        }\n",
    "        return results\n",
    "\n",
    "# ============================================\n",
    "# 4. VISUALIZATIONS\n",
    "# ============================================\n",
    "\n",
    "def plot_fic_heatmaps(fic_results, dataset_name, metric='accuracy'):\n",
    "    alphaF_values = sorted(fic_results.keys())\n",
    "    if not alphaF_values:\n",
    "        return\n",
    "\n",
    "    pairs = list(fic_results[alphaF_values[0]].keys())\n",
    "    all_groups = sorted(set(g for p in pairs for g in p.split(' - ')))\n",
    "\n",
    "    # Larger figure\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(20, 16))\n",
    "    fig.suptitle(f'{dataset_name}: FIC Heatmaps for Different alphaF Values ({metric})',\n",
    "                 fontsize=20, fontweight='bold', y=0.98)\n",
    "\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for idx, alphaF in enumerate(alphaF_values):\n",
    "        ax = axes[idx]\n",
    "        n = len(all_groups)\n",
    "        mat = np.full((n, n), np.nan)\n",
    "        group_idx = {g: i for i, g in enumerate(all_groups)}\n",
    "\n",
    "        for pair, d in fic_results[alphaF].items():\n",
    "            g1, g2 = pair.split(' - ')\n",
    "            i, j = group_idx[g1], group_idx[g2]\n",
    "            mat[i, j] = mat[j, i] = d['fic_score']\n",
    "\n",
    "        im = ax.imshow(mat, cmap='RdYlGn', vmin=-1, vmax=1, aspect='equal')\n",
    "\n",
    "        # Add value labels inside cells\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                if i != j and not np.isnan(mat[i, j]):\n",
    "                    text = ax.text(j, i, f'{mat[i,j]:.2f}',\n",
    "                                   ha='center', va='center',\n",
    "                                   fontsize=14, fontweight='bold',\n",
    "                                   color='white' if abs(mat[i,j]) > 0.5 else 'black')\n",
    "\n",
    "        ax.set_xticks(range(n))\n",
    "        ax.set_yticks(range(n))\n",
    "        ax.set_xticklabels(all_groups, rotation=45, ha='right', fontsize=13, fontweight='bold')\n",
    "        ax.set_yticklabels(all_groups, fontsize=13, fontweight='bold')\n",
    "        ax.set_title(f'αF = {alphaF}', fontsize=18, fontweight='bold', pad=20)\n",
    "        \n",
    "        # Add grid\n",
    "        ax.set_xticks(np.arange(-.5, n, 1), minor=True)\n",
    "        ax.set_yticks(np.arange(-.5, n, 1), minor=True)\n",
    "        ax.grid(which='minor', color='gray', linestyle='-', linewidth=0.5, alpha=0.3)\n",
    "\n",
    "    # Add a single comprehensive colorbar with tier labels\n",
    "    cbar_ax = fig.add_axes([0.90, 0.15, 0.02, 0.7])  # [left, bottom, width, height]\n",
    "    cbar = fig.colorbar(im, cax=cbar_ax)\n",
    "    cbar.set_label('FIC Score', fontsize=14, fontweight='bold', labelpad=15)\n",
    "    cbar.ax.tick_params(labelsize=12)\n",
    "    \n",
    "    # Bold the colorbar tick labels\n",
    "    for label in cbar.ax.get_yticklabels():\n",
    "        label.set_fontweight('bold')\n",
    "    \n",
    "    # Add tier annotations on the colorbar\n",
    "    cbar.ax.text(1.5, 0.875, 'Optimum', transform=cbar.ax.transAxes, \n",
    "                 fontsize=11, fontweight='bold', va='center', ha='left', color='darkgreen')\n",
    "    cbar.ax.text(1.5, 0.625, 'Acceptable', transform=cbar.ax.transAxes, \n",
    "                 fontsize=11, fontweight='bold', va='center', ha='left', color='goldenrod')\n",
    "    cbar.ax.text(1.5, 0.375, 'Questionable', transform=cbar.ax.transAxes, \n",
    "                 fontsize=11, fontweight='bold', va='center', ha='left', color='darkorange')\n",
    "    cbar.ax.text(1.5, 0.125, 'Unacceptable', transform=cbar.ax.transAxes, \n",
    "                 fontsize=12, fontweight='bold', va='center', ha='left', color='darkred')\n",
    "    \n",
    "    # Add tier threshold lines on colorbar\n",
    "    cbar.ax.axhline(0.75, color='darkgreen', linestyle='--', linewidth=3, xmax=0.8)\n",
    "    cbar.ax.axhline(0.50, color='goldenrod', linestyle='--', linewidth=3, xmax=0.8)\n",
    "    cbar.ax.axhline(0.00, color='darkred', linestyle='--', linewidth=3, xmax=0.8)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 0.9, 0.95])\n",
    "    plt.savefig(os.path.join(output_dir, f'{dataset_name}_FIC_Heatmaps_{metric}.png'), dpi=400, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def plot_benchmarking_tiers(fic_results, dataset_name, metric='accuracy'):\n",
    "    # Sort alphaF values to ensure consistent order\n",
    "    alphaF_values = sorted(fic_results.keys())\n",
    "    \n",
    "    # Define colors for tiers\n",
    "    colors = {'Optimum': '#2E8B57', 'Acceptable': '#FFD700', \n",
    "              'Questionable': '#FF8C00', 'Unacceptable': '#DC143C'}\n",
    "    \n",
    "    for alphaF in alphaF_values:\n",
    "        if alphaF not in fic_results or not fic_results[alphaF]:\n",
    "            print(f\"No data for alphaF={alphaF} in benchmarking tiers\")\n",
    "            continue\n",
    "        \n",
    "        # Create a figure with more width to accommodate legend\n",
    "        fig, ax = plt.subplots(figsize=(16, 8))\n",
    "        \n",
    "        data = fic_results[alphaF]\n",
    "        pairs = list(data.keys())\n",
    "        fic_scores = [data[p]['fic_score'] for p in pairs]\n",
    "        tiers = [data[p]['tier'] for p in pairs]\n",
    "        \n",
    "        # Create bar colors based on tiers\n",
    "        bar_colors = [colors[t] for t in tiers]\n",
    "        \n",
    "        # Create bars with smaller width for more compact look\n",
    "        bars = ax.bar(range(len(pairs)), fic_scores, color=bar_colors, \n",
    "                      edgecolor='black', linewidth=1.2, width=0.6)\n",
    "        \n",
    "        # Add tier threshold lines with better styling\n",
    "        ax.axhline(0.75, color='darkgreen', linestyle='--', linewidth=2.0, \n",
    "                   alpha=0.7)\n",
    "        ax.axhline(0.50, color='goldenrod', linestyle='--', linewidth=2.0, \n",
    "                   alpha=0.7)\n",
    "        ax.axhline(0.00, color='darkred', linestyle='--', linewidth=2.0, \n",
    "                   alpha=0.7)\n",
    "        \n",
    "        # Customize axes with better labels\n",
    "        ax.set_xlabel('Group Pairs', fontsize=14, fontweight='bold', labelpad=10)\n",
    "        ax.set_ylabel('FIC Score', fontsize=14, fontweight='bold', labelpad=10)\n",
    "        ax.set_title(f'{dataset_name}\\nFIC Benchmarking Tiers ({metric}, αF = {alphaF})',\n",
    "                    fontsize=16, fontweight='bold', pad=15)\n",
    "        \n",
    "        # Set x-ticks with rotation for readability\n",
    "        ax.set_xticks(range(len(pairs)))\n",
    "        ax.set_xticklabels(pairs, rotation=45, ha='right', fontsize=11, fontweight='bold')\n",
    "        \n",
    "        # Set consistent y-axis limits\n",
    "        ax.set_ylim(-0.25, 1.05)\n",
    "        \n",
    "        # Bold the y-axis tick labels\n",
    "        y_ticks = ax.get_yticks()\n",
    "        ax.set_yticklabels([f'{tick:.2f}' for tick in y_ticks], fontsize=11, fontweight='bold')\n",
    "        \n",
    "        # Add grid with lighter style\n",
    "        ax.grid(True, axis='y', alpha=0.3, linestyle='-', linewidth=0.5)\n",
    "        ax.grid(True, axis='x', alpha=0.1, linestyle='-', linewidth=0.5)\n",
    "        \n",
    "        # Add better legend - moved to top right with fewer items\n",
    "        from matplotlib.patches import Patch\n",
    "        legend_elements = [\n",
    "            Patch(facecolor=colors['Optimum'], edgecolor='black', label='Optimum (FIC > 0.75)'),\n",
    "            Patch(facecolor=colors['Acceptable'], edgecolor='black', label='Acceptable (0.50 < FIC ≤ 0.75)'),\n",
    "            Patch(facecolor=colors['Questionable'], edgecolor='black', label='Questionable (0 < FIC ≤ 0.50)'),\n",
    "            Patch(facecolor=colors['Unacceptable'], edgecolor='black', label='Unacceptable (FIC ≤ 0)')\n",
    "        ]\n",
    "        \n",
    "        # Create a separate legend for threshold lines\n",
    "        from matplotlib.lines import Line2D\n",
    "        line_legend_elements = [\n",
    "            Line2D([0], [0], color='darkgreen', linestyle='--', linewidth=2, label='Optimum Threshold (0.75)'),\n",
    "            Line2D([0], [0], color='goldenrod', linestyle='--', linewidth=2, label='Acceptable Threshold (0.50)'),\n",
    "            Line2D([0], [0], color='darkred', linestyle='--', linewidth=2, label='Unacceptable Threshold (0.00)')\n",
    "        ]\n",
    "        \n",
    "        # Place tier legend at upper left - FIXED: removed title_fontweight\n",
    "        tier_legend = ax.legend(handles=legend_elements, fontsize=10, \n",
    "                                loc='upper left', bbox_to_anchor=(1.02, 1.0),\n",
    "                                frameon=True, framealpha=0.9, edgecolor='black',\n",
    "                                title='FIC Tiers', title_fontsize=11)\n",
    "        # Make the legend title bold\n",
    "        tier_legend.get_title().set_fontweight('bold')\n",
    "        ax.add_artist(tier_legend)\n",
    "        \n",
    "        # Place threshold legend at upper left below tier legend - FIXED: removed title_fontweight\n",
    "        threshold_legend = ax.legend(handles=line_legend_elements, fontsize=9, \n",
    "                                     loc='upper left', bbox_to_anchor=(1.02, 0.65),\n",
    "                                     frameon=True, framealpha=0.9, edgecolor='black',\n",
    "                                     title='Thresholds', title_fontsize=10)\n",
    "        # Make the legend title bold\n",
    "        threshold_legend.get_title().set_fontweight('bold')\n",
    "        \n",
    "        # Add annotation for alphaF interpretation\n",
    "        annotation_text = f'αF = {alphaF}\\nFIC = 1 - (ω/αF)\\nω = |r\"$M_1 - M_2$\"|'\n",
    "        ax.text(0.02, 0.98, annotation_text, transform=ax.transAxes,\n",
    "                fontsize=9, verticalalignment='top',\n",
    "                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
    "        \n",
    "        # Adjust layout to make room for legend\n",
    "        plt.tight_layout(rect=[0, 0, 0.85, 1])\n",
    "        \n",
    "        # Save the figure with alphaF in the filename\n",
    "        plt.savefig(os.path.join(output_dir, f'{dataset_name}_Benchmarking_Tiers_alphaF_{alphaF}_{metric}.png'), \n",
    "                    dpi=400, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        print(f\"Saved benchmarking tiers plot for alphaF={alphaF}\")\n",
    "\n",
    "# ============================================\n",
    "# 5. ANALYSIS FUNCTIONS\n",
    "# ============================================\n",
    "\n",
    "def analyze_dataset(dataset_name, data_generator, target_col, protected_col, case_number=1, model_types=['baseline', 'l1', 'l2']):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"CASE {case_number}: {dataset_name}\")\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "    data = data_generator()\n",
    "    fic_framework = FairnessInformationCriterion()\n",
    "\n",
    "    baseline_metrics, _ = train_and_evaluate_models(data, target_col, protected_col, 'baseline')\n",
    "\n",
    "    metrics_df = pd.DataFrame.from_dict(baseline_metrics, orient='index')\n",
    "    metrics_df = metrics_df[['accuracy', 'selection_rate', 'tpr', 'tnr', 'fpr', 'fnr', 'ppv', 'npv', 'f1', 'auc']]\n",
    "    print(\"GROUP METRICS TABLE (Baseline Logistic Regression):\")\n",
    "    print(metrics_df.round(4).to_string())\n",
    "    metrics_df.to_csv(os.path.join(output_dir, f'Case{case_number}_Group_Metrics.csv'))\n",
    "\n",
    "    fic_results = fic_framework.analyze_fairness(baseline_metrics, 'accuracy')\n",
    "\n",
    "    # FIC table\n",
    "    fic_table = []\n",
    "    for pair in sorted(set(p for a in fic_results.values() for p in a.keys())):\n",
    "        row = {'Group Pair': pair}\n",
    "        for af in fic_framework.alphaF_values:\n",
    "            if af in fic_results and pair in fic_results[af]:\n",
    "                d = fic_results[af][pair]\n",
    "                row[f'alphaF={af}'] = f\"omega={d['omega']:.4f}, FIC={d['fic_score']:.3f}\"\n",
    "                row[f'Hypothesis alphaF={af}'] = \"Fail to reject Ho (Fair)\" if d['omega'] <= af else \"Reject H₀ (Unfair)\"\n",
    "            else:\n",
    "                row[f'alphaF={af}'] = \"N/A\"; row[f'Hypothesis alphaF={af}'] = \"N/A\"\n",
    "        fic_table.append(row)\n",
    "    fic_df = pd.DataFrame(fic_table)\n",
    "    print(\"FIC ANALYSIS TABLE:\")\n",
    "    print(fic_df.to_string(index=False))\n",
    "    fic_df.to_csv(os.path.join(output_dir, f'Case{case_number}_FIC_Analysis.csv'), index=False)\n",
    "\n",
    "    # Tier classification\n",
    "    tier_data = []\n",
    "    print(\"TIER CLASSIFICATION:\")\n",
    "    for af in fic_framework.alphaF_values:\n",
    "        print(f\"\\nFor αF = {af}:\")\n",
    "        print(\"-\" * 50)\n",
    "        if af in fic_results:\n",
    "            for pair, d in fic_results[af].items():\n",
    "                tier = fic_framework.classify_tier(d['fic_score'])\n",
    "                msg = tier if d['fic_score'] <= 0.75 else f\"{tier} (omega_max < {0.25*af:.4f})\"\n",
    "                print(f\"{pair}: ω={d['omega']:.4f}, FIC={d['fic_score']:.3f} → {msg}\")\n",
    "                tier_data.append({'alphaF': af, 'Group Pair': pair, 'ω': d['omega'], 'FIC': d['fic_score'], 'Tier': tier})\n",
    "    tier_df = pd.DataFrame(tier_data)\n",
    "    tier_df.to_csv(os.path.join(output_dir, f'Case{case_number}_Tier_Classification.csv'), index=False)\n",
    "\n",
    "    print(\"GENERATING VISUALIZATIONS...\")\n",
    "    plot_fic_heatmaps(fic_results, f'Case{case_number}_{dataset_name}')\n",
    "    plot_benchmarking_tiers(fic_results, f'Case{case_number}_{dataset_name}')\n",
    "\n",
    "    # Model comparison\n",
    "    print(\"MODEL COMPARISON:\")\n",
    "    comparison = []\n",
    "    for mt in model_types:\n",
    "        mets, test_data = train_and_evaluate_models(data, target_col, protected_col, mt)\n",
    "        model_fic = fic_framework.analyze_fairness(mets, 'accuracy')\n",
    "        avg_fic = np.mean([d['fic_score'] for d in model_fic[0.10].values()]) if 0.10 in model_fic and model_fic[0.10] else np.nan\n",
    "        max_omega = max([d['omega'] for d in model_fic[0.10].values()]) if 0.10 in model_fic and model_fic[0.10] else np.nan\n",
    "        _, y_test, _, y_pred, _ = test_data\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        comparison.append({\n",
    "            'Model': mt.upper(),\n",
    "            'Overall Accuracy': f\"{acc:.4f}\",\n",
    "            'Avg FIC alphaF=0.10)': f\"{avg_fic:.3f}\" if not np.isnan(avg_fic) else \"N/A\",\n",
    "            'ω_max (alphaF=0.10)': f\"{max_omega:.4f}\" if not np.isnan(max_omega) else \"N/A\"\n",
    "        })\n",
    "    comparison_df = pd.DataFrame(comparison)\n",
    "    print(comparison_df.to_string(index=False))\n",
    "    comparison_df.to_csv(os.path.join(output_dir, f'Case{case_number}_Model_Comparison.csv'), index=False)\n",
    "\n",
    "    return {\n",
    "        'data': data,\n",
    "        'baseline_metrics': baseline_metrics,\n",
    "        'fic_results': fic_results,\n",
    "        'metrics_df': metrics_df,\n",
    "        'fic_df': fic_df,\n",
    "        'tier_df': tier_df,\n",
    "        'comparison_df': comparison_df\n",
    "    }\n",
    "\n",
    "# ============================================\n",
    "# 6. MAIN ANALYSIS\n",
    "# ============================================\n",
    "\n",
    "def run_complete_analysis():\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"FAIRNESS INFORMATION CRITERION (FIC) ANALYSIS - COMPAS DATASET\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    compas_results = analyze_dataset(\n",
    "        dataset_name=\"COMPAS - Recidivism Risk Prediction\",\n",
    "        data_generator=lambda: generate_compas_data(8000),\n",
    "        target_col='high_risk',\n",
    "        protected_col='race_group',\n",
    "        case_number=1\n",
    "    )\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"SUMMARY REPORT - COMPAS DATASET\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    print(\"COMPAS DATASET KEY FINDINGS:\")\n",
    "    print(\"-\" * 60)\n",
    "    data = compas_results['data']\n",
    "    print(f\"Total samples: {len(data)}\")\n",
    "    print(f\"High risk proportion: {data['high_risk'].mean():.3f}\")\n",
    "    print(\"\\nRace group distribution:\")\n",
    "    race_dist = data['race_group'].value_counts()\n",
    "    for race, count in race_dist.items():\n",
    "        prop = count / len(data)\n",
    "        print(f\"  {race}: {count} ({prop:.3f})\")\n",
    "    \n",
    "    print(\"\\nHigh risk by race group:\")\n",
    "    for race in sorted(data['race_group'].unique()):\n",
    "        subset = data[data['race_group'] == race]\n",
    "        risk_prop = subset['high_risk'].mean()\n",
    "        print(f\"  {race}: {risk_prop:.3f}\")\n",
    "\n",
    "    print(\"\\nFIC ANALYSIS SUMMARY:\")\n",
    "    print(\"-\" * 60)\n",
    "    for af in [0.05, 0.10, 0.15, 0.20]:\n",
    "        if af in compas_results['fic_results'] and compas_results['fic_results'][af]:\n",
    "            items = list(compas_results['fic_results'][af].items())\n",
    "            max_o = max(d['omega'] for _, d in items)\n",
    "            min_o = min(d['omega'] for _, d in items)\n",
    "            avg_o = np.mean([d['omega'] for _, d in items])\n",
    "            worst_pair = max(items, key=lambda x: x[1]['omega'])[0]\n",
    "            best_pair = min(items, key=lambda x: x[1]['omega'])[0]\n",
    "            print(f\"alphaF={af}:\")\n",
    "            print(f\"  omega range: [{min_o:.4f}, {max_o:.4f}], avg: {avg_o:.4f}\")\n",
    "            print(f\"  Most unfair pair: {worst_pair} (ω={max_o:.4f})\")\n",
    "            print(f\"  Most fair pair: {best_pair} (ω={min_o:.4f})\")\n",
    "            \n",
    "            # Tier distribution\n",
    "            fic = FairnessInformationCriterion()\n",
    "            tiers = {'Optimum': 0, 'Acceptable': 0, 'Questionable': 0, 'Unacceptable': 0}\n",
    "            for d in compas_results['fic_results'][af].values():\n",
    "                tiers[fic.classify_tier(d['fic_score'])] += 1\n",
    "            print(f\"  Tier distribution: {tiers}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ANALYSIS COMPLETE - HIGH-QUALITY PLOTS SAVED\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    return compas_results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Check if dataset exists or download it\n",
    "    compas_results = run_complete_analysis()\n",
    "\n",
    "    print(\"\\nAll analysis completed!\")\n",
    "    print(f\"Results saved to: {output_dir}/\")\n",
    "    print(\"Files include:\")\n",
    "    print(\"  - Group metrics (CSV)\")\n",
    "    print(\"  - FIC analysis tables (CSV)\")\n",
    "    print(\"  - Tier classification (CSV)\")\n",
    "    print(\"  - Model comparison (CSV)\")\n",
    "    print(\"  - FIC heatmaps (PNG)\")\n",
    "    print(\"  - Benchmarking tiers for all alphaF values (PNG)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a10fefc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Dr. Akin\\\\OneDrive\\\\2025\\\\Paper_2025\\\\PHD_Work'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#.... Compact and Well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5b9f4f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FAIRNESS INFORMATION CRITERION (FIC) ANALYSIS - COMPAS DATASET\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "CASE 1: COMPAS - Recidivism Risk Prediction\n",
      "================================================================================\n",
      "Looking for COMPAS dataset at: C:\\Users\\Dr. Akin\\OneDrive\\2025\\Paper_2025\\PHD_Work\\compas-scores-two-years.csv\n",
      "Loaded COMPAS dataset from specified folder\n",
      "Processed dataset shape: (7214, 8)\n",
      "Target distribution (high_risk):\n",
      "high_risk\n",
      "0    0.634599\n",
      "1    0.365401\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Race group distribution:\n",
      "race_group\n",
      "African_American    0.512337\n",
      "Caucasian           0.340172\n",
      "Hispanic            0.088301\n",
      "Other_Race          0.059190\n",
      "Name: proportion, dtype: float64\n",
      "GROUP METRICS TABLE (Baseline Logistic Regression):\n",
      "                  accuracy  selection_rate     tpr     tnr     fpr     fnr     ppv     npv      f1     auc\n",
      "African_American    0.6993          0.3501  0.5498  0.8460  0.1540  0.4502  0.7781  0.6568  0.6443  0.7555\n",
      "Caucasian           0.7976          0.1787  0.4531  0.9139  0.0861  0.5469  0.6397  0.8320  0.5305  0.8210\n",
      "Hispanic            0.8305          0.1525  0.4615  0.9348  0.0652  0.5385  0.6667  0.8600  0.5455  0.8443\n",
      "Other_Race          0.8647          0.1353  0.5000  0.9217  0.0783  0.5000  0.5000  0.9217  0.5000  0.8565\n",
      "FIC ANALYSIS TABLE:\n",
      "                   Group Pair              alphaF=0.05   Hypothesis alphaF=0.05               alphaF=0.1    Hypothesis alphaF=0.1              alphaF=0.15   Hypothesis alphaF=0.15              alphaF=0.2    Hypothesis alphaF=0.2\n",
      " African_American - Caucasian omega=0.0984, FIC=-0.967       Reject H₀ (Unfair)  omega=0.0984, FIC=0.016 Fail to reject Ho (Fair)  omega=0.0984, FIC=0.344 Fail to reject Ho (Fair) omega=0.0984, FIC=0.508 Fail to reject Ho (Fair)\n",
      "  African_American - Hispanic omega=0.1312, FIC=-1.625       Reject H₀ (Unfair) omega=0.1312, FIC=-0.312       Reject H₀ (Unfair)  omega=0.1312, FIC=0.125 Fail to reject Ho (Fair) omega=0.1312, FIC=0.344 Fail to reject Ho (Fair)\n",
      "African_American - Other_Race omega=0.1654, FIC=-2.308       Reject H₀ (Unfair) omega=0.1654, FIC=-0.654       Reject H₀ (Unfair) omega=0.1654, FIC=-0.103       Reject H₀ (Unfair) omega=0.1654, FIC=0.173 Fail to reject Ho (Fair)\n",
      "         Caucasian - Hispanic  omega=0.0329, FIC=0.343 Fail to reject Ho (Fair)  omega=0.0329, FIC=0.671 Fail to reject Ho (Fair)  omega=0.0329, FIC=0.781 Fail to reject Ho (Fair) omega=0.0329, FIC=0.836 Fail to reject Ho (Fair)\n",
      "       Caucasian - Other_Race omega=0.0670, FIC=-0.341       Reject H₀ (Unfair)  omega=0.0670, FIC=0.330 Fail to reject Ho (Fair)  omega=0.0670, FIC=0.553 Fail to reject Ho (Fair) omega=0.0670, FIC=0.665 Fail to reject Ho (Fair)\n",
      "        Hispanic - Other_Race  omega=0.0342, FIC=0.317 Fail to reject Ho (Fair)  omega=0.0342, FIC=0.658 Fail to reject Ho (Fair)  omega=0.0342, FIC=0.772 Fail to reject Ho (Fair) omega=0.0342, FIC=0.829 Fail to reject Ho (Fair)\n",
      "TIER CLASSIFICATION:\n",
      "\n",
      "For αF = 0.05:\n",
      "--------------------------------------------------\n",
      "African_American - Caucasian: ω=0.0984, FIC=-0.967 → Unacceptable\n",
      "African_American - Hispanic: ω=0.1312, FIC=-1.625 → Unacceptable\n",
      "African_American - Other_Race: ω=0.1654, FIC=-2.308 → Unacceptable\n",
      "Caucasian - Hispanic: ω=0.0329, FIC=0.343 → Questionable\n",
      "Caucasian - Other_Race: ω=0.0670, FIC=-0.341 → Unacceptable\n",
      "Hispanic - Other_Race: ω=0.0342, FIC=0.317 → Questionable\n",
      "\n",
      "For αF = 0.1:\n",
      "--------------------------------------------------\n",
      "African_American - Caucasian: ω=0.0984, FIC=0.016 → Questionable\n",
      "African_American - Hispanic: ω=0.1312, FIC=-0.312 → Unacceptable\n",
      "African_American - Other_Race: ω=0.1654, FIC=-0.654 → Unacceptable\n",
      "Caucasian - Hispanic: ω=0.0329, FIC=0.671 → Acceptable\n",
      "Caucasian - Other_Race: ω=0.0670, FIC=0.330 → Questionable\n",
      "Hispanic - Other_Race: ω=0.0342, FIC=0.658 → Acceptable\n",
      "\n",
      "For αF = 0.15:\n",
      "--------------------------------------------------\n",
      "African_American - Caucasian: ω=0.0984, FIC=0.344 → Questionable\n",
      "African_American - Hispanic: ω=0.1312, FIC=0.125 → Questionable\n",
      "African_American - Other_Race: ω=0.1654, FIC=-0.103 → Unacceptable\n",
      "Caucasian - Hispanic: ω=0.0329, FIC=0.781 → Optimum (omega_max < 0.0375)\n",
      "Caucasian - Other_Race: ω=0.0670, FIC=0.553 → Acceptable\n",
      "Hispanic - Other_Race: ω=0.0342, FIC=0.772 → Optimum (omega_max < 0.0375)\n",
      "\n",
      "For αF = 0.2:\n",
      "--------------------------------------------------\n",
      "African_American - Caucasian: ω=0.0984, FIC=0.508 → Acceptable\n",
      "African_American - Hispanic: ω=0.1312, FIC=0.344 → Questionable\n",
      "African_American - Other_Race: ω=0.1654, FIC=0.173 → Questionable\n",
      "Caucasian - Hispanic: ω=0.0329, FIC=0.836 → Optimum (omega_max < 0.0500)\n",
      "Caucasian - Other_Race: ω=0.0670, FIC=0.665 → Acceptable\n",
      "Hispanic - Other_Race: ω=0.0342, FIC=0.829 → Optimum (omega_max < 0.0500)\n",
      "GENERATING VISUALIZATIONS...\n",
      "Saved benchmarking tiers plot for alphaF=0.05\n",
      "Saved benchmarking tiers plot for alphaF=0.1\n",
      "Saved benchmarking tiers plot for alphaF=0.15\n",
      "Saved benchmarking tiers plot for alphaF=0.2\n",
      "MODEL COMPARISON:\n",
      "   Model Overall Accuracy Avg FIC alphaF=0.10) ω_max (alphaF=0.10)\n",
      "BASELINE           0.7547                0.118              0.1654\n",
      "      L1           0.7547                0.118              0.1654\n",
      "      L2           0.7547                0.118              0.1654\n",
      "\n",
      "================================================================================\n",
      "SUMMARY REPORT - COMPAS DATASET\n",
      "================================================================================\n",
      "COMPAS DATASET KEY FINDINGS:\n",
      "------------------------------------------------------------\n",
      "Total samples: 7214\n",
      "High risk proportion: 0.365\n",
      "\n",
      "Race group distribution:\n",
      "  African_American: 3696 (0.512)\n",
      "  Caucasian: 2454 (0.340)\n",
      "  Hispanic: 637 (0.088)\n",
      "  Other_Race: 427 (0.059)\n",
      "\n",
      "High risk by race group:\n",
      "  African_American: 0.489\n",
      "  Caucasian: 0.250\n",
      "  Hispanic: 0.217\n",
      "  Other_Race: 0.178\n",
      "\n",
      "FIC ANALYSIS SUMMARY:\n",
      "------------------------------------------------------------\n",
      "alphaF=0.05:\n",
      "  omega range: [0.0329, 0.1654], avg: 0.0882\n",
      "  Most unfair pair: African_American - Other_Race (ω=0.1654)\n",
      "  Most fair pair: Caucasian - Hispanic (ω=0.0329)\n",
      "  Tier distribution: {'Optimum': 0, 'Acceptable': 0, 'Questionable': 2, 'Unacceptable': 4}\n",
      "alphaF=0.1:\n",
      "  omega range: [0.0329, 0.1654], avg: 0.0882\n",
      "  Most unfair pair: African_American - Other_Race (ω=0.1654)\n",
      "  Most fair pair: Caucasian - Hispanic (ω=0.0329)\n",
      "  Tier distribution: {'Optimum': 0, 'Acceptable': 2, 'Questionable': 2, 'Unacceptable': 2}\n",
      "alphaF=0.15:\n",
      "  omega range: [0.0329, 0.1654], avg: 0.0882\n",
      "  Most unfair pair: African_American - Other_Race (ω=0.1654)\n",
      "  Most fair pair: Caucasian - Hispanic (ω=0.0329)\n",
      "  Tier distribution: {'Optimum': 2, 'Acceptable': 1, 'Questionable': 2, 'Unacceptable': 1}\n",
      "alphaF=0.2:\n",
      "  omega range: [0.0329, 0.1654], avg: 0.0882\n",
      "  Most unfair pair: African_American - Other_Race (ω=0.1654)\n",
      "  Most fair pair: Caucasian - Hispanic (ω=0.0329)\n",
      "  Tier distribution: {'Optimum': 2, 'Acceptable': 2, 'Questionable': 2, 'Unacceptable': 0}\n",
      "\n",
      "================================================================================\n",
      "ANALYSIS COMPLETE - HIGH-QUALITY PLOTS SAVED\n",
      "================================================================================\n",
      "\n",
      "All analysis completed!\n",
      "Results saved to: compas_fic_results_NLEGEND/\n",
      "Files include:\n",
      "  - Group metrics (CSV)\n",
      "  - FIC analysis tables (CSV)\n",
      "  - Tier classification (CSV)\n",
      "  - Model comparison (CSV)\n",
      "  - FIC heatmaps (PNG)\n",
      "  - Benchmarking tiers for all alphaF values (PNG)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create output directory\n",
    "output_dir = \"compas_fic_results_NLEGEND\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Set style for publication quality\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Global font settings for consistency\n",
    "plt.rcParams.update({\n",
    "    'font.size': 12,\n",
    "    'axes.titlesize': 16,\n",
    "    'axes.labelsize': 14,\n",
    "    'xtick.labelsize': 12,\n",
    "    'ytick.labelsize': 12,\n",
    "    'legend.fontsize': 12,\n",
    "})\n",
    "\n",
    "# ============================================\n",
    "# 1. LOAD AND PREPROCESS COMPAS DATASET\n",
    "# ============================================\n",
    "\n",
    "def load_compas_data():\n",
    "    \"\"\"\n",
    "    Load and preprocess COMPAS ProPublica dataset from local folder\n",
    "    \"\"\"\n",
    "    # Define your specific folder path\n",
    "    data_folder = r'C:\\Users\\Dr. Akin\\OneDrive\\2025\\Paper_2025\\PHD_Work'\n",
    "    data_file = \"compas-scores-two-years.csv\"\n",
    "    data_path = os.path.join(data_folder, data_file)\n",
    "    \n",
    "    print(f\"Looking for COMPAS dataset at: {data_path}\")\n",
    "    \n",
    "    # Try to load from your specified folder\n",
    "    compas_df = pd.read_csv(data_path)\n",
    "    print(\"Loaded COMPAS dataset from specified folder\")\n",
    "   \n",
    "    \n",
    "    # Filter relevant columns\n",
    "    relevant_columns = [\n",
    "        'age', 'sex', 'race', 'priors_count', 'c_charge_degree',\n",
    "        'juv_fel_count', 'juv_misd_count', 'juv_other_count',\n",
    "        'decile_score', 'two_year_recid'\n",
    "    ]\n",
    "    \n",
    "    # Check which columns exist in the dataset\n",
    "    available_columns = [col for col in relevant_columns if col in compas_df.columns]\n",
    "    compas_df = compas_df[available_columns].copy()\n",
    "    \n",
    "    # Drop rows with missing values\n",
    "    compas_df = compas_df.dropna()\n",
    "    \n",
    "    # Create high_risk target: 0-5 as low risk, 6-10 as high risk\n",
    "    compas_df['high_risk'] = (compas_df['decile_score'] >= 6).astype(int)\n",
    "    \n",
    "    # Consolidate race categories\n",
    "    def consolidate_race(race):\n",
    "        race = str(race).strip().lower()\n",
    "        if 'african' in race or 'black' in race:\n",
    "            return 'African_American'\n",
    "        elif 'caucasian' in race or 'white' in race:\n",
    "            return 'Caucasian'\n",
    "        elif 'hispanic' in race or 'latino' in race:\n",
    "            return 'Hispanic'\n",
    "        elif 'asian' in race or 'arab' in race or 'native' in race or 'other' in race:\n",
    "            return 'Other_Race'\n",
    "        else:\n",
    "            return 'Other_Race'\n",
    "    \n",
    "    compas_df['race_group'] = compas_df['race'].apply(consolidate_race)\n",
    "    \n",
    "    # Filter to keep only our target race groups\n",
    "    target_races = ['African_American', 'Caucasian', 'Hispanic', 'Other_Race']\n",
    "    compas_df = compas_df[compas_df['race_group'].isin(target_races)].copy()\n",
    "    \n",
    "    # Create additional features for better prediction\n",
    "    compas_df['total_juvenile_charges'] = compas_df['juv_fel_count'] + compas_df['juv_misd_count'] + compas_df['juv_other_count']\n",
    "    compas_df['is_felony'] = (compas_df['c_charge_degree'] == 'F').astype(int)\n",
    "    compas_df['age_group'] = pd.cut(compas_df['age'], \n",
    "                                     bins=[0, 25, 35, 45, 55, 100],\n",
    "                                     labels=['18-25', '26-35', '36-45', '46-55', '56+'])\n",
    "    \n",
    "    # Select final columns for analysis\n",
    "    final_columns = [\n",
    "        'age', 'sex', 'race_group', 'priors_count', 'is_felony',\n",
    "        'total_juvenile_charges', 'age_group', 'high_risk'\n",
    "    ]\n",
    "    \n",
    "    # Ensure all columns exist\n",
    "    final_columns = [col for col in final_columns if col in compas_df.columns]\n",
    "    compas_df = compas_df[final_columns]\n",
    "    \n",
    "    print(f\"Processed dataset shape: {compas_df.shape}\")\n",
    "    print(f\"Target distribution (high_risk):\")\n",
    "    print(compas_df['high_risk'].value_counts(normalize=True))\n",
    "    print(f\"\\nRace group distribution:\")\n",
    "    print(compas_df['race_group'].value_counts(normalize=True))\n",
    "    \n",
    "    return compas_df\n",
    "\n",
    "def generate_compas_data(n_samples=None):\n",
    "    \"\"\"\n",
    "    Wrapper function to load COMPAS data\n",
    "    n_samples parameter is kept for compatibility but not used\n",
    "    \"\"\"\n",
    "    data = load_compas_data()\n",
    "    \n",
    "    # If n_samples is specified and smaller than dataset, sample it\n",
    "    if n_samples and n_samples < len(data):\n",
    "        data = data.sample(n=n_samples, random_state=42)\n",
    "    \n",
    "    return data\n",
    "\n",
    "# ============================================\n",
    "# 2-3. MODEL & FIC\n",
    "# ============================================\n",
    "\n",
    "def compute_all_metrics(y_true, y_pred, y_prob):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_true, y_pred),\n",
    "        'selection_rate': (tp + fp) / len(y_true),\n",
    "        'tpr': tp / (tp + fn) if (tp + fn) > 0 else 0,\n",
    "        'tnr': tn / (tn + fp) if (tn + fp) > 0 else 0,\n",
    "        'fpr': fp / (fp + tn) if (fp + tn) > 0 else 0,\n",
    "        'fnr': fn / (tp + fn) if (tp + fn) > 0 else 0,\n",
    "        'ppv': tp / (tp + fp) if (tp + fp) > 0 else 0,\n",
    "        'npv': tn / (tn + fn) if (tn + fn) > 0 else 0,\n",
    "        'f1': f1_score(y_true, y_pred),\n",
    "        'auc': roc_auc_score(y_true, y_prob) if len(np.unique(y_true)) > 1 else np.nan\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "def train_and_evaluate_models(data, target_col, protected_col, model_type='baseline'):\n",
    "    X = data.drop(columns=[target_col, protected_col])\n",
    "    y = data[target_col]\n",
    "    categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "    numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(drop='first'), categorical_cols)\n",
    "    ])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "    protected_test = data.loc[X_test.index, protected_col]\n",
    "\n",
    "    X_train_processed = preprocessor.fit_transform(X_train)\n",
    "    X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "    if model_type == 'baseline':\n",
    "        model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "    elif model_type == 'l1':\n",
    "        model = LogisticRegression(penalty='l1', solver='liblinear', random_state=42, max_iter=1000, C=1.0)\n",
    "    elif model_type == 'l2':\n",
    "        model = LogisticRegression(penalty='l2', random_state=42, max_iter=1000, C=1.0)\n",
    "    else:\n",
    "        model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "    model.fit(X_train_processed, y_train)\n",
    "    y_pred = model.predict(X_test_processed)\n",
    "    y_prob = model.predict_proba(X_test_processed)[:, 1]\n",
    "\n",
    "    group_metrics = {}\n",
    "    for group in protected_test.unique():\n",
    "        mask = protected_test == group\n",
    "        if mask.sum() > 0:\n",
    "            group_metrics[group] = compute_all_metrics(y_test[mask], y_pred[mask], y_prob[mask])\n",
    "\n",
    "    return group_metrics, (X_test, y_test, protected_test, y_pred, y_prob)\n",
    "\n",
    "class FairnessInformationCriterion:\n",
    "    def __init__(self, alphaF_values=[0.05, 0.10, 0.15, 0.20]):\n",
    "        self.alphaF_values = alphaF_values\n",
    "\n",
    "    def compute_omega(self, metric1, metric2):\n",
    "        return abs(metric1 - metric2)\n",
    "\n",
    "    def compute_fic(self, omega, alphaF):\n",
    "        return 1 - (omega / alphaF)\n",
    "\n",
    "    def classify_tier(self, fic_score):\n",
    "        if fic_score > 0.75:\n",
    "            return \"Optimum\"\n",
    "        elif fic_score > 0.50:\n",
    "            return \"Acceptable\"\n",
    "        elif fic_score > 0:\n",
    "            return \"Questionable\"\n",
    "        else:\n",
    "            return \"Unacceptable\"\n",
    "\n",
    "    def analyze_fairness(self, group_metrics, metric_name='accuracy'):\n",
    "        results = {}\n",
    "        groups = list(group_metrics.keys())\n",
    "        for alphaF in self.alphaF_values:\n",
    "            results[alphaF] = {}\n",
    "            for i, g1 in enumerate(groups):\n",
    "                for g2 in groups[i+1:]:\n",
    "                    pair = f\"{g1} - {g2}\"\n",
    "                    m1 = group_metrics[g1].get(metric_name, np.nan)\n",
    "                    m2 = group_metrics[g2].get(metric_name, np.nan)\n",
    "                    if not np.isnan(m1) and not np.isnan(m2):\n",
    "                        omega = self.compute_omega(m1, m2)\n",
    "                        fic_score = self.compute_fic(omega, alphaF)\n",
    "                        tier = self.classify_tier(fic_score)\n",
    "                        results[alphaF][pair] = {\n",
    "                            'omega': omega, 'fic_score': fic_score, 'tier': tier,\n",
    "                            'metric1': m1, 'metric2': m2\n",
    "                        }\n",
    "        return results\n",
    "\n",
    "# ============================================\n",
    "# 4. VISUALIZATIONS\n",
    "# ============================================\n",
    "\n",
    "def plot_fic_heatmaps(fic_results, dataset_name, metric='accuracy'):\n",
    "    alphaF_values = sorted(fic_results.keys())\n",
    "    if not alphaF_values:\n",
    "        return\n",
    "\n",
    "    pairs = list(fic_results[alphaF_values[0]].keys())\n",
    "    all_groups = sorted(set(g for p in pairs for g in p.split(' - ')))\n",
    "\n",
    "    # Larger figure\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(20, 16))\n",
    "    fig.suptitle(f'{dataset_name}: FIC Heatmaps for Different alphaF Values ({metric})',\n",
    "                 fontsize=20, fontweight='bold', y=0.98)\n",
    "\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for idx, alphaF in enumerate(alphaF_values):\n",
    "        ax = axes[idx]\n",
    "        n = len(all_groups)\n",
    "        mat = np.full((n, n), np.nan)\n",
    "        group_idx = {g: i for i, g in enumerate(all_groups)}\n",
    "\n",
    "        for pair, d in fic_results[alphaF].items():\n",
    "            g1, g2 = pair.split(' - ')\n",
    "            i, j = group_idx[g1], group_idx[g2]\n",
    "            mat[i, j] = mat[j, i] = d['fic_score']\n",
    "\n",
    "        im = ax.imshow(mat, cmap='RdYlGn', vmin=-1, vmax=1, aspect='equal')\n",
    "\n",
    "        # Add value labels inside cells\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                if i != j and not np.isnan(mat[i, j]):\n",
    "                    text = ax.text(j, i, f'{mat[i,j]:.2f}',\n",
    "                                   ha='center', va='center',\n",
    "                                   fontsize=14, fontweight='bold',\n",
    "                                   color='white' if abs(mat[i,j]) > 0.5 else 'black')\n",
    "\n",
    "        ax.set_xticks(range(n))\n",
    "        ax.set_yticks(range(n))\n",
    "        ax.set_xticklabels(all_groups, rotation=45, ha='right', fontsize=13, fontweight='bold')\n",
    "        ax.set_yticklabels(all_groups, fontsize=13, fontweight='bold')\n",
    "        ax.set_title(f'αF = {alphaF}', fontsize=18, fontweight='bold', pad=20)\n",
    "        \n",
    "        # Add grid\n",
    "        ax.set_xticks(np.arange(-.5, n, 1), minor=True)\n",
    "        ax.set_yticks(np.arange(-.5, n, 1), minor=True)\n",
    "        ax.grid(which='minor', color='gray', linestyle='-', linewidth=0.5, alpha=0.3)\n",
    "\n",
    "    # Add a single comprehensive colorbar with tier labels\n",
    "    cbar_ax = fig.add_axes([0.75, 0.15, 0.03, 0.7])  # [left, bottom, width, height]\n",
    "    cbar = fig.colorbar(im, cax=cbar_ax)\n",
    "    cbar.set_label('FIC Score', fontsize=14, fontweight='bold', labelpad=15)\n",
    "    cbar.ax.tick_params(labelsize=12)\n",
    "    \n",
    "    # Bold the colorbar tick labels\n",
    "    for label in cbar.ax.get_yticklabels():\n",
    "        label.set_fontweight('bold')\n",
    "    \n",
    "    # Add tier annotations on the colorbar\n",
    "    cbar.ax.text(1.1, 0.90, 'Optimum', transform=cbar.ax.transAxes, \n",
    "                 fontsize=14, fontweight='bold', va='center', ha='left', color='darkgreen')\n",
    "    cbar.ax.text(1.1, 0.60, 'Acceptable', transform=cbar.ax.transAxes, \n",
    "                 fontsize=14, fontweight='bold', va='center', ha='left', color='goldenrod')\n",
    "    cbar.ax.text(1.1, 0.350, 'Questionable', transform=cbar.ax.transAxes, \n",
    "                 fontsize=14, fontweight='bold', va='center', ha='left', color='darkorange')\n",
    "    cbar.ax.text(1.1, 0.100, 'Unacceptable', transform=cbar.ax.transAxes, \n",
    "                 fontsize=14, fontweight='bold', va='center', ha='left', color='darkred')\n",
    "    \n",
    "    # Add tier threshold lines on colorbar\n",
    "    cbar.ax.axhline(0.75, color='darkgreen', linestyle='--', linewidth=3, xmax=0.8)\n",
    "    cbar.ax.axhline(0.50, color='goldenrod', linestyle='--', linewidth=3, xmax=0.8)\n",
    "    cbar.ax.axhline(0.00, color='darkred', linestyle='--', linewidth=3, xmax=0.8)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 0.8, 0.95])\n",
    "    plt.savefig(os.path.join(output_dir, f'{dataset_name}_FIC_Heatmaps_{metric}.png'), dpi=400, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_benchmarking_tiers(fic_results, dataset_name, metric='accuracy'):\n",
    "    # Sort alphaF values to ensure consistent order\n",
    "    alphaF_values = sorted(fic_results.keys())\n",
    "    \n",
    "    # Define colors for tiers\n",
    "    colors = {'Optimum': '#2E8B57', 'Acceptable': '#FFD700', \n",
    "              'Questionable': '#FF8C00', 'Unacceptable': '#DC143C'}\n",
    "    \n",
    "    for alphaF in alphaF_values:\n",
    "        if alphaF not in fic_results or not fic_results[alphaF]:\n",
    "            print(f\"No data for alphaF={alphaF} in benchmarking tiers\")\n",
    "            continue\n",
    "        \n",
    "        # Create a figure with more width to accommodate legend\n",
    "        fig, ax = plt.subplots(figsize=(16, 8))\n",
    "        \n",
    "        data = fic_results[alphaF]\n",
    "        pairs = list(data.keys())\n",
    "        fic_scores = [data[p]['fic_score'] for p in pairs]\n",
    "        tiers = [data[p]['tier'] for p in pairs]\n",
    "        \n",
    "        # Find max positive and max negative values\n",
    "        max_positive = max(fic_scores) if fic_scores else 1.0\n",
    "        min_negative = min(fic_scores) if fic_scores else -0.25\n",
    "        \n",
    "        # Add padding (10% on positive side, 10% on negative side)\n",
    "        y_max = max_positive * 1.10 if max_positive > 0 else 0.10\n",
    "        y_min = min_negative * 1.10 if min_negative < 0 else -0.10\n",
    "        \n",
    "        # Ensure at least some range for visualization\n",
    "        if y_max - y_min < 0.5:\n",
    "            # If range is too small, center it around the data\n",
    "            center = (max_positive + min_negative) / 2\n",
    "            y_max = center + 0.25\n",
    "            y_min = center - 0.25\n",
    "        \n",
    "        # Create bar colors based on tiers\n",
    "        bar_colors = [colors[t] for t in tiers]\n",
    "        \n",
    "        # Create bars with smaller width for more compact look\n",
    "        bars = ax.bar(range(len(pairs)), fic_scores, color=bar_colors, \n",
    "                      edgecolor='black', linewidth=1.2, width=0.6)\n",
    "        \n",
    "        # Add tier threshold lines with better styling\n",
    "        ax.axhline(0.75, color='darkgreen', linestyle='--', linewidth=2.0, \n",
    "                   alpha=0.7)\n",
    "        ax.axhline(0.50, color='goldenrod', linestyle='--', linewidth=2.0, \n",
    "                   alpha=0.7)\n",
    "        ax.axhline(0.00, color='darkred', linestyle='--', linewidth=2.0, \n",
    "                   alpha=0.7)\n",
    "        \n",
    "        # Customize axes with better labels\n",
    "        ax.set_xlabel('Group Pairs', fontsize=14, fontweight='bold', labelpad=10)\n",
    "        ax.set_ylabel('FIC Score', fontsize=14, fontweight='bold', labelpad=10)\n",
    "        ax.set_title(f'{dataset_name}\\nFIC Benchmarking Tiers ({metric}, αF = {alphaF})',\n",
    "                    fontsize=16, fontweight='bold', pad=15)\n",
    "        \n",
    "        # Set x-ticks with rotation for readability\n",
    "        ax.set_xticks(range(len(pairs)))\n",
    "        ax.set_xticklabels(pairs, rotation=45, ha='right', fontsize=11, fontweight='bold')\n",
    "        \n",
    "        # Set dynamic y-axis limits based on actual max positive and max negative - CHANGED\n",
    "        ax.set_ylim(y_min, y_max)\n",
    "        \n",
    "        # Bold the y-axis tick labels\n",
    "        y_ticks = ax.get_yticks()\n",
    "        ax.set_yticklabels([f'{tick:.2f}' for tick in y_ticks], fontsize=11, fontweight='bold')\n",
    "        \n",
    "        # Add grid with lighter style\n",
    "        ax.grid(True, axis='y', alpha=0.3, linestyle='-', linewidth=0.5)\n",
    "        ax.grid(True, axis='x', alpha=0.1, linestyle='-', linewidth=0.5)\n",
    "        \n",
    "        # Add better legend - moved to top right with fewer items\n",
    "        from matplotlib.patches import Patch\n",
    "        legend_elements = [\n",
    "            Patch(facecolor=colors['Optimum'], edgecolor='black', label='Optimum (FIC > 0.75)'),\n",
    "            Patch(facecolor=colors['Acceptable'], edgecolor='black', label='Acceptable (0.50 < FIC ≤ 0.75)'),\n",
    "            Patch(facecolor=colors['Questionable'], edgecolor='black', label='Questionable (0 < FIC ≤ 0.50)'),\n",
    "            Patch(facecolor=colors['Unacceptable'], edgecolor='black', label='Unacceptable (FIC ≤ 0)')\n",
    "        ]\n",
    "        \n",
    "        # Create a separate legend for threshold lines\n",
    "        from matplotlib.lines import Line2D\n",
    "        line_legend_elements = [\n",
    "            Line2D([0], [0], color='darkgreen', linestyle='--', linewidth=2, label='Optimum Threshold (0.75)'),\n",
    "            Line2D([0], [0], color='goldenrod', linestyle='--', linewidth=2, label='Acceptable Threshold (0.50)'),\n",
    "            Line2D([0], [0], color='darkred', linestyle='--', linewidth=2, label='Unacceptable Threshold (0.00)')\n",
    "        ]\n",
    "        \n",
    "        # Place tier legend at upper left\n",
    "        tier_legend = ax.legend(handles=legend_elements, fontsize=10, \n",
    "                                loc='upper left', bbox_to_anchor=(1.02, 1.0),\n",
    "                                frameon=True, framealpha=0.9, edgecolor='black',\n",
    "                                title='FIC Tiers', title_fontsize=11)\n",
    "        # Make the legend title bold\n",
    "        tier_legend.get_title().set_fontweight('bold')\n",
    "        ax.add_artist(tier_legend)\n",
    "        \n",
    "        # Place threshold legend at upper left below tier legend\n",
    "        threshold_legend = ax.legend(handles=line_legend_elements, fontsize=9, \n",
    "                                     loc='upper left', bbox_to_anchor=(1.02, 0.65),\n",
    "                                     frameon=True, framealpha=0.9, edgecolor='black',\n",
    "                                     title='Thresholds', title_fontsize=10)\n",
    "        # Make the legend title bold\n",
    "        threshold_legend.get_title().set_fontweight('bold')\n",
    "        \n",
    "        # Add annotation for alphaF interpretation\n",
    "        annotation_text = f'αF = {alphaF}\\nFIC = 1 - (ω/αF)\\nω = |M₁ - M₂|'\n",
    "        ax.text(0.02, 0.98, annotation_text, transform=ax.transAxes,\n",
    "                fontsize=9, verticalalignment='top', fontweight='bold',\n",
    "                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
    "        \n",
    "        # Adjust layout to make room for legend\n",
    "        plt.tight_layout(rect=[0, 0, 0.85, 1])\n",
    "        \n",
    "        # Save the figure with alphaF in the filename\n",
    "        plt.savefig(os.path.join(output_dir, f'{dataset_name}_Benchmarking_Tiers_alphaF_{alphaF}_{metric}.png'), \n",
    "                    dpi=400, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        print(f\"Saved benchmarking tiers plot for alphaF={alphaF}\")\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# 5. ANALYSIS FUNCTIONS\n",
    "# ============================================\n",
    "\n",
    "def analyze_dataset(dataset_name, data_generator, target_col, protected_col, case_number=1, model_types=['baseline', 'l1', 'l2']):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"CASE {case_number}: {dataset_name}\")\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "    data = data_generator()\n",
    "    fic_framework = FairnessInformationCriterion()\n",
    "\n",
    "    baseline_metrics, _ = train_and_evaluate_models(data, target_col, protected_col, 'baseline')\n",
    "\n",
    "    metrics_df = pd.DataFrame.from_dict(baseline_metrics, orient='index')\n",
    "    metrics_df = metrics_df[['accuracy', 'selection_rate', 'tpr', 'tnr', 'fpr', 'fnr', 'ppv', 'npv', 'f1', 'auc']]\n",
    "    print(\"GROUP METRICS TABLE (Baseline Logistic Regression):\")\n",
    "    print(metrics_df.round(4).to_string())\n",
    "    metrics_df.to_csv(os.path.join(output_dir, f'Case{case_number}_Group_Metrics.csv'))\n",
    "\n",
    "    fic_results = fic_framework.analyze_fairness(baseline_metrics, 'accuracy')\n",
    "\n",
    "    # FIC table\n",
    "    fic_table = []\n",
    "    for pair in sorted(set(p for a in fic_results.values() for p in a.keys())):\n",
    "        row = {'Group Pair': pair}\n",
    "        for af in fic_framework.alphaF_values:\n",
    "            if af in fic_results and pair in fic_results[af]:\n",
    "                d = fic_results[af][pair]\n",
    "                row[f'alphaF={af}'] = f\"omega={d['omega']:.4f}, FIC={d['fic_score']:.3f}\"\n",
    "                row[f'Hypothesis alphaF={af}'] = \"Fail to reject Ho (Fair)\" if d['omega'] <= af else \"Reject H₀ (Unfair)\"\n",
    "            else:\n",
    "                row[f'alphaF={af}'] = \"N/A\"; row[f'Hypothesis alphaF={af}'] = \"N/A\"\n",
    "        fic_table.append(row)\n",
    "    fic_df = pd.DataFrame(fic_table)\n",
    "    print(\"FIC ANALYSIS TABLE:\")\n",
    "    print(fic_df.to_string(index=False))\n",
    "    fic_df.to_csv(os.path.join(output_dir, f'Case{case_number}_FIC_Analysis.csv'), index=False)\n",
    "\n",
    "    # Tier classification\n",
    "    tier_data = []\n",
    "    print(\"TIER CLASSIFICATION:\")\n",
    "    for af in fic_framework.alphaF_values:\n",
    "        print(f\"\\nFor αF = {af}:\")\n",
    "        print(\"-\" * 50)\n",
    "        if af in fic_results:\n",
    "            for pair, d in fic_results[af].items():\n",
    "                tier = fic_framework.classify_tier(d['fic_score'])\n",
    "                msg = tier if d['fic_score'] <= 0.75 else f\"{tier} (omega_max < {0.25*af:.4f})\"\n",
    "                print(f\"{pair}: ω={d['omega']:.4f}, FIC={d['fic_score']:.3f} → {msg}\")\n",
    "                tier_data.append({'alphaF': af, 'Group Pair': pair, 'ω': d['omega'], 'FIC': d['fic_score'], 'Tier': tier})\n",
    "    tier_df = pd.DataFrame(tier_data)\n",
    "    tier_df.to_csv(os.path.join(output_dir, f'Case{case_number}_Tier_Classification.csv'), index=False)\n",
    "\n",
    "    print(\"GENERATING VISUALIZATIONS...\")\n",
    "    plot_fic_heatmaps(fic_results, f'Case{case_number}_{dataset_name}')\n",
    "    plot_benchmarking_tiers(fic_results, f'Case{case_number}_{dataset_name}')\n",
    "\n",
    "    # Model comparison\n",
    "    print(\"MODEL COMPARISON:\")\n",
    "    comparison = []\n",
    "    for mt in model_types:\n",
    "        mets, test_data = train_and_evaluate_models(data, target_col, protected_col, mt)\n",
    "        model_fic = fic_framework.analyze_fairness(mets, 'accuracy')\n",
    "        avg_fic = np.mean([d['fic_score'] for d in model_fic[0.10].values()]) if 0.10 in model_fic and model_fic[0.10] else np.nan\n",
    "        max_omega = max([d['omega'] for d in model_fic[0.10].values()]) if 0.10 in model_fic and model_fic[0.10] else np.nan\n",
    "        _, y_test, _, y_pred, _ = test_data\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        comparison.append({\n",
    "            'Model': mt.upper(),\n",
    "            'Overall Accuracy': f\"{acc:.4f}\",\n",
    "            'Avg FIC alphaF=0.10)': f\"{avg_fic:.3f}\" if not np.isnan(avg_fic) else \"N/A\",\n",
    "            'ω_max (alphaF=0.10)': f\"{max_omega:.4f}\" if not np.isnan(max_omega) else \"N/A\"\n",
    "        })\n",
    "    comparison_df = pd.DataFrame(comparison)\n",
    "    print(comparison_df.to_string(index=False))\n",
    "    comparison_df.to_csv(os.path.join(output_dir, f'Case{case_number}_Model_Comparison.csv'), index=False)\n",
    "\n",
    "    return {\n",
    "        'data': data,\n",
    "        'baseline_metrics': baseline_metrics,\n",
    "        'fic_results': fic_results,\n",
    "        'metrics_df': metrics_df,\n",
    "        'fic_df': fic_df,\n",
    "        'tier_df': tier_df,\n",
    "        'comparison_df': comparison_df\n",
    "    }\n",
    "\n",
    "# ============================================\n",
    "# 6. MAIN ANALYSIS\n",
    "# ============================================\n",
    "\n",
    "def run_complete_analysis():\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"FAIRNESS INFORMATION CRITERION (FIC) ANALYSIS - COMPAS DATASET\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    compas_results = analyze_dataset(\n",
    "        dataset_name=\"COMPAS - Recidivism Risk Prediction\",\n",
    "        data_generator=lambda: generate_compas_data(8000),\n",
    "        target_col='high_risk',\n",
    "        protected_col='race_group',\n",
    "        case_number=1\n",
    "    )\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"SUMMARY REPORT - COMPAS DATASET\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    print(\"COMPAS DATASET KEY FINDINGS:\")\n",
    "    print(\"-\" * 60)\n",
    "    data = compas_results['data']\n",
    "    print(f\"Total samples: {len(data)}\")\n",
    "    print(f\"High risk proportion: {data['high_risk'].mean():.3f}\")\n",
    "    print(\"\\nRace group distribution:\")\n",
    "    race_dist = data['race_group'].value_counts()\n",
    "    for race, count in race_dist.items():\n",
    "        prop = count / len(data)\n",
    "        print(f\"  {race}: {count} ({prop:.3f})\")\n",
    "    \n",
    "    print(\"\\nHigh risk by race group:\")\n",
    "    for race in sorted(data['race_group'].unique()):\n",
    "        subset = data[data['race_group'] == race]\n",
    "        risk_prop = subset['high_risk'].mean()\n",
    "        print(f\"  {race}: {risk_prop:.3f}\")\n",
    "\n",
    "    print(\"\\nFIC ANALYSIS SUMMARY:\")\n",
    "    print(\"-\" * 60)\n",
    "    for af in [0.05, 0.10, 0.15, 0.20]:\n",
    "        if af in compas_results['fic_results'] and compas_results['fic_results'][af]:\n",
    "            items = list(compas_results['fic_results'][af].items())\n",
    "            max_o = max(d['omega'] for _, d in items)\n",
    "            min_o = min(d['omega'] for _, d in items)\n",
    "            avg_o = np.mean([d['omega'] for _, d in items])\n",
    "            worst_pair = max(items, key=lambda x: x[1]['omega'])[0]\n",
    "            best_pair = min(items, key=lambda x: x[1]['omega'])[0]\n",
    "            print(f\"alphaF={af}:\")\n",
    "            print(f\"  omega range: [{min_o:.4f}, {max_o:.4f}], avg: {avg_o:.4f}\")\n",
    "            print(f\"  Most unfair pair: {worst_pair} (ω={max_o:.4f})\")\n",
    "            print(f\"  Most fair pair: {best_pair} (ω={min_o:.4f})\")\n",
    "            \n",
    "            # Tier distribution\n",
    "            fic = FairnessInformationCriterion()\n",
    "            tiers = {'Optimum': 0, 'Acceptable': 0, 'Questionable': 0, 'Unacceptable': 0}\n",
    "            for d in compas_results['fic_results'][af].values():\n",
    "                tiers[fic.classify_tier(d['fic_score'])] += 1\n",
    "            print(f\"  Tier distribution: {tiers}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ANALYSIS COMPLETE - HIGH-QUALITY PLOTS SAVED\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    return compas_results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Check if dataset exists or download it\n",
    "    compas_results = run_complete_analysis()\n",
    "\n",
    "    print(\"\\nAll analysis completed!\")\n",
    "    print(f\"Results saved to: {output_dir}/\")\n",
    "    print(\"Files include:\")\n",
    "    print(\"  - Group metrics (CSV)\")\n",
    "    print(\"  - FIC analysis tables (CSV)\")\n",
    "    print(\"  - Tier classification (CSV)\")\n",
    "    print(\"  - Model comparison (CSV)\")\n",
    "    print(\"  - FIC heatmaps (PNG)\")\n",
    "    print(\"  - Benchmarking tiers for all alphaF values (PNG)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780f99fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#..... COMPLETED WITH ALL METRICS PLOTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2e663217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FAIRNESS INFORMATION CRITERION (FIC) ANALYSIS - COMPAS DATASET\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "CASE 1: COMPAS - Recidivism Risk Prediction\n",
      "================================================================================\n",
      "Looking for COMPAS dataset at: C:\\Users\\Dr. Akin\\OneDrive\\2025\\Paper_2025\\PHD_Work\\compas-scores-two-years.csv\n",
      "Loaded COMPAS dataset from specified folder\n",
      "Processed dataset shape: (7214, 8)\n",
      "Target distribution (high_risk):\n",
      "high_risk\n",
      "0    0.634599\n",
      "1    0.365401\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Race group distribution:\n",
      "race_group\n",
      "African_American    0.512337\n",
      "Caucasian           0.340172\n",
      "Hispanic            0.088301\n",
      "Other_Race          0.059190\n",
      "Name: proportion, dtype: float64\n",
      "GROUP METRICS TABLE (Baseline Logistic Regression):\n",
      "                  accuracy  selection_rate     tpr     tnr     fpr     fnr     ppv     npv      f1     auc\n",
      "African_American    0.6993          0.3501  0.5498  0.8460  0.1540  0.4502  0.7781  0.6568  0.6443  0.7555\n",
      "Caucasian           0.7976          0.1787  0.4531  0.9139  0.0861  0.5469  0.6397  0.8320  0.5305  0.8210\n",
      "Hispanic            0.8305          0.1525  0.4615  0.9348  0.0652  0.5385  0.6667  0.8600  0.5455  0.8443\n",
      "Other_Race          0.8647          0.1353  0.5000  0.9217  0.0783  0.5000  0.5000  0.9217  0.5000  0.8565\n",
      "\n",
      "GENERATING VISUALIZATIONS FOR ALL METRICS...\n",
      "\n",
      "============================================================\n",
      "ANALYZING METRIC: ACCURACY\n",
      "============================================================\n",
      "  Saved benchmarking tiers plot for alphaF=0.05 (accuracy)\n",
      "  Saved benchmarking tiers plot for alphaF=0.1 (accuracy)\n",
      "  Saved benchmarking tiers plot for alphaF=0.15 (accuracy)\n",
      "  Saved benchmarking tiers plot for alphaF=0.2 (accuracy)\n",
      "Summary for accuracy:\n",
      "  αF=0.05: ω_max=0.1654, ω_avg=0.0882, Tiers={'Optimum': 0, 'Acceptable': 0, 'Questionable': 2, 'Unacceptable': 4}\n",
      "  αF=0.1: ω_max=0.1654, ω_avg=0.0882, Tiers={'Optimum': 0, 'Acceptable': 2, 'Questionable': 2, 'Unacceptable': 2}\n",
      "  αF=0.15: ω_max=0.1654, ω_avg=0.0882, Tiers={'Optimum': 2, 'Acceptable': 1, 'Questionable': 2, 'Unacceptable': 1}\n",
      "  αF=0.2: ω_max=0.1654, ω_avg=0.0882, Tiers={'Optimum': 2, 'Acceptable': 2, 'Questionable': 2, 'Unacceptable': 0}\n",
      "\n",
      "============================================================\n",
      "ANALYZING METRIC: SELECTION_RATE\n",
      "============================================================\n",
      "  Saved benchmarking tiers plot for alphaF=0.05 (selection_rate)\n",
      "  Saved benchmarking tiers plot for alphaF=0.1 (selection_rate)\n",
      "  Saved benchmarking tiers plot for alphaF=0.15 (selection_rate)\n",
      "  Saved benchmarking tiers plot for alphaF=0.2 (selection_rate)\n",
      "Summary for selection_rate:\n",
      "  αF=0.05: ω_max=0.2148, ω_avg=0.1117, Tiers={'Optimum': 0, 'Acceptable': 1, 'Questionable': 2, 'Unacceptable': 3}\n",
      "  αF=0.1: ω_max=0.2148, ω_avg=0.1117, Tiers={'Optimum': 1, 'Acceptable': 2, 'Questionable': 0, 'Unacceptable': 3}\n",
      "  αF=0.15: ω_max=0.2148, ω_avg=0.1117, Tiers={'Optimum': 2, 'Acceptable': 1, 'Questionable': 0, 'Unacceptable': 3}\n",
      "  αF=0.2: ω_max=0.2148, ω_avg=0.1117, Tiers={'Optimum': 3, 'Acceptable': 0, 'Questionable': 2, 'Unacceptable': 1}\n",
      "\n",
      "============================================================\n",
      "ANALYZING METRIC: TPR\n",
      "============================================================\n",
      "  Saved benchmarking tiers plot for alphaF=0.05 (tpr)\n",
      "  Saved benchmarking tiers plot for alphaF=0.1 (tpr)\n",
      "  Saved benchmarking tiers plot for alphaF=0.15 (tpr)\n",
      "  Saved benchmarking tiers plot for alphaF=0.2 (tpr)\n",
      "Summary for tpr:\n",
      "  αF=0.05: ω_max=0.0967, ω_avg=0.0548, Tiers={'Optimum': 1, 'Acceptable': 0, 'Questionable': 3, 'Unacceptable': 2}\n",
      "  αF=0.1: ω_max=0.0967, ω_avg=0.0548, Tiers={'Optimum': 1, 'Acceptable': 3, 'Questionable': 2, 'Unacceptable': 0}\n",
      "  αF=0.15: ω_max=0.0967, ω_avg=0.0548, Tiers={'Optimum': 1, 'Acceptable': 3, 'Questionable': 2, 'Unacceptable': 0}\n",
      "  αF=0.2: ω_max=0.0967, ω_avg=0.0548, Tiers={'Optimum': 4, 'Acceptable': 2, 'Questionable': 0, 'Unacceptable': 0}\n",
      "\n",
      "============================================================\n",
      "ANALYZING METRIC: TNR\n",
      "============================================================\n",
      "  Saved benchmarking tiers plot for alphaF=0.05 (tnr)\n",
      "  Saved benchmarking tiers plot for alphaF=0.1 (tnr)\n",
      "  Saved benchmarking tiers plot for alphaF=0.15 (tnr)\n",
      "  Saved benchmarking tiers plot for alphaF=0.2 (tnr)\n",
      "Summary for tnr:\n",
      "  αF=0.05: ω_max=0.0888, ω_avg=0.0457, Tiers={'Optimum': 1, 'Acceptable': 2, 'Questionable': 0, 'Unacceptable': 3}\n",
      "  αF=0.1: ω_max=0.0888, ω_avg=0.0457, Tiers={'Optimum': 3, 'Acceptable': 0, 'Questionable': 3, 'Unacceptable': 0}\n",
      "  αF=0.15: ω_max=0.0888, ω_avg=0.0457, Tiers={'Optimum': 3, 'Acceptable': 1, 'Questionable': 2, 'Unacceptable': 0}\n",
      "  αF=0.2: ω_max=0.0888, ω_avg=0.0457, Tiers={'Optimum': 3, 'Acceptable': 3, 'Questionable': 0, 'Unacceptable': 0}\n",
      "\n",
      "============================================================\n",
      "ANALYZING METRIC: FPR\n",
      "============================================================\n",
      "  Saved benchmarking tiers plot for alphaF=0.05 (fpr)\n",
      "  Saved benchmarking tiers plot for alphaF=0.1 (fpr)\n",
      "  Saved benchmarking tiers plot for alphaF=0.15 (fpr)\n",
      "  Saved benchmarking tiers plot for alphaF=0.2 (fpr)\n",
      "Summary for fpr:\n",
      "  αF=0.05: ω_max=0.0888, ω_avg=0.0457, Tiers={'Optimum': 1, 'Acceptable': 2, 'Questionable': 0, 'Unacceptable': 3}\n",
      "  αF=0.1: ω_max=0.0888, ω_avg=0.0457, Tiers={'Optimum': 3, 'Acceptable': 0, 'Questionable': 3, 'Unacceptable': 0}\n",
      "  αF=0.15: ω_max=0.0888, ω_avg=0.0457, Tiers={'Optimum': 3, 'Acceptable': 1, 'Questionable': 2, 'Unacceptable': 0}\n",
      "  αF=0.2: ω_max=0.0888, ω_avg=0.0457, Tiers={'Optimum': 3, 'Acceptable': 3, 'Questionable': 0, 'Unacceptable': 0}\n",
      "\n",
      "============================================================\n",
      "ANALYZING METRIC: FNR\n",
      "============================================================\n",
      "  Saved benchmarking tiers plot for alphaF=0.05 (fnr)\n",
      "  Saved benchmarking tiers plot for alphaF=0.1 (fnr)\n",
      "  Saved benchmarking tiers plot for alphaF=0.15 (fnr)\n",
      "  Saved benchmarking tiers plot for alphaF=0.2 (fnr)\n",
      "Summary for fnr:\n",
      "  αF=0.05: ω_max=0.0967, ω_avg=0.0548, Tiers={'Optimum': 1, 'Acceptable': 0, 'Questionable': 3, 'Unacceptable': 2}\n",
      "  αF=0.1: ω_max=0.0967, ω_avg=0.0548, Tiers={'Optimum': 1, 'Acceptable': 3, 'Questionable': 2, 'Unacceptable': 0}\n",
      "  αF=0.15: ω_max=0.0967, ω_avg=0.0548, Tiers={'Optimum': 1, 'Acceptable': 3, 'Questionable': 2, 'Unacceptable': 0}\n",
      "  αF=0.2: ω_max=0.0967, ω_avg=0.0548, Tiers={'Optimum': 4, 'Acceptable': 2, 'Questionable': 0, 'Unacceptable': 0}\n",
      "\n",
      "============================================================\n",
      "ANALYZING METRIC: PPV\n",
      "============================================================\n",
      "  Saved benchmarking tiers plot for alphaF=0.05 (ppv)\n",
      "  Saved benchmarking tiers plot for alphaF=0.1 (ppv)\n",
      "  Saved benchmarking tiers plot for alphaF=0.15 (ppv)\n",
      "  Saved benchmarking tiers plot for alphaF=0.2 (ppv)\n",
      "Summary for ppv:\n",
      "  αF=0.05: ω_max=0.2781, ω_avg=0.1435, Tiers={'Optimum': 0, 'Acceptable': 0, 'Questionable': 1, 'Unacceptable': 5}\n",
      "  αF=0.1: ω_max=0.2781, ω_avg=0.1435, Tiers={'Optimum': 0, 'Acceptable': 1, 'Questionable': 0, 'Unacceptable': 5}\n",
      "  αF=0.15: ω_max=0.2781, ω_avg=0.1435, Tiers={'Optimum': 1, 'Acceptable': 0, 'Questionable': 3, 'Unacceptable': 2}\n",
      "  αF=0.2: ω_max=0.2781, ω_avg=0.1435, Tiers={'Optimum': 1, 'Acceptable': 0, 'Questionable': 4, 'Unacceptable': 1}\n",
      "\n",
      "============================================================\n",
      "ANALYZING METRIC: NPV\n",
      "============================================================\n",
      "  Saved benchmarking tiers plot for alphaF=0.05 (npv)\n",
      "  Saved benchmarking tiers plot for alphaF=0.1 (npv)\n",
      "  Saved benchmarking tiers plot for alphaF=0.15 (npv)\n",
      "  Saved benchmarking tiers plot for alphaF=0.2 (npv)\n",
      "Summary for npv:\n",
      "  αF=0.05: ω_max=0.2649, ω_avg=0.1371, Tiers={'Optimum': 0, 'Acceptable': 0, 'Questionable': 1, 'Unacceptable': 5}\n",
      "  αF=0.1: ω_max=0.2649, ω_avg=0.1371, Tiers={'Optimum': 0, 'Acceptable': 1, 'Questionable': 2, 'Unacceptable': 3}\n",
      "  αF=0.15: ω_max=0.2649, ω_avg=0.1371, Tiers={'Optimum': 1, 'Acceptable': 1, 'Questionable': 1, 'Unacceptable': 3}\n",
      "  αF=0.2: ω_max=0.2649, ω_avg=0.1371, Tiers={'Optimum': 1, 'Acceptable': 2, 'Questionable': 1, 'Unacceptable': 2}\n",
      "\n",
      "============================================================\n",
      "ANALYZING METRIC: F1\n",
      "============================================================\n",
      "  Saved benchmarking tiers plot for alphaF=0.05 (f1)\n",
      "  Saved benchmarking tiers plot for alphaF=0.1 (f1)\n",
      "  Saved benchmarking tiers plot for alphaF=0.15 (f1)\n",
      "  Saved benchmarking tiers plot for alphaF=0.2 (f1)\n",
      "Summary for f1:\n",
      "  αF=0.05: ω_max=0.1443, ω_avg=0.0747, Tiers={'Optimum': 0, 'Acceptable': 1, 'Questionable': 2, 'Unacceptable': 3}\n",
      "  αF=0.1: ω_max=0.1443, ω_avg=0.0747, Tiers={'Optimum': 1, 'Acceptable': 2, 'Questionable': 1, 'Unacceptable': 2}\n",
      "  αF=0.15: ω_max=0.1443, ω_avg=0.0747, Tiers={'Optimum': 2, 'Acceptable': 1, 'Questionable': 3, 'Unacceptable': 0}\n",
      "  αF=0.2: ω_max=0.1443, ω_avg=0.0747, Tiers={'Optimum': 3, 'Acceptable': 1, 'Questionable': 2, 'Unacceptable': 0}\n",
      "\n",
      "============================================================\n",
      "ANALYZING METRIC: AUC\n",
      "============================================================\n",
      "  Saved benchmarking tiers plot for alphaF=0.05 (auc)\n",
      "  Saved benchmarking tiers plot for alphaF=0.1 (auc)\n",
      "  Saved benchmarking tiers plot for alphaF=0.15 (auc)\n",
      "  Saved benchmarking tiers plot for alphaF=0.2 (auc)\n",
      "Summary for auc:\n",
      "  αF=0.05: ω_max=0.1010, ω_avg=0.0544, Tiers={'Optimum': 1, 'Acceptable': 1, 'Questionable': 1, 'Unacceptable': 3}\n",
      "  αF=0.1: ω_max=0.1010, ω_avg=0.0544, Tiers={'Optimum': 2, 'Acceptable': 1, 'Questionable': 2, 'Unacceptable': 1}\n",
      "  αF=0.15: ω_max=0.1010, ω_avg=0.0544, Tiers={'Optimum': 3, 'Acceptable': 1, 'Questionable': 2, 'Unacceptable': 0}\n",
      "  αF=0.2: ω_max=0.1010, ω_avg=0.0544, Tiers={'Optimum': 3, 'Acceptable': 2, 'Questionable': 1, 'Unacceptable': 0}\n",
      "\n",
      "FIC ANALYSIS TABLE (Accuracy):\n",
      "                   Group Pair              alphaF=0.05   Hypothesis alphaF=0.05               alphaF=0.1    Hypothesis alphaF=0.1              alphaF=0.15   Hypothesis alphaF=0.15              alphaF=0.2    Hypothesis alphaF=0.2\n",
      " African_American - Caucasian omega=0.0984, FIC=-0.967       Reject H₀ (Unfair)  omega=0.0984, FIC=0.016 Fail to reject Ho (Fair)  omega=0.0984, FIC=0.344 Fail to reject Ho (Fair) omega=0.0984, FIC=0.508 Fail to reject Ho (Fair)\n",
      "  African_American - Hispanic omega=0.1312, FIC=-1.625       Reject H₀ (Unfair) omega=0.1312, FIC=-0.312       Reject H₀ (Unfair)  omega=0.1312, FIC=0.125 Fail to reject Ho (Fair) omega=0.1312, FIC=0.344 Fail to reject Ho (Fair)\n",
      "African_American - Other_Race omega=0.1654, FIC=-2.308       Reject H₀ (Unfair) omega=0.1654, FIC=-0.654       Reject H₀ (Unfair) omega=0.1654, FIC=-0.103       Reject H₀ (Unfair) omega=0.1654, FIC=0.173 Fail to reject Ho (Fair)\n",
      "         Caucasian - Hispanic  omega=0.0329, FIC=0.343 Fail to reject Ho (Fair)  omega=0.0329, FIC=0.671 Fail to reject Ho (Fair)  omega=0.0329, FIC=0.781 Fail to reject Ho (Fair) omega=0.0329, FIC=0.836 Fail to reject Ho (Fair)\n",
      "       Caucasian - Other_Race omega=0.0670, FIC=-0.341       Reject H₀ (Unfair)  omega=0.0670, FIC=0.330 Fail to reject Ho (Fair)  omega=0.0670, FIC=0.553 Fail to reject Ho (Fair) omega=0.0670, FIC=0.665 Fail to reject Ho (Fair)\n",
      "        Hispanic - Other_Race  omega=0.0342, FIC=0.317 Fail to reject Ho (Fair)  omega=0.0342, FIC=0.658 Fail to reject Ho (Fair)  omega=0.0342, FIC=0.772 Fail to reject Ho (Fair) omega=0.0342, FIC=0.829 Fail to reject Ho (Fair)\n",
      "\n",
      "TIER CLASSIFICATION (Accuracy):\n",
      "\n",
      "For αF = 0.05:\n",
      "--------------------------------------------------\n",
      "African_American - Caucasian: ω=0.0984, FIC=-0.967 → Unacceptable\n",
      "African_American - Hispanic: ω=0.1312, FIC=-1.625 → Unacceptable\n",
      "African_American - Other_Race: ω=0.1654, FIC=-2.308 → Unacceptable\n",
      "Caucasian - Hispanic: ω=0.0329, FIC=0.343 → Questionable\n",
      "Caucasian - Other_Race: ω=0.0670, FIC=-0.341 → Unacceptable\n",
      "Hispanic - Other_Race: ω=0.0342, FIC=0.317 → Questionable\n",
      "\n",
      "For αF = 0.1:\n",
      "--------------------------------------------------\n",
      "African_American - Caucasian: ω=0.0984, FIC=0.016 → Questionable\n",
      "African_American - Hispanic: ω=0.1312, FIC=-0.312 → Unacceptable\n",
      "African_American - Other_Race: ω=0.1654, FIC=-0.654 → Unacceptable\n",
      "Caucasian - Hispanic: ω=0.0329, FIC=0.671 → Acceptable\n",
      "Caucasian - Other_Race: ω=0.0670, FIC=0.330 → Questionable\n",
      "Hispanic - Other_Race: ω=0.0342, FIC=0.658 → Acceptable\n",
      "\n",
      "For αF = 0.15:\n",
      "--------------------------------------------------\n",
      "African_American - Caucasian: ω=0.0984, FIC=0.344 → Questionable\n",
      "African_American - Hispanic: ω=0.1312, FIC=0.125 → Questionable\n",
      "African_American - Other_Race: ω=0.1654, FIC=-0.103 → Unacceptable\n",
      "Caucasian - Hispanic: ω=0.0329, FIC=0.781 → Optimum (omega_max < 0.0375)\n",
      "Caucasian - Other_Race: ω=0.0670, FIC=0.553 → Acceptable\n",
      "Hispanic - Other_Race: ω=0.0342, FIC=0.772 → Optimum (omega_max < 0.0375)\n",
      "\n",
      "For αF = 0.2:\n",
      "--------------------------------------------------\n",
      "African_American - Caucasian: ω=0.0984, FIC=0.508 → Acceptable\n",
      "African_American - Hispanic: ω=0.1312, FIC=0.344 → Questionable\n",
      "African_American - Other_Race: ω=0.1654, FIC=0.173 → Questionable\n",
      "Caucasian - Hispanic: ω=0.0329, FIC=0.836 → Optimum (omega_max < 0.0500)\n",
      "Caucasian - Other_Race: ω=0.0670, FIC=0.665 → Acceptable\n",
      "Hispanic - Other_Race: ω=0.0342, FIC=0.829 → Optimum (omega_max < 0.0500)\n",
      "\n",
      "MODEL COMPARISON:\n",
      "   Model Overall Accuracy Avg FIC alphaF=0.10) ω_max (alphaF=0.10)\n",
      "BASELINE           0.7547                0.118              0.1654\n",
      "      L1           0.7547                0.118              0.1654\n",
      "      L2           0.7547                0.118              0.1654\n",
      "\n",
      "================================================================================\n",
      "SUMMARY REPORT - COMPAS DATASET\n",
      "================================================================================\n",
      "COMPAS DATASET KEY FINDINGS:\n",
      "------------------------------------------------------------\n",
      "Total samples: 7214\n",
      "High risk proportion: 0.365\n",
      "\n",
      "Race group distribution:\n",
      "  African_American: 3696 (0.512)\n",
      "  Caucasian: 2454 (0.340)\n",
      "  Hispanic: 637 (0.088)\n",
      "  Other_Race: 427 (0.059)\n",
      "\n",
      "High risk by race group:\n",
      "  African_American: 0.489\n",
      "  Caucasian: 0.250\n",
      "  Hispanic: 0.217\n",
      "  Other_Race: 0.178\n",
      "\n",
      "FIC ANALYSIS SUMMARY (Accuracy):\n",
      "------------------------------------------------------------\n",
      "alphaF=0.05:\n",
      "  omega range: [0.0329, 0.1654], avg: 0.0882\n",
      "  Most unfair pair: African_American - Other_Race (ω=0.1654)\n",
      "  Most fair pair: Caucasian - Hispanic (ω=0.0329)\n",
      "  Tier distribution: {'Optimum': 0, 'Acceptable': 0, 'Questionable': 2, 'Unacceptable': 4}\n",
      "alphaF=0.1:\n",
      "  omega range: [0.0329, 0.1654], avg: 0.0882\n",
      "  Most unfair pair: African_American - Other_Race (ω=0.1654)\n",
      "  Most fair pair: Caucasian - Hispanic (ω=0.0329)\n",
      "  Tier distribution: {'Optimum': 0, 'Acceptable': 2, 'Questionable': 2, 'Unacceptable': 2}\n",
      "alphaF=0.15:\n",
      "  omega range: [0.0329, 0.1654], avg: 0.0882\n",
      "  Most unfair pair: African_American - Other_Race (ω=0.1654)\n",
      "  Most fair pair: Caucasian - Hispanic (ω=0.0329)\n",
      "  Tier distribution: {'Optimum': 2, 'Acceptable': 1, 'Questionable': 2, 'Unacceptable': 1}\n",
      "alphaF=0.2:\n",
      "  omega range: [0.0329, 0.1654], avg: 0.0882\n",
      "  Most unfair pair: African_American - Other_Race (ω=0.1654)\n",
      "  Most fair pair: Caucasian - Hispanic (ω=0.0329)\n",
      "  Tier distribution: {'Optimum': 2, 'Acceptable': 2, 'Questionable': 2, 'Unacceptable': 0}\n",
      "\n",
      "================================================================================\n",
      "ANALYSIS COMPLETE - HIGH-QUALITY PLOTS SAVED\n",
      "================================================================================\n",
      "Generated plots for all metrics: accuracy, selection_rate, tpr, tnr, fpr, fnr, ppv, npv, f1, auc\n",
      "Each metric has:\n",
      "  - 1 heatmap figure (2x2 grid for all alphaF values)\n",
      "  - 4 benchmarking tier plots (one for each alphaF: 0.05, 0.10, 0.15, 0.20)\n",
      "\n",
      "All analysis completed!\n",
      "Results saved to: compas_fic_results_NLEGEND_ALL_METRICS/\n",
      "Files include:\n",
      "  - Group metrics (CSV)\n",
      "  - FIC analysis tables for accuracy (CSV)\n",
      "  - Tier classification for accuracy (CSV)\n",
      "  - Model comparison (CSV)\n",
      "  - FIC heatmaps for ALL 10 metrics (PNG)\n",
      "  - Benchmarking tiers for ALL 10 metrics (4 plots per metric = 40 PNG files)\n",
      "\n",
      "Total plots generated: 50 files\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create output directory\n",
    "output_dir = \"compas_fic_results_NLEGEND_ALL_METRICS\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Set style for publication quality\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Global font settings for consistency\n",
    "plt.rcParams.update({\n",
    "    'font.size': 12,\n",
    "    'axes.titlesize': 16,\n",
    "    'axes.labelsize': 14,\n",
    "    'xtick.labelsize': 12,\n",
    "    'ytick.labelsize': 12,\n",
    "    'legend.fontsize': 12,\n",
    "})\n",
    "\n",
    "# ============================================\n",
    "# 1. LOAD AND PREPROCESS COMPAS DATASET\n",
    "# ============================================\n",
    "\n",
    "def load_compas_data():\n",
    "    \"\"\"\n",
    "    Load and preprocess COMPAS ProPublica dataset from local folder\n",
    "    \"\"\"\n",
    "    # Define your specific folder path\n",
    "    data_folder = r'C:\\Users\\Dr. Akin\\OneDrive\\2025\\Paper_2025\\PHD_Work'\n",
    "    data_file = \"compas-scores-two-years.csv\"\n",
    "    data_path = os.path.join(data_folder, data_file)\n",
    "    \n",
    "    print(f\"Looking for COMPAS dataset at: {data_path}\")\n",
    "    \n",
    "    # Try to load from your specified folder\n",
    "    compas_df = pd.read_csv(data_path)\n",
    "    print(\"Loaded COMPAS dataset from specified folder\")\n",
    "   \n",
    "    \n",
    "    # Filter relevant columns\n",
    "    relevant_columns = [\n",
    "        'age', 'sex', 'race', 'priors_count', 'c_charge_degree',\n",
    "        'juv_fel_count', 'juv_misd_count', 'juv_other_count',\n",
    "        'decile_score', 'two_year_recid'\n",
    "    ]\n",
    "    \n",
    "    # Check which columns exist in the dataset\n",
    "    available_columns = [col for col in relevant_columns if col in compas_df.columns]\n",
    "    compas_df = compas_df[available_columns].copy()\n",
    "    \n",
    "    # Drop rows with missing values\n",
    "    compas_df = compas_df.dropna()\n",
    "    \n",
    "    # Create high_risk target: 0-5 as low risk, 6-10 as high risk\n",
    "    compas_df['high_risk'] = (compas_df['decile_score'] >= 6).astype(int)\n",
    "    \n",
    "    # Consolidate race categories\n",
    "    def consolidate_race(race):\n",
    "        race = str(race).strip().lower()\n",
    "        if 'african' in race or 'black' in race:\n",
    "            return 'African_American'\n",
    "        elif 'caucasian' in race or 'white' in race:\n",
    "            return 'Caucasian'\n",
    "        elif 'hispanic' in race or 'latino' in race:\n",
    "            return 'Hispanic'\n",
    "        elif 'asian' in race or 'arab' in race or 'native' in race or 'other' in race:\n",
    "            return 'Other_Race'\n",
    "        else:\n",
    "            return 'Other_Race'\n",
    "    \n",
    "    compas_df['race_group'] = compas_df['race'].apply(consolidate_race)\n",
    "    \n",
    "    # Filter to keep only our target race groups\n",
    "    target_races = ['African_American', 'Caucasian', 'Hispanic', 'Other_Race']\n",
    "    compas_df = compas_df[compas_df['race_group'].isin(target_races)].copy()\n",
    "    \n",
    "    # Create additional features for better prediction\n",
    "    compas_df['total_juvenile_charges'] = compas_df['juv_fel_count'] + compas_df['juv_misd_count'] + compas_df['juv_other_count']\n",
    "    compas_df['is_felony'] = (compas_df['c_charge_degree'] == 'F').astype(int)\n",
    "    compas_df['age_group'] = pd.cut(compas_df['age'], \n",
    "                                     bins=[0, 25, 35, 45, 55, 100],\n",
    "                                     labels=['18-25', '26-35', '36-45', '46-55', '56+'])\n",
    "    \n",
    "    # Select final columns for analysis\n",
    "    final_columns = [\n",
    "        'age', 'sex', 'race_group', 'priors_count', 'is_felony',\n",
    "        'total_juvenile_charges', 'age_group', 'high_risk'\n",
    "    ]\n",
    "    \n",
    "    # Ensure all columns exist\n",
    "    final_columns = [col for col in final_columns if col in compas_df.columns]\n",
    "    compas_df = compas_df[final_columns]\n",
    "    \n",
    "    print(f\"Processed dataset shape: {compas_df.shape}\")\n",
    "    print(f\"Target distribution (high_risk):\")\n",
    "    print(compas_df['high_risk'].value_counts(normalize=True))\n",
    "    print(f\"\\nRace group distribution:\")\n",
    "    print(compas_df['race_group'].value_counts(normalize=True))\n",
    "    \n",
    "    return compas_df\n",
    "\n",
    "def generate_compas_data(n_samples=None):\n",
    "    \"\"\"\n",
    "    Wrapper function to load COMPAS data\n",
    "    n_samples parameter is kept for compatibility but not used\n",
    "    \"\"\"\n",
    "    data = load_compas_data()\n",
    "    \n",
    "    # If n_samples is specified and smaller than dataset, sample it\n",
    "    if n_samples and n_samples < len(data):\n",
    "        data = data.sample(n=n_samples, random_state=42)\n",
    "    \n",
    "    return data\n",
    "\n",
    "# ============================================\n",
    "# 2-3. MODEL & FIC\n",
    "# ============================================\n",
    "\n",
    "def compute_all_metrics(y_true, y_pred, y_prob):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_true, y_pred),\n",
    "        'selection_rate': (tp + fp) / len(y_true),\n",
    "        'tpr': tp / (tp + fn) if (tp + fn) > 0 else 0,\n",
    "        'tnr': tn / (tn + fp) if (tn + fp) > 0 else 0,\n",
    "        'fpr': fp / (fp + tn) if (fp + tn) > 0 else 0,\n",
    "        'fnr': fn / (tp + fn) if (tp + fn) > 0 else 0,\n",
    "        'ppv': tp / (tp + fp) if (tp + fp) > 0 else 0,\n",
    "        'npv': tn / (tn + fn) if (tn + fn) > 0 else 0,\n",
    "        'f1': f1_score(y_true, y_pred),\n",
    "        'auc': roc_auc_score(y_true, y_prob) if len(np.unique(y_true)) > 1 else np.nan\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "def train_and_evaluate_models(data, target_col, protected_col, model_type='baseline'):\n",
    "    X = data.drop(columns=[target_col, protected_col])\n",
    "    y = data[target_col]\n",
    "    categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "    numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(drop='first'), categorical_cols)\n",
    "    ])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "    protected_test = data.loc[X_test.index, protected_col]\n",
    "\n",
    "    X_train_processed = preprocessor.fit_transform(X_train)\n",
    "    X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "    if model_type == 'baseline':\n",
    "        model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "    elif model_type == 'l1':\n",
    "        model = LogisticRegression(penalty='l1', solver='liblinear', random_state=42, max_iter=1000, C=1.0)\n",
    "    elif model_type == 'l2':\n",
    "        model = LogisticRegression(penalty='l2', random_state=42, max_iter=1000, C=1.0)\n",
    "    else:\n",
    "        model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "    model.fit(X_train_processed, y_train)\n",
    "    y_pred = model.predict(X_test_processed)\n",
    "    y_prob = model.predict_proba(X_test_processed)[:, 1]\n",
    "\n",
    "    group_metrics = {}\n",
    "    for group in protected_test.unique():\n",
    "        mask = protected_test == group\n",
    "        if mask.sum() > 0:\n",
    "            group_metrics[group] = compute_all_metrics(y_test[mask], y_pred[mask], y_prob[mask])\n",
    "\n",
    "    return group_metrics, (X_test, y_test, protected_test, y_pred, y_prob)\n",
    "\n",
    "class FairnessInformationCriterion:\n",
    "    def __init__(self, alphaF_values=[0.05, 0.10, 0.15, 0.20]):\n",
    "        self.alphaF_values = alphaF_values\n",
    "\n",
    "    def compute_omega(self, metric1, metric2):\n",
    "        return abs(metric1 - metric2)\n",
    "\n",
    "    def compute_fic(self, omega, alphaF):\n",
    "        return 1 - (omega / alphaF)\n",
    "\n",
    "    def classify_tier(self, fic_score):\n",
    "        if fic_score > 0.75:\n",
    "            return \"Optimum\"\n",
    "        elif fic_score > 0.50:\n",
    "            return \"Acceptable\"\n",
    "        elif fic_score > 0:\n",
    "            return \"Questionable\"\n",
    "        else:\n",
    "            return \"Unacceptable\"\n",
    "\n",
    "    def analyze_fairness(self, group_metrics, metric_name='accuracy'):\n",
    "        results = {}\n",
    "        groups = list(group_metrics.keys())\n",
    "        for alphaF in self.alphaF_values:\n",
    "            results[alphaF] = {}\n",
    "            for i, g1 in enumerate(groups):\n",
    "                for g2 in groups[i+1:]:\n",
    "                    pair = f\"{g1} - {g2}\"\n",
    "                    m1 = group_metrics[g1].get(metric_name, np.nan)\n",
    "                    m2 = group_metrics[g2].get(metric_name, np.nan)\n",
    "                    if not np.isnan(m1) and not np.isnan(m2):\n",
    "                        omega = self.compute_omega(m1, m2)\n",
    "                        fic_score = self.compute_fic(omega, alphaF)\n",
    "                        tier = self.classify_tier(fic_score)\n",
    "                        results[alphaF][pair] = {\n",
    "                            'omega': omega, 'fic_score': fic_score, 'tier': tier,\n",
    "                            'metric1': m1, 'metric2': m2\n",
    "                        }\n",
    "        return results\n",
    "\n",
    "# ============================================\n",
    "# 4. VISUALIZATIONS - UPDATED FOR ALL METRICS\n",
    "# ============================================\n",
    "\n",
    "def plot_fic_heatmaps(fic_results, dataset_name, metric='accuracy'):\n",
    "    alphaF_values = sorted(fic_results.keys())\n",
    "    if not alphaF_values:\n",
    "        return\n",
    "\n",
    "    pairs = list(fic_results[alphaF_values[0]].keys())\n",
    "    all_groups = sorted(set(g for p in pairs for g in p.split(' - ')))\n",
    "\n",
    "    # Larger figure\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(20, 16))\n",
    "    fig.suptitle(f'{dataset_name}: FIC Heatmaps for Different alphaF Values ({metric})',\n",
    "                 fontsize=20, fontweight='bold', y=0.98)\n",
    "\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for idx, alphaF in enumerate(alphaF_values):\n",
    "        ax = axes[idx]\n",
    "        n = len(all_groups)\n",
    "        mat = np.full((n, n), np.nan)\n",
    "        group_idx = {g: i for i, g in enumerate(all_groups)}\n",
    "\n",
    "        for pair, d in fic_results[alphaF].items():\n",
    "            g1, g2 = pair.split(' - ')\n",
    "            i, j = group_idx[g1], group_idx[g2]\n",
    "            mat[i, j] = mat[j, i] = d['fic_score']\n",
    "\n",
    "        im = ax.imshow(mat, cmap='RdYlGn', vmin=-1, vmax=1, aspect='equal')\n",
    "\n",
    "        # Add value labels inside cells\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                if i != j and not np.isnan(mat[i, j]):\n",
    "                    text = ax.text(j, i, f'{mat[i,j]:.2f}',\n",
    "                                   ha='center', va='center',\n",
    "                                   fontsize=14, fontweight='bold',\n",
    "                                   color='white' if abs(mat[i,j]) > 0.5 else 'black')\n",
    "\n",
    "        ax.set_xticks(range(n))\n",
    "        ax.set_yticks(range(n))\n",
    "        ax.set_xticklabels(all_groups, rotation=45, ha='right', fontsize=13, fontweight='bold')\n",
    "        ax.set_yticklabels(all_groups, fontsize=13, fontweight='bold')\n",
    "        ax.set_title(f'αF = {alphaF}', fontsize=18, fontweight='bold', pad=20)\n",
    "        \n",
    "        # Add grid\n",
    "        ax.set_xticks(np.arange(-.5, n, 1), minor=True)\n",
    "        ax.set_yticks(np.arange(-.5, n, 1), minor=True)\n",
    "        ax.grid(which='minor', color='gray', linestyle='-', linewidth=0.5, alpha=0.3)\n",
    "\n",
    "    # Add a single comprehensive colorbar with tier labels\n",
    "    cbar_ax = fig.add_axes([0.75, 0.15, 0.03, 0.7])  # [left, bottom, width, height]\n",
    "    cbar = fig.colorbar(im, cax=cbar_ax)\n",
    "    cbar.set_label('FIC Score', fontsize=14, fontweight='bold', labelpad=15)\n",
    "    cbar.ax.tick_params(labelsize=12)\n",
    "    \n",
    "    # Bold the colorbar tick labels\n",
    "    for label in cbar.ax.get_yticklabels():\n",
    "        label.set_fontweight('bold')\n",
    "    \n",
    "    # Add tier annotations on the colorbar\n",
    "    cbar.ax.text(1.1, 0.90, 'Optimum', transform=cbar.ax.transAxes, \n",
    "                 fontsize=14, fontweight='bold', va='center', ha='left', color='darkgreen')\n",
    "    cbar.ax.text(1.1, 0.60, 'Acceptable', transform=cbar.ax.transAxes, \n",
    "                 fontsize=14, fontweight='bold', va='center', ha='left', color='goldenrod')\n",
    "    cbar.ax.text(1.1, 0.350, 'Questionable', transform=cbar.ax.transAxes, \n",
    "                 fontsize=14, fontweight='bold', va='center', ha='left', color='darkorange')\n",
    "    cbar.ax.text(1.1, 0.100, 'Unacceptable', transform=cbar.ax.transAxes, \n",
    "                 fontsize=14, fontweight='bold', va='center', ha='left', color='darkred')\n",
    "    \n",
    "    # Add tier threshold lines on colorbar\n",
    "    cbar.ax.axhline(0.75, color='darkgreen', linestyle='--', linewidth=3, xmax=0.8)\n",
    "    cbar.ax.axhline(0.50, color='goldenrod', linestyle='--', linewidth=3, xmax=0.8)\n",
    "    cbar.ax.axhline(0.00, color='darkred', linestyle='--', linewidth=3, xmax=0.8)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 0.8, 0.95])\n",
    "    plt.savefig(os.path.join(output_dir, f'{dataset_name}_FIC_Heatmaps_{metric}.png'), dpi=400, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_benchmarking_tiers(fic_results, dataset_name, metric='accuracy'):\n",
    "    # Sort alphaF values to ensure consistent order\n",
    "    alphaF_values = sorted(fic_results.keys())\n",
    "    \n",
    "    # Define colors for tiers\n",
    "    colors = {'Optimum': '#2E8B57', 'Acceptable': '#FFD700', \n",
    "              'Questionable': '#FF8C00', 'Unacceptable': '#DC143C'}\n",
    "    \n",
    "    for alphaF in alphaF_values:\n",
    "        if alphaF not in fic_results or not fic_results[alphaF]:\n",
    "            print(f\"No data for alphaF={alphaF} in benchmarking tiers\")\n",
    "            continue\n",
    "        \n",
    "        # Create a figure with more width to accommodate legend\n",
    "        fig, ax = plt.subplots(figsize=(16, 8))\n",
    "        \n",
    "        data = fic_results[alphaF]\n",
    "        pairs = list(data.keys())\n",
    "        fic_scores = [data[p]['fic_score'] for p in pairs]\n",
    "        tiers = [data[p]['tier'] for p in pairs]\n",
    "        \n",
    "        # Find max positive and max negative values\n",
    "        max_positive = max(fic_scores) if fic_scores else 1.0\n",
    "        min_negative = min(fic_scores) if fic_scores else -0.25\n",
    "        \n",
    "        # Add padding (10% on positive side, 10% on negative side)\n",
    "        y_max = max_positive * 1.10 if max_positive > 0 else 0.10\n",
    "        y_min = min_negative * 1.10 if min_negative < 0 else -0.10\n",
    "        \n",
    "        # Ensure at least some range for visualization\n",
    "        if y_max - y_min < 0.5:\n",
    "            # If range is too small, center it around the data\n",
    "            center = (max_positive + min_negative) / 2\n",
    "            y_max = center + 0.25\n",
    "            y_min = center - 0.25\n",
    "        \n",
    "        # Create bar colors based on tiers\n",
    "        bar_colors = [colors[t] for t in tiers]\n",
    "        \n",
    "        # Create bars with smaller width for more compact look\n",
    "        bars = ax.bar(range(len(pairs)), fic_scores, color=bar_colors, \n",
    "                      edgecolor='black', linewidth=1.2, width=0.6)\n",
    "        \n",
    "        # Add tier threshold lines with better styling\n",
    "        ax.axhline(0.75, color='darkgreen', linestyle='--', linewidth=2.0, \n",
    "                   alpha=0.7)\n",
    "        ax.axhline(0.50, color='goldenrod', linestyle='--', linewidth=2.0, \n",
    "                   alpha=0.7)\n",
    "        ax.axhline(0.00, color='darkred', linestyle='--', linewidth=2.0, \n",
    "                   alpha=0.7)\n",
    "        \n",
    "        # Customize axes with better labels\n",
    "        ax.set_xlabel('Group Pairs', fontsize=14, fontweight='bold', labelpad=10)\n",
    "        ax.set_ylabel('FIC Score', fontsize=14, fontweight='bold', labelpad=10)\n",
    "        ax.set_title(f'{dataset_name}\\nFIC Benchmarking Tiers ({metric}, αF = {alphaF})',\n",
    "                    fontsize=16, fontweight='bold', pad=15)\n",
    "        \n",
    "        # Set x-ticks with rotation for readability\n",
    "        ax.set_xticks(range(len(pairs)))\n",
    "        ax.set_xticklabels(pairs, rotation=45, ha='right', fontsize=11, fontweight='bold')\n",
    "        \n",
    "        # Set dynamic y-axis limits based on actual max positive and max negative\n",
    "        ax.set_ylim(y_min, y_max)\n",
    "        \n",
    "        # Bold the y-axis tick labels\n",
    "        y_ticks = ax.get_yticks()\n",
    "        ax.set_yticklabels([f'{tick:.2f}' for tick in y_ticks], fontsize=11, fontweight='bold')\n",
    "        \n",
    "        # Add grid with lighter style\n",
    "        ax.grid(True, axis='y', alpha=0.3, linestyle='-', linewidth=0.5)\n",
    "        ax.grid(True, axis='x', alpha=0.1, linestyle='-', linewidth=0.5)\n",
    "        \n",
    "        # Add better legend - moved to top right with fewer items\n",
    "        from matplotlib.patches import Patch\n",
    "        legend_elements = [\n",
    "            Patch(facecolor=colors['Optimum'], edgecolor='black', label='Optimum (FIC > 0.75)'),\n",
    "            Patch(facecolor=colors['Acceptable'], edgecolor='black', label='Acceptable (0.50 < FIC ≤ 0.75)'),\n",
    "            Patch(facecolor=colors['Questionable'], edgecolor='black', label='Questionable (0 < FIC ≤ 0.50)'),\n",
    "            Patch(facecolor=colors['Unacceptable'], edgecolor='black', label='Unacceptable (FIC ≤ 0)')\n",
    "        ]\n",
    "        \n",
    "        # Create a separate legend for threshold lines\n",
    "        from matplotlib.lines import Line2D\n",
    "        line_legend_elements = [\n",
    "            Line2D([0], [0], color='darkgreen', linestyle='--', linewidth=2, label='Optimum Threshold (0.75)'),\n",
    "            Line2D([0], [0], color='goldenrod', linestyle='--', linewidth=2, label='Acceptable Threshold (0.50)'),\n",
    "            Line2D([0], [0], color='darkred', linestyle='--', linewidth=2, label='Unacceptable Threshold (0.00)')\n",
    "        ]\n",
    "        \n",
    "        # Place tier legend at upper left\n",
    "        tier_legend = ax.legend(handles=legend_elements, fontsize=10, \n",
    "                                loc='upper left', bbox_to_anchor=(1.02, 1.0),\n",
    "                                frameon=True, framealpha=0.9, edgecolor='black',\n",
    "                                title='FIC Tiers', title_fontsize=11)\n",
    "        # Make the legend title bold\n",
    "        tier_legend.get_title().set_fontweight('bold')\n",
    "        ax.add_artist(tier_legend)\n",
    "        \n",
    "        # Place threshold legend at upper left below tier legend\n",
    "        threshold_legend = ax.legend(handles=line_legend_elements, fontsize=9, \n",
    "                                     loc='upper left', bbox_to_anchor=(1.02, 0.65),\n",
    "                                     frameon=True, framealpha=0.9, edgecolor='black',\n",
    "                                     title='Thresholds', title_fontsize=10)\n",
    "        # Make the legend title bold\n",
    "        threshold_legend.get_title().set_fontweight('bold')\n",
    "        \n",
    "        # Add annotation for alphaF interpretation\n",
    "        annotation_text = f'αF = {alphaF}\\nFIC = 1 - (ω/αF)\\nω = |M₁ - M₂|'\n",
    "        ax.text(0.02, 0.98, annotation_text, transform=ax.transAxes,\n",
    "                fontsize=9, verticalalignment='top', fontweight='bold',\n",
    "                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
    "        \n",
    "        # Adjust layout to make room for legend\n",
    "        plt.tight_layout(rect=[0, 0, 0.85, 1])\n",
    "        \n",
    "        # Save the figure with alphaF in the filename\n",
    "        plt.savefig(os.path.join(output_dir, f'{dataset_name}_Benchmarking_Tiers_alphaF_{alphaF}_{metric}.png'), \n",
    "                    dpi=400, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        print(f\"  Saved benchmarking tiers plot for alphaF={alphaF} ({metric})\")\n",
    "\n",
    "# ============================================\n",
    "# 5. ANALYSIS FUNCTIONS - UPDATED FOR ALL METRICS\n",
    "# ============================================\n",
    "\n",
    "def analyze_dataset(dataset_name, data_generator, target_col, protected_col, case_number=1, model_types=['baseline', 'l1', 'l2']):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"CASE {case_number}: {dataset_name}\")\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "    data = data_generator()\n",
    "    fic_framework = FairnessInformationCriterion()\n",
    "\n",
    "    baseline_metrics, _ = train_and_evaluate_models(data, target_col, protected_col, 'baseline')\n",
    "\n",
    "    metrics_df = pd.DataFrame.from_dict(baseline_metrics, orient='index')\n",
    "    metrics_df = metrics_df[['accuracy', 'selection_rate', 'tpr', 'tnr', 'fpr', 'fnr', 'ppv', 'npv', 'f1', 'auc']]\n",
    "    print(\"GROUP METRICS TABLE (Baseline Logistic Regression):\")\n",
    "    print(metrics_df.round(4).to_string())\n",
    "    metrics_df.to_csv(os.path.join(output_dir, f'Case{case_number}_Group_Metrics.csv'))\n",
    "\n",
    "    print(\"\\nGENERATING VISUALIZATIONS FOR ALL METRICS...\")\n",
    "    \n",
    "    # List of all metrics to analyze\n",
    "    all_metrics = ['accuracy', 'selection_rate', 'tpr', 'tnr', 'fpr', 'fnr', 'ppv', 'npv', 'f1', 'auc']\n",
    "    \n",
    "    # Dictionary to store all FIC results\n",
    "    all_fic_results = {}\n",
    "    \n",
    "    for metric in all_metrics:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"ANALYZING METRIC: {metric.upper()}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # Analyze fairness for this metric\n",
    "        fic_results = fic_framework.analyze_fairness(baseline_metrics, metric)\n",
    "        all_fic_results[metric] = fic_results\n",
    "        \n",
    "        # Generate heatmaps for this metric\n",
    "        plot_fic_heatmaps(fic_results, f'Case{case_number}_{dataset_name}_{metric}', metric)\n",
    "        \n",
    "        # Generate benchmarking tiers for this metric\n",
    "        plot_benchmarking_tiers(fic_results, f'Case{case_number}_{dataset_name}_{metric}', metric)\n",
    "        \n",
    "        # Print summary for this metric\n",
    "        print(f\"Summary for {metric}:\")\n",
    "        for af in fic_framework.alphaF_values:\n",
    "            if af in fic_results and fic_results[af]:\n",
    "                omegas = [d['omega'] for d in fic_results[af].values()]\n",
    "                max_o = max(omegas)\n",
    "                avg_o = np.mean(omegas)\n",
    "                fic = FairnessInformationCriterion()\n",
    "                tiers = {'Optimum': 0, 'Acceptable': 0, 'Questionable': 0, 'Unacceptable': 0}\n",
    "                for d in fic_results[af].values():\n",
    "                    tiers[fic.classify_tier(d['fic_score'])] += 1\n",
    "                print(f\"  αF={af}: ω_max={max_o:.4f}, ω_avg={avg_o:.4f}, Tiers={tiers}\")\n",
    "\n",
    "    # Store FIC results for accuracy (original metric) for backward compatibility\n",
    "    fic_results = all_fic_results['accuracy']\n",
    "    \n",
    "    # FIC table for accuracy (original)\n",
    "    fic_table = []\n",
    "    for pair in sorted(set(p for a in fic_results.values() for p in a.keys())):\n",
    "        row = {'Group Pair': pair}\n",
    "        for af in fic_framework.alphaF_values:\n",
    "            if af in fic_results and pair in fic_results[af]:\n",
    "                d = fic_results[af][pair]\n",
    "                row[f'alphaF={af}'] = f\"omega={d['omega']:.4f}, FIC={d['fic_score']:.3f}\"\n",
    "                row[f'Hypothesis alphaF={af}'] = \"Fail to reject Ho (Fair)\" if d['omega'] <= af else \"Reject H₀ (Unfair)\"\n",
    "            else:\n",
    "                row[f'alphaF={af}'] = \"N/A\"; row[f'Hypothesis alphaF={af}'] = \"N/A\"\n",
    "        fic_table.append(row)\n",
    "    fic_df = pd.DataFrame(fic_table)\n",
    "    print(\"\\nFIC ANALYSIS TABLE (Accuracy):\")\n",
    "    print(fic_df.to_string(index=False))\n",
    "    fic_df.to_csv(os.path.join(output_dir, f'Case{case_number}_FIC_Analysis_accuracy.csv'), index=False)\n",
    "\n",
    "    # Tier classification for accuracy (original)\n",
    "    tier_data = []\n",
    "    print(\"\\nTIER CLASSIFICATION (Accuracy):\")\n",
    "    for af in fic_framework.alphaF_values:\n",
    "        print(f\"\\nFor αF = {af}:\")\n",
    "        print(\"-\" * 50)\n",
    "        if af in fic_results:\n",
    "            for pair, d in fic_results[af].items():\n",
    "                tier = fic_framework.classify_tier(d['fic_score'])\n",
    "                msg = tier if d['fic_score'] <= 0.75 else f\"{tier} (omega_max < {0.25*af:.4f})\"\n",
    "                print(f\"{pair}: ω={d['omega']:.4f}, FIC={d['fic_score']:.3f} → {msg}\")\n",
    "                tier_data.append({'alphaF': af, 'Group Pair': pair, 'ω': d['omega'], 'FIC': d['fic_score'], 'Tier': tier})\n",
    "    tier_df = pd.DataFrame(tier_data)\n",
    "    tier_df.to_csv(os.path.join(output_dir, f'Case{case_number}_Tier_Classification_accuracy.csv'), index=False)\n",
    "\n",
    "    # Model comparison\n",
    "    print(\"\\nMODEL COMPARISON:\")\n",
    "    comparison = []\n",
    "    for mt in model_types:\n",
    "        mets, test_data = train_and_evaluate_models(data, target_col, protected_col, mt)\n",
    "        model_fic = fic_framework.analyze_fairness(mets, 'accuracy')\n",
    "        avg_fic = np.mean([d['fic_score'] for d in model_fic[0.10].values()]) if 0.10 in model_fic and model_fic[0.10] else np.nan\n",
    "        max_omega = max([d['omega'] for d in model_fic[0.10].values()]) if 0.10 in model_fic and model_fic[0.10] else np.nan\n",
    "        _, y_test, _, y_pred, _ = test_data\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        comparison.append({\n",
    "            'Model': mt.upper(),\n",
    "            'Overall Accuracy': f\"{acc:.4f}\",\n",
    "            'Avg FIC alphaF=0.10)': f\"{avg_fic:.3f}\" if not np.isnan(avg_fic) else \"N/A\",\n",
    "            'ω_max (alphaF=0.10)': f\"{max_omega:.4f}\" if not np.isnan(max_omega) else \"N/A\"\n",
    "        })\n",
    "    comparison_df = pd.DataFrame(comparison)\n",
    "    print(comparison_df.to_string(index=False))\n",
    "    comparison_df.to_csv(os.path.join(output_dir, f'Case{case_number}_Model_Comparison.csv'), index=False)\n",
    "\n",
    "    return {\n",
    "        'data': data,\n",
    "        'baseline_metrics': baseline_metrics,\n",
    "        'fic_results': fic_results,\n",
    "        'all_fic_results': all_fic_results,  # Store all metrics results\n",
    "        'metrics_df': metrics_df,\n",
    "        'fic_df': fic_df,\n",
    "        'tier_df': tier_df,\n",
    "        'comparison_df': comparison_df\n",
    "    }\n",
    "\n",
    "# ============================================\n",
    "# 6. MAIN ANALYSIS\n",
    "# ============================================\n",
    "\n",
    "def run_complete_analysis():\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"FAIRNESS INFORMATION CRITERION (FIC) ANALYSIS - COMPAS DATASET\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    compas_results = analyze_dataset(\n",
    "        dataset_name=\"COMPAS - Recidivism Risk Prediction\",\n",
    "        data_generator=lambda: generate_compas_data(8000),\n",
    "        target_col='high_risk',\n",
    "        protected_col='race_group',\n",
    "        case_number=1\n",
    "    )\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"SUMMARY REPORT - COMPAS DATASET\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    print(\"COMPAS DATASET KEY FINDINGS:\")\n",
    "    print(\"-\" * 60)\n",
    "    data = compas_results['data']\n",
    "    print(f\"Total samples: {len(data)}\")\n",
    "    print(f\"High risk proportion: {data['high_risk'].mean():.3f}\")\n",
    "    print(\"\\nRace group distribution:\")\n",
    "    race_dist = data['race_group'].value_counts()\n",
    "    for race, count in race_dist.items():\n",
    "        prop = count / len(data)\n",
    "        print(f\"  {race}: {count} ({prop:.3f})\")\n",
    "    \n",
    "    print(\"\\nHigh risk by race group:\")\n",
    "    for race in sorted(data['race_group'].unique()):\n",
    "        subset = data[data['race_group'] == race]\n",
    "        risk_prop = subset['high_risk'].mean()\n",
    "        print(f\"  {race}: {risk_prop:.3f}\")\n",
    "\n",
    "    print(\"\\nFIC ANALYSIS SUMMARY (Accuracy):\")\n",
    "    print(\"-\" * 60)\n",
    "    for af in [0.05, 0.10, 0.15, 0.20]:\n",
    "        if af in compas_results['fic_results'] and compas_results['fic_results'][af]:\n",
    "            items = list(compas_results['fic_results'][af].items())\n",
    "            max_o = max(d['omega'] for _, d in items)\n",
    "            min_o = min(d['omega'] for _, d in items)\n",
    "            avg_o = np.mean([d['omega'] for _, d in items])\n",
    "            worst_pair = max(items, key=lambda x: x[1]['omega'])[0]\n",
    "            best_pair = min(items, key=lambda x: x[1]['omega'])[0]\n",
    "            print(f\"alphaF={af}:\")\n",
    "            print(f\"  omega range: [{min_o:.4f}, {max_o:.4f}], avg: {avg_o:.4f}\")\n",
    "            print(f\"  Most unfair pair: {worst_pair} (ω={max_o:.4f})\")\n",
    "            print(f\"  Most fair pair: {best_pair} (ω={min_o:.4f})\")\n",
    "            \n",
    "            # Tier distribution\n",
    "            fic = FairnessInformationCriterion()\n",
    "            tiers = {'Optimum': 0, 'Acceptable': 0, 'Questionable': 0, 'Unacceptable': 0}\n",
    "            for d in compas_results['fic_results'][af].values():\n",
    "                tiers[fic.classify_tier(d['fic_score'])] += 1\n",
    "            print(f\"  Tier distribution: {tiers}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ANALYSIS COMPLETE - HIGH-QUALITY PLOTS SAVED\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Generated plots for all metrics: accuracy, selection_rate, tpr, tnr, fpr, fnr, ppv, npv, f1, auc\")\n",
    "    print(f\"Each metric has:\")\n",
    "    print(f\"  - 1 heatmap figure (2x2 grid for all alphaF values)\")\n",
    "    print(f\"  - 4 benchmarking tier plots (one for each alphaF: 0.05, 0.10, 0.15, 0.20)\")\n",
    "\n",
    "    return compas_results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Check if dataset exists or download it\n",
    "    compas_results = run_complete_analysis()\n",
    "\n",
    "    print(\"\\nAll analysis completed!\")\n",
    "    print(f\"Results saved to: {output_dir}/\")\n",
    "    print(\"Files include:\")\n",
    "    print(\"  - Group metrics (CSV)\")\n",
    "    print(\"  - FIC analysis tables for accuracy (CSV)\")\n",
    "    print(\"  - Tier classification for accuracy (CSV)\")\n",
    "    print(\"  - Model comparison (CSV)\")\n",
    "    print(\"  - FIC heatmaps for ALL 10 metrics (PNG)\")\n",
    "    print(\"  - Benchmarking tiers for ALL 10 metrics (4 plots per metric = 40 PNG files)\")\n",
    "    print(f\"\\nTotal plots generated: {10 + 40} files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb74b4d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d58d0a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FAIRNESS INFORMATION CRITERION (FIC) ANALYSIS - COMPAS DATASET\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "CASE 1: COMPAS - Recidivism Risk Prediction\n",
      "================================================================================\n",
      "Looking for COMPAS dataset at: C:\\Users\\Dr. Akin\\OneDrive\\2025\\Paper_2025\\PHD_Work\\compas-scores-two-years.csv\n",
      "Loaded COMPAS dataset from specified folder\n",
      "Processed dataset shape: (7214, 8)\n",
      "Target distribution (high_risk):\n",
      "high_risk\n",
      "0    0.634599\n",
      "1    0.365401\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Race group distribution:\n",
      "race_group\n",
      "African_American    0.512337\n",
      "Caucasian           0.340172\n",
      "Hispanic            0.088301\n",
      "Other_Race          0.059190\n",
      "Name: proportion, dtype: float64\n",
      "GROUP METRICS TABLE (Baseline Logistic Regression):\n",
      "                  accuracy  selection_rate     tpr     tnr     fpr     fnr     ppv     npv      f1     auc\n",
      "African_American    0.6993          0.3501  0.5498  0.8460  0.1540  0.4502  0.7781  0.6568  0.6443  0.7555\n",
      "Caucasian           0.7976          0.1787  0.4531  0.9139  0.0861  0.5469  0.6397  0.8320  0.5305  0.8210\n",
      "Hispanic            0.8305          0.1525  0.4615  0.9348  0.0652  0.5385  0.6667  0.8600  0.5455  0.8443\n",
      "Other_Race          0.8647          0.1353  0.5000  0.9217  0.0783  0.5000  0.5000  0.9217  0.5000  0.8565\n",
      "\n",
      "GENERATING VISUALIZATIONS FOR ALL METRICS...\n",
      "\n",
      "============================================================\n",
      "ANALYZING METRIC: ACCURACY\n",
      "============================================================\n",
      "  Saved benchmarking tiers plot for alphaF=0.05 (accuracy)\n",
      "  Saved benchmarking tiers plot for alphaF=0.1 (accuracy)\n",
      "  Saved benchmarking tiers plot for alphaF=0.15 (accuracy)\n",
      "  Saved benchmarking tiers plot for alphaF=0.2 (accuracy)\n",
      "Summary for accuracy:\n",
      "  αF=0.05: ω_max=0.1654, ω_avg=0.0882, Tiers={'Optimum': 0, 'Acceptable': 0, 'Questionable': 2, 'Unacceptable': 4}\n",
      "  αF=0.1: ω_max=0.1654, ω_avg=0.0882, Tiers={'Optimum': 0, 'Acceptable': 2, 'Questionable': 2, 'Unacceptable': 2}\n",
      "  αF=0.15: ω_max=0.1654, ω_avg=0.0882, Tiers={'Optimum': 2, 'Acceptable': 1, 'Questionable': 2, 'Unacceptable': 1}\n",
      "  αF=0.2: ω_max=0.1654, ω_avg=0.0882, Tiers={'Optimum': 2, 'Acceptable': 2, 'Questionable': 2, 'Unacceptable': 0}\n",
      "\n",
      "============================================================\n",
      "ANALYZING METRIC: SELECTION_RATE\n",
      "============================================================\n",
      "  Saved benchmarking tiers plot for alphaF=0.05 (selection_rate)\n",
      "  Saved benchmarking tiers plot for alphaF=0.1 (selection_rate)\n",
      "  Saved benchmarking tiers plot for alphaF=0.15 (selection_rate)\n",
      "  Saved benchmarking tiers plot for alphaF=0.2 (selection_rate)\n",
      "Summary for selection_rate:\n",
      "  αF=0.05: ω_max=0.2148, ω_avg=0.1117, Tiers={'Optimum': 0, 'Acceptable': 1, 'Questionable': 2, 'Unacceptable': 3}\n",
      "  αF=0.1: ω_max=0.2148, ω_avg=0.1117, Tiers={'Optimum': 1, 'Acceptable': 2, 'Questionable': 0, 'Unacceptable': 3}\n",
      "  αF=0.15: ω_max=0.2148, ω_avg=0.1117, Tiers={'Optimum': 2, 'Acceptable': 1, 'Questionable': 0, 'Unacceptable': 3}\n",
      "  αF=0.2: ω_max=0.2148, ω_avg=0.1117, Tiers={'Optimum': 3, 'Acceptable': 0, 'Questionable': 2, 'Unacceptable': 1}\n",
      "\n",
      "============================================================\n",
      "ANALYZING METRIC: TPR\n",
      "============================================================\n",
      "  Saved benchmarking tiers plot for alphaF=0.05 (tpr)\n",
      "  Saved benchmarking tiers plot for alphaF=0.1 (tpr)\n",
      "  Saved benchmarking tiers plot for alphaF=0.15 (tpr)\n",
      "  Saved benchmarking tiers plot for alphaF=0.2 (tpr)\n",
      "Summary for tpr:\n",
      "  αF=0.05: ω_max=0.0967, ω_avg=0.0548, Tiers={'Optimum': 1, 'Acceptable': 0, 'Questionable': 3, 'Unacceptable': 2}\n",
      "  αF=0.1: ω_max=0.0967, ω_avg=0.0548, Tiers={'Optimum': 1, 'Acceptable': 3, 'Questionable': 2, 'Unacceptable': 0}\n",
      "  αF=0.15: ω_max=0.0967, ω_avg=0.0548, Tiers={'Optimum': 1, 'Acceptable': 3, 'Questionable': 2, 'Unacceptable': 0}\n",
      "  αF=0.2: ω_max=0.0967, ω_avg=0.0548, Tiers={'Optimum': 4, 'Acceptable': 2, 'Questionable': 0, 'Unacceptable': 0}\n",
      "\n",
      "============================================================\n",
      "ANALYZING METRIC: TNR\n",
      "============================================================\n",
      "  Saved benchmarking tiers plot for alphaF=0.05 (tnr)\n",
      "  Saved benchmarking tiers plot for alphaF=0.1 (tnr)\n",
      "  Saved benchmarking tiers plot for alphaF=0.15 (tnr)\n",
      "  Saved benchmarking tiers plot for alphaF=0.2 (tnr)\n",
      "Summary for tnr:\n",
      "  αF=0.05: ω_max=0.0888, ω_avg=0.0457, Tiers={'Optimum': 1, 'Acceptable': 2, 'Questionable': 0, 'Unacceptable': 3}\n",
      "  αF=0.1: ω_max=0.0888, ω_avg=0.0457, Tiers={'Optimum': 3, 'Acceptable': 0, 'Questionable': 3, 'Unacceptable': 0}\n",
      "  αF=0.15: ω_max=0.0888, ω_avg=0.0457, Tiers={'Optimum': 3, 'Acceptable': 1, 'Questionable': 2, 'Unacceptable': 0}\n",
      "  αF=0.2: ω_max=0.0888, ω_avg=0.0457, Tiers={'Optimum': 3, 'Acceptable': 3, 'Questionable': 0, 'Unacceptable': 0}\n",
      "\n",
      "============================================================\n",
      "ANALYZING METRIC: FPR\n",
      "============================================================\n",
      "  Saved benchmarking tiers plot for alphaF=0.05 (fpr)\n",
      "  Saved benchmarking tiers plot for alphaF=0.1 (fpr)\n",
      "  Saved benchmarking tiers plot for alphaF=0.15 (fpr)\n",
      "  Saved benchmarking tiers plot for alphaF=0.2 (fpr)\n",
      "Summary for fpr:\n",
      "  αF=0.05: ω_max=0.0888, ω_avg=0.0457, Tiers={'Optimum': 1, 'Acceptable': 2, 'Questionable': 0, 'Unacceptable': 3}\n",
      "  αF=0.1: ω_max=0.0888, ω_avg=0.0457, Tiers={'Optimum': 3, 'Acceptable': 0, 'Questionable': 3, 'Unacceptable': 0}\n",
      "  αF=0.15: ω_max=0.0888, ω_avg=0.0457, Tiers={'Optimum': 3, 'Acceptable': 1, 'Questionable': 2, 'Unacceptable': 0}\n",
      "  αF=0.2: ω_max=0.0888, ω_avg=0.0457, Tiers={'Optimum': 3, 'Acceptable': 3, 'Questionable': 0, 'Unacceptable': 0}\n",
      "\n",
      "============================================================\n",
      "ANALYZING METRIC: FNR\n",
      "============================================================\n",
      "  Saved benchmarking tiers plot for alphaF=0.05 (fnr)\n",
      "  Saved benchmarking tiers plot for alphaF=0.1 (fnr)\n",
      "  Saved benchmarking tiers plot for alphaF=0.15 (fnr)\n",
      "  Saved benchmarking tiers plot for alphaF=0.2 (fnr)\n",
      "Summary for fnr:\n",
      "  αF=0.05: ω_max=0.0967, ω_avg=0.0548, Tiers={'Optimum': 1, 'Acceptable': 0, 'Questionable': 3, 'Unacceptable': 2}\n",
      "  αF=0.1: ω_max=0.0967, ω_avg=0.0548, Tiers={'Optimum': 1, 'Acceptable': 3, 'Questionable': 2, 'Unacceptable': 0}\n",
      "  αF=0.15: ω_max=0.0967, ω_avg=0.0548, Tiers={'Optimum': 1, 'Acceptable': 3, 'Questionable': 2, 'Unacceptable': 0}\n",
      "  αF=0.2: ω_max=0.0967, ω_avg=0.0548, Tiers={'Optimum': 4, 'Acceptable': 2, 'Questionable': 0, 'Unacceptable': 0}\n",
      "\n",
      "============================================================\n",
      "ANALYZING METRIC: PPV\n",
      "============================================================\n",
      "  Saved benchmarking tiers plot for alphaF=0.05 (ppv)\n",
      "  Saved benchmarking tiers plot for alphaF=0.1 (ppv)\n",
      "  Saved benchmarking tiers plot for alphaF=0.15 (ppv)\n",
      "  Saved benchmarking tiers plot for alphaF=0.2 (ppv)\n",
      "Summary for ppv:\n",
      "  αF=0.05: ω_max=0.2781, ω_avg=0.1435, Tiers={'Optimum': 0, 'Acceptable': 0, 'Questionable': 1, 'Unacceptable': 5}\n",
      "  αF=0.1: ω_max=0.2781, ω_avg=0.1435, Tiers={'Optimum': 0, 'Acceptable': 1, 'Questionable': 0, 'Unacceptable': 5}\n",
      "  αF=0.15: ω_max=0.2781, ω_avg=0.1435, Tiers={'Optimum': 1, 'Acceptable': 0, 'Questionable': 3, 'Unacceptable': 2}\n",
      "  αF=0.2: ω_max=0.2781, ω_avg=0.1435, Tiers={'Optimum': 1, 'Acceptable': 0, 'Questionable': 4, 'Unacceptable': 1}\n",
      "\n",
      "============================================================\n",
      "ANALYZING METRIC: NPV\n",
      "============================================================\n",
      "  Saved benchmarking tiers plot for alphaF=0.05 (npv)\n",
      "  Saved benchmarking tiers plot for alphaF=0.1 (npv)\n",
      "  Saved benchmarking tiers plot for alphaF=0.15 (npv)\n",
      "  Saved benchmarking tiers plot for alphaF=0.2 (npv)\n",
      "Summary for npv:\n",
      "  αF=0.05: ω_max=0.2649, ω_avg=0.1371, Tiers={'Optimum': 0, 'Acceptable': 0, 'Questionable': 1, 'Unacceptable': 5}\n",
      "  αF=0.1: ω_max=0.2649, ω_avg=0.1371, Tiers={'Optimum': 0, 'Acceptable': 1, 'Questionable': 2, 'Unacceptable': 3}\n",
      "  αF=0.15: ω_max=0.2649, ω_avg=0.1371, Tiers={'Optimum': 1, 'Acceptable': 1, 'Questionable': 1, 'Unacceptable': 3}\n",
      "  αF=0.2: ω_max=0.2649, ω_avg=0.1371, Tiers={'Optimum': 1, 'Acceptable': 2, 'Questionable': 1, 'Unacceptable': 2}\n",
      "\n",
      "============================================================\n",
      "ANALYZING METRIC: F1\n",
      "============================================================\n",
      "  Saved benchmarking tiers plot for alphaF=0.05 (f1)\n",
      "  Saved benchmarking tiers plot for alphaF=0.1 (f1)\n",
      "  Saved benchmarking tiers plot for alphaF=0.15 (f1)\n",
      "  Saved benchmarking tiers plot for alphaF=0.2 (f1)\n",
      "Summary for f1:\n",
      "  αF=0.05: ω_max=0.1443, ω_avg=0.0747, Tiers={'Optimum': 0, 'Acceptable': 1, 'Questionable': 2, 'Unacceptable': 3}\n",
      "  αF=0.1: ω_max=0.1443, ω_avg=0.0747, Tiers={'Optimum': 1, 'Acceptable': 2, 'Questionable': 1, 'Unacceptable': 2}\n",
      "  αF=0.15: ω_max=0.1443, ω_avg=0.0747, Tiers={'Optimum': 2, 'Acceptable': 1, 'Questionable': 3, 'Unacceptable': 0}\n",
      "  αF=0.2: ω_max=0.1443, ω_avg=0.0747, Tiers={'Optimum': 3, 'Acceptable': 1, 'Questionable': 2, 'Unacceptable': 0}\n",
      "\n",
      "============================================================\n",
      "ANALYZING METRIC: AUC\n",
      "============================================================\n",
      "  Saved benchmarking tiers plot for alphaF=0.05 (auc)\n",
      "  Saved benchmarking tiers plot for alphaF=0.1 (auc)\n",
      "  Saved benchmarking tiers plot for alphaF=0.15 (auc)\n",
      "  Saved benchmarking tiers plot for alphaF=0.2 (auc)\n",
      "Summary for auc:\n",
      "  αF=0.05: ω_max=0.1010, ω_avg=0.0544, Tiers={'Optimum': 1, 'Acceptable': 1, 'Questionable': 1, 'Unacceptable': 3}\n",
      "  αF=0.1: ω_max=0.1010, ω_avg=0.0544, Tiers={'Optimum': 2, 'Acceptable': 1, 'Questionable': 2, 'Unacceptable': 1}\n",
      "  αF=0.15: ω_max=0.1010, ω_avg=0.0544, Tiers={'Optimum': 3, 'Acceptable': 1, 'Questionable': 2, 'Unacceptable': 0}\n",
      "  αF=0.2: ω_max=0.1010, ω_avg=0.0544, Tiers={'Optimum': 3, 'Acceptable': 2, 'Questionable': 1, 'Unacceptable': 0}\n",
      "\n",
      "FIC ANALYSIS TABLE (Accuracy):\n",
      "                   Group Pair              alphaF=0.05   Hypothesis alphaF=0.05               alphaF=0.1    Hypothesis alphaF=0.1              alphaF=0.15   Hypothesis alphaF=0.15              alphaF=0.2    Hypothesis alphaF=0.2\n",
      " African_American - Caucasian omega=0.0984, FIC=-0.967       Reject H₀ (Unfair)  omega=0.0984, FIC=0.016 Fail to reject Ho (Fair)  omega=0.0984, FIC=0.344 Fail to reject Ho (Fair) omega=0.0984, FIC=0.508 Fail to reject Ho (Fair)\n",
      "  African_American - Hispanic omega=0.1312, FIC=-1.625       Reject H₀ (Unfair) omega=0.1312, FIC=-0.312       Reject H₀ (Unfair)  omega=0.1312, FIC=0.125 Fail to reject Ho (Fair) omega=0.1312, FIC=0.344 Fail to reject Ho (Fair)\n",
      "African_American - Other_Race omega=0.1654, FIC=-2.308       Reject H₀ (Unfair) omega=0.1654, FIC=-0.654       Reject H₀ (Unfair) omega=0.1654, FIC=-0.103       Reject H₀ (Unfair) omega=0.1654, FIC=0.173 Fail to reject Ho (Fair)\n",
      "         Caucasian - Hispanic  omega=0.0329, FIC=0.343 Fail to reject Ho (Fair)  omega=0.0329, FIC=0.671 Fail to reject Ho (Fair)  omega=0.0329, FIC=0.781 Fail to reject Ho (Fair) omega=0.0329, FIC=0.836 Fail to reject Ho (Fair)\n",
      "       Caucasian - Other_Race omega=0.0670, FIC=-0.341       Reject H₀ (Unfair)  omega=0.0670, FIC=0.330 Fail to reject Ho (Fair)  omega=0.0670, FIC=0.553 Fail to reject Ho (Fair) omega=0.0670, FIC=0.665 Fail to reject Ho (Fair)\n",
      "        Hispanic - Other_Race  omega=0.0342, FIC=0.317 Fail to reject Ho (Fair)  omega=0.0342, FIC=0.658 Fail to reject Ho (Fair)  omega=0.0342, FIC=0.772 Fail to reject Ho (Fair) omega=0.0342, FIC=0.829 Fail to reject Ho (Fair)\n",
      "\n",
      "TIER CLASSIFICATION (Accuracy):\n",
      "\n",
      "For αF = 0.05:\n",
      "--------------------------------------------------\n",
      "African_American - Caucasian: ω=0.0984, FIC=-0.967 → Unacceptable\n",
      "African_American - Hispanic: ω=0.1312, FIC=-1.625 → Unacceptable\n",
      "African_American - Other_Race: ω=0.1654, FIC=-2.308 → Unacceptable\n",
      "Caucasian - Hispanic: ω=0.0329, FIC=0.343 → Questionable\n",
      "Caucasian - Other_Race: ω=0.0670, FIC=-0.341 → Unacceptable\n",
      "Hispanic - Other_Race: ω=0.0342, FIC=0.317 → Questionable\n",
      "\n",
      "For αF = 0.1:\n",
      "--------------------------------------------------\n",
      "African_American - Caucasian: ω=0.0984, FIC=0.016 → Questionable\n",
      "African_American - Hispanic: ω=0.1312, FIC=-0.312 → Unacceptable\n",
      "African_American - Other_Race: ω=0.1654, FIC=-0.654 → Unacceptable\n",
      "Caucasian - Hispanic: ω=0.0329, FIC=0.671 → Acceptable\n",
      "Caucasian - Other_Race: ω=0.0670, FIC=0.330 → Questionable\n",
      "Hispanic - Other_Race: ω=0.0342, FIC=0.658 → Acceptable\n",
      "\n",
      "For αF = 0.15:\n",
      "--------------------------------------------------\n",
      "African_American - Caucasian: ω=0.0984, FIC=0.344 → Questionable\n",
      "African_American - Hispanic: ω=0.1312, FIC=0.125 → Questionable\n",
      "African_American - Other_Race: ω=0.1654, FIC=-0.103 → Unacceptable\n",
      "Caucasian - Hispanic: ω=0.0329, FIC=0.781 → Optimum (omega_max < 0.0375)\n",
      "Caucasian - Other_Race: ω=0.0670, FIC=0.553 → Acceptable\n",
      "Hispanic - Other_Race: ω=0.0342, FIC=0.772 → Optimum (omega_max < 0.0375)\n",
      "\n",
      "For αF = 0.2:\n",
      "--------------------------------------------------\n",
      "African_American - Caucasian: ω=0.0984, FIC=0.508 → Acceptable\n",
      "African_American - Hispanic: ω=0.1312, FIC=0.344 → Questionable\n",
      "African_American - Other_Race: ω=0.1654, FIC=0.173 → Questionable\n",
      "Caucasian - Hispanic: ω=0.0329, FIC=0.836 → Optimum (omega_max < 0.0500)\n",
      "Caucasian - Other_Race: ω=0.0670, FIC=0.665 → Acceptable\n",
      "Hispanic - Other_Race: ω=0.0342, FIC=0.829 → Optimum (omega_max < 0.0500)\n",
      "\n",
      "MODEL COMPARISON:\n",
      "   Model Overall Accuracy Avg FIC alphaF=0.10) ω_max (alphaF=0.10)\n",
      "BASELINE           0.7547                0.118              0.1654\n",
      "      L1           0.7547                0.118              0.1654\n",
      "      L2           0.7547                0.118              0.1654\n",
      "\n",
      "================================================================================\n",
      "SUMMARY REPORT - COMPAS DATASET\n",
      "================================================================================\n",
      "COMPAS DATASET KEY FINDINGS:\n",
      "------------------------------------------------------------\n",
      "Total samples: 7214\n",
      "High risk proportion: 0.365\n",
      "\n",
      "Race group distribution:\n",
      "  African_American: 3696 (0.512)\n",
      "  Caucasian: 2454 (0.340)\n",
      "  Hispanic: 637 (0.088)\n",
      "  Other_Race: 427 (0.059)\n",
      "\n",
      "High risk by race group:\n",
      "  African_American: 0.489\n",
      "  Caucasian: 0.250\n",
      "  Hispanic: 0.217\n",
      "  Other_Race: 0.178\n",
      "\n",
      "FIC ANALYSIS SUMMARY (Accuracy):\n",
      "------------------------------------------------------------\n",
      "alphaF=0.05:\n",
      "  omega range: [0.0329, 0.1654], avg: 0.0882\n",
      "  Most unfair pair: African_American - Other_Race (ω=0.1654)\n",
      "  Most fair pair: Caucasian - Hispanic (ω=0.0329)\n",
      "  Tier distribution: {'Optimum': 0, 'Acceptable': 0, 'Questionable': 2, 'Unacceptable': 4}\n",
      "alphaF=0.1:\n",
      "  omega range: [0.0329, 0.1654], avg: 0.0882\n",
      "  Most unfair pair: African_American - Other_Race (ω=0.1654)\n",
      "  Most fair pair: Caucasian - Hispanic (ω=0.0329)\n",
      "  Tier distribution: {'Optimum': 0, 'Acceptable': 2, 'Questionable': 2, 'Unacceptable': 2}\n",
      "alphaF=0.15:\n",
      "  omega range: [0.0329, 0.1654], avg: 0.0882\n",
      "  Most unfair pair: African_American - Other_Race (ω=0.1654)\n",
      "  Most fair pair: Caucasian - Hispanic (ω=0.0329)\n",
      "  Tier distribution: {'Optimum': 2, 'Acceptable': 1, 'Questionable': 2, 'Unacceptable': 1}\n",
      "alphaF=0.2:\n",
      "  omega range: [0.0329, 0.1654], avg: 0.0882\n",
      "  Most unfair pair: African_American - Other_Race (ω=0.1654)\n",
      "  Most fair pair: Caucasian - Hispanic (ω=0.0329)\n",
      "  Tier distribution: {'Optimum': 2, 'Acceptable': 2, 'Questionable': 2, 'Unacceptable': 0}\n",
      "\n",
      "================================================================================\n",
      "ANALYSIS COMPLETE - HIGH-QUALITY PLOTS SAVED\n",
      "================================================================================\n",
      "Generated plots for all metrics: accuracy, selection_rate, tpr, tnr, fpr, fnr, ppv, npv, f1, auc\n",
      "Each metric has:\n",
      "  - 1 heatmap figure (2x2 grid for all alphaF values)\n",
      "  - 4 benchmarking tier plots (one for each alphaF: 0.05, 0.10, 0.15, 0.20)\n",
      "\n",
      "All plots saved in both PNG and PDF formats.\n",
      "PNG files saved in: compas_fic_results_NLEGEND_ALL_METRICS_PDF/\n",
      "PDF files saved in: compas_fic_results_NLEGEND_ALL_METRICS_PDF\\PDF_plots/\n",
      "\n",
      "All analysis completed!\n",
      "Results saved to: compas_fic_results_NLEGEND_ALL_METRICS_PDF/\n",
      "PDF files saved to: compas_fic_results_NLEGEND_ALL_METRICS_PDF\\PDF_plots/\n",
      "\n",
      "Files include:\n",
      "  - Group metrics (CSV)\n",
      "  - FIC analysis tables for accuracy (CSV)\n",
      "  - Tier classification for accuracy (CSV)\n",
      "  - Model comparison (CSV)\n",
      "  - FIC heatmaps for ALL 10 metrics (PNG + PDF)\n",
      "  - Benchmarking tiers for ALL 10 metrics (4 plots per metric = 40 PNG + 40 PDF files)\n",
      "Total plots generated: 50 PNG files + 50 PDF files = 100 total files\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create output directory\n",
    "output_dir = \"compas_fic_results_NLEGEND_ALL_METRICS_PDF\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Also create PDF subdirectory\n",
    "pdf_dir = os.path.join(output_dir, \"PDF_plots\")\n",
    "os.makedirs(pdf_dir, exist_ok=True)\n",
    "\n",
    "# Set style for publication quality\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Global font settings for consistency\n",
    "plt.rcParams.update({\n",
    "    'font.size': 12,\n",
    "    'axes.titlesize': 16,\n",
    "    'axes.labelsize': 14,\n",
    "    'xtick.labelsize': 12,\n",
    "    'ytick.labelsize': 12,\n",
    "    'legend.fontsize': 12,\n",
    "})\n",
    "\n",
    "# ============================================\n",
    "# 1. LOAD AND PREPROCESS COMPAS DATASET\n",
    "# ============================================\n",
    "\n",
    "def load_compas_data():\n",
    "    \"\"\"\n",
    "    Load and preprocess COMPAS ProPublica dataset from local folder\n",
    "    \"\"\"\n",
    "    # Define your specific folder path\n",
    "    data_folder = r'C:\\Users\\Dr. Akin\\OneDrive\\2025\\Paper_2025\\PHD_Work'\n",
    "    data_file = \"compas-scores-two-years.csv\"\n",
    "    data_path = os.path.join(data_folder, data_file)\n",
    "    \n",
    "    print(f\"Looking for COMPAS dataset at: {data_path}\")\n",
    "    \n",
    "    # Try to load from your specified folder\n",
    "    compas_df = pd.read_csv(data_path)\n",
    "    print(\"Loaded COMPAS dataset from specified folder\")\n",
    "   \n",
    "    \n",
    "    # Filter relevant columns\n",
    "    relevant_columns = [\n",
    "        'age', 'sex', 'race', 'priors_count', 'c_charge_degree',\n",
    "        'juv_fel_count', 'juv_misd_count', 'juv_other_count',\n",
    "        'decile_score', 'two_year_recid'\n",
    "    ]\n",
    "    \n",
    "    # Check which columns exist in the dataset\n",
    "    available_columns = [col for col in relevant_columns if col in compas_df.columns]\n",
    "    compas_df = compas_df[available_columns].copy()\n",
    "    \n",
    "    # Drop rows with missing values\n",
    "    compas_df = compas_df.dropna()\n",
    "    \n",
    "    # Create high_risk target: 0-5 as low risk, 6-10 as high risk\n",
    "    compas_df['high_risk'] = (compas_df['decile_score'] >= 6).astype(int)\n",
    "    \n",
    "    # Consolidate race categories\n",
    "    def consolidate_race(race):\n",
    "        race = str(race).strip().lower()\n",
    "        if 'african' in race or 'black' in race:\n",
    "            return 'African_American'\n",
    "        elif 'caucasian' in race or 'white' in race:\n",
    "            return 'Caucasian'\n",
    "        elif 'hispanic' in race or 'latino' in race:\n",
    "            return 'Hispanic'\n",
    "        elif 'asian' in race or 'arab' in race or 'native' in race or 'other' in race:\n",
    "            return 'Other_Race'\n",
    "        else:\n",
    "            return 'Other_Race'\n",
    "    \n",
    "    compas_df['race_group'] = compas_df['race'].apply(consolidate_race)\n",
    "    \n",
    "    # Filter to keep only our target race groups\n",
    "    target_races = ['African_American', 'Caucasian', 'Hispanic', 'Other_Race']\n",
    "    compas_df = compas_df[compas_df['race_group'].isin(target_races)].copy()\n",
    "    \n",
    "    # Create additional features for better prediction\n",
    "    compas_df['total_juvenile_charges'] = compas_df['juv_fel_count'] + compas_df['juv_misd_count'] + compas_df['juv_other_count']\n",
    "    compas_df['is_felony'] = (compas_df['c_charge_degree'] == 'F').astype(int)\n",
    "    compas_df['age_group'] = pd.cut(compas_df['age'], \n",
    "                                     bins=[0, 25, 35, 45, 55, 100],\n",
    "                                     labels=['18-25', '26-35', '36-45', '46-55', '56+'])\n",
    "    \n",
    "    # Select final columns for analysis\n",
    "    final_columns = [\n",
    "        'age', 'sex', 'race_group', 'priors_count', 'is_felony',\n",
    "        'total_juvenile_charges', 'age_group', 'high_risk'\n",
    "    ]\n",
    "    \n",
    "    # Ensure all columns exist\n",
    "    final_columns = [col for col in final_columns if col in compas_df.columns]\n",
    "    compas_df = compas_df[final_columns]\n",
    "    \n",
    "    print(f\"Processed dataset shape: {compas_df.shape}\")\n",
    "    print(f\"Target distribution (high_risk):\")\n",
    "    print(compas_df['high_risk'].value_counts(normalize=True))\n",
    "    print(f\"\\nRace group distribution:\")\n",
    "    print(compas_df['race_group'].value_counts(normalize=True))\n",
    "    \n",
    "    return compas_df\n",
    "\n",
    "def generate_compas_data(n_samples=None):\n",
    "    \"\"\"\n",
    "    Wrapper function to load COMPAS data\n",
    "    n_samples parameter is kept for compatibility but not used\n",
    "    \"\"\"\n",
    "    data = load_compas_data()\n",
    "    \n",
    "    # If n_samples is specified and smaller than dataset, sample it\n",
    "    if n_samples and n_samples < len(data):\n",
    "        data = data.sample(n=n_samples, random_state=42)\n",
    "    \n",
    "    return data\n",
    "\n",
    "# ============================================\n",
    "# 2-3. MODEL & FIC\n",
    "# ============================================\n",
    "\n",
    "def compute_all_metrics(y_true, y_pred, y_prob):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_true, y_pred),\n",
    "        'selection_rate': (tp + fp) / len(y_true),\n",
    "        'tpr': tp / (tp + fn) if (tp + fn) > 0 else 0,\n",
    "        'tnr': tn / (tn + fp) if (tn + fp) > 0 else 0,\n",
    "        'fpr': fp / (fp + tn) if (fp + tn) > 0 else 0,\n",
    "        'fnr': fn / (tp + fn) if (tp + fn) > 0 else 0,\n",
    "        'ppv': tp / (tp + fp) if (tp + fp) > 0 else 0,\n",
    "        'npv': tn / (tn + fn) if (tn + fn) > 0 else 0,\n",
    "        'f1': f1_score(y_true, y_pred),\n",
    "        'auc': roc_auc_score(y_true, y_prob) if len(np.unique(y_true)) > 1 else np.nan\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "def train_and_evaluate_models(data, target_col, protected_col, model_type='baseline'):\n",
    "    X = data.drop(columns=[target_col, protected_col])\n",
    "    y = data[target_col]\n",
    "    categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "    numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(drop='first'), categorical_cols)\n",
    "    ])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "    protected_test = data.loc[X_test.index, protected_col]\n",
    "\n",
    "    X_train_processed = preprocessor.fit_transform(X_train)\n",
    "    X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "    if model_type == 'baseline':\n",
    "        model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "    elif model_type == 'l1':\n",
    "        model = LogisticRegression(penalty='l1', solver='liblinear', random_state=42, max_iter=1000, C=1.0)\n",
    "    elif model_type == 'l2':\n",
    "        model = LogisticRegression(penalty='l2', random_state=42, max_iter=1000, C=1.0)\n",
    "    else:\n",
    "        model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "    model.fit(X_train_processed, y_train)\n",
    "    y_pred = model.predict(X_test_processed)\n",
    "    y_prob = model.predict_proba(X_test_processed)[:, 1]\n",
    "\n",
    "    group_metrics = {}\n",
    "    for group in protected_test.unique():\n",
    "        mask = protected_test == group\n",
    "        if mask.sum() > 0:\n",
    "            group_metrics[group] = compute_all_metrics(y_test[mask], y_pred[mask], y_prob[mask])\n",
    "\n",
    "    return group_metrics, (X_test, y_test, protected_test, y_pred, y_prob)\n",
    "\n",
    "class FairnessInformationCriterion:\n",
    "    def __init__(self, alphaF_values=[0.05, 0.10, 0.15, 0.20]):\n",
    "        self.alphaF_values = alphaF_values\n",
    "\n",
    "    def compute_omega(self, metric1, metric2):\n",
    "        return abs(metric1 - metric2)\n",
    "\n",
    "    def compute_fic(self, omega, alphaF):\n",
    "        return 1 - (omega / alphaF)\n",
    "\n",
    "    def classify_tier(self, fic_score):\n",
    "        if fic_score > 0.75:\n",
    "            return \"Optimum\"\n",
    "        elif fic_score > 0.50:\n",
    "            return \"Acceptable\"\n",
    "        elif fic_score > 0:\n",
    "            return \"Questionable\"\n",
    "        else:\n",
    "            return \"Unacceptable\"\n",
    "\n",
    "    def analyze_fairness(self, group_metrics, metric_name='accuracy'):\n",
    "        results = {}\n",
    "        groups = list(group_metrics.keys())\n",
    "        for alphaF in self.alphaF_values:\n",
    "            results[alphaF] = {}\n",
    "            for i, g1 in enumerate(groups):\n",
    "                for g2 in groups[i+1:]:\n",
    "                    pair = f\"{g1} - {g2}\"\n",
    "                    m1 = group_metrics[g1].get(metric_name, np.nan)\n",
    "                    m2 = group_metrics[g2].get(metric_name, np.nan)\n",
    "                    if not np.isnan(m1) and not np.isnan(m2):\n",
    "                        omega = self.compute_omega(m1, m2)\n",
    "                        fic_score = self.compute_fic(omega, alphaF)\n",
    "                        tier = self.classify_tier(fic_score)\n",
    "                        results[alphaF][pair] = {\n",
    "                            'omega': omega, 'fic_score': fic_score, 'tier': tier,\n",
    "                            'metric1': m1, 'metric2': m2\n",
    "                        }\n",
    "        return results\n",
    "\n",
    "# ============================================\n",
    "# 4. VISUALIZATIONS - UPDATED FOR PDF AND EXPANDED LEGEND\n",
    "# ============================================\n",
    "\n",
    "def plot_fic_heatmaps(fic_results, dataset_name, metric='accuracy'):\n",
    "    alphaF_values = sorted(fic_results.keys())\n",
    "    if not alphaF_values:\n",
    "        return\n",
    "\n",
    "    pairs = list(fic_results[alphaF_values[0]].keys())\n",
    "    all_groups = sorted(set(g for p in pairs for g in p.split(' - ')))\n",
    "\n",
    "    # Larger figure\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(20, 16))\n",
    "    fig.suptitle(f'FIC Heatmaps for Different alphaF Values ({metric})',\n",
    "                 fontsize=20, fontweight='bold', y=0.98)\n",
    "\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for idx, alphaF in enumerate(alphaF_values):\n",
    "        ax = axes[idx]\n",
    "        n = len(all_groups)\n",
    "        mat = np.full((n, n), np.nan)\n",
    "        group_idx = {g: i for i, g in enumerate(all_groups)}\n",
    "\n",
    "        for pair, d in fic_results[alphaF].items():\n",
    "            g1, g2 = pair.split(' - ')\n",
    "            i, j = group_idx[g1], group_idx[g2]\n",
    "            mat[i, j] = mat[j, i] = d['fic_score']\n",
    "\n",
    "        im = ax.imshow(mat, cmap='RdYlGn', vmin=-1, vmax=1, aspect='equal')\n",
    "\n",
    "        # Add value labels inside cells\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                if i != j and not np.isnan(mat[i, j]):\n",
    "                    text = ax.text(j, i, f'{mat[i,j]:.2f}',\n",
    "                                   ha='center', va='center',\n",
    "                                   fontsize=14, fontweight='bold',\n",
    "                                   color='white' if abs(mat[i,j]) > 0.5 else 'black')\n",
    "\n",
    "        ax.set_xticks(range(n))\n",
    "        ax.set_yticks(range(n))\n",
    "        ax.set_xticklabels(all_groups, rotation=45, ha='right', fontsize=13, fontweight='bold')\n",
    "        ax.set_yticklabels(all_groups, fontsize=13, fontweight='bold')\n",
    "        ax.set_title(f'αF = {alphaF}', fontsize=18, fontweight='bold', pad=20)\n",
    "        \n",
    "        # Add grid\n",
    "        ax.set_xticks(np.arange(-.5, n, 1), minor=True)\n",
    "        ax.set_yticks(np.arange(-.5, n, 1), minor=True)\n",
    "        ax.grid(which='minor', color='gray', linestyle='-', linewidth=0.5, alpha=0.3)\n",
    "\n",
    "    # Add a single comprehensive colorbar with tier labels\n",
    "    cbar_ax = fig.add_axes([0.78, 0.15, 0.02, 0.7])  # [left, bottom, width, height]\n",
    "    cbar = fig.colorbar(im, cax=cbar_ax)\n",
    "    cbar.set_label('FIC Score', fontsize=14, fontweight='bold', labelpad=15)\n",
    "    cbar.ax.tick_params(labelsize=12)\n",
    "    \n",
    "    # Bold the colorbar tick labels\n",
    "    for label in cbar.ax.get_yticklabels():\n",
    "        label.set_fontweight('bold')\n",
    "    \n",
    "    # Add tier annotations on the colorbar with more space\n",
    "    cbar.ax.text(1.6, 0.90, 'Optimum', transform=cbar.ax.transAxes, \n",
    "                 fontsize=14, fontweight='bold', va='center', ha='left', color='darkgreen')\n",
    "    cbar.ax.text(1.6, 0.60, 'Acceptable', transform=cbar.ax.transAxes, \n",
    "                 fontsize=14, fontweight='bold', va='center', ha='left', color='goldenrod')\n",
    "    cbar.ax.text(1.6, 0.350, 'Questionable', transform=cbar.ax.transAxes, \n",
    "                 fontsize=14, fontweight='bold', va='center', ha='left', color='darkorange')\n",
    "    cbar.ax.text(1.6, 0.100, 'Unacceptable', transform=cbar.ax.transAxes, \n",
    "                 fontsize=14, fontweight='bold', va='center', ha='left', color='darkred')\n",
    "    \n",
    "    # Add tier threshold lines on colorbar\n",
    "    cbar.ax.axhline(0.75, color='darkgreen', linestyle='--', linewidth=3, xmax=0.6)\n",
    "    cbar.ax.axhline(0.50, color='goldenrod', linestyle='--', linewidth=3, xmax=0.6)\n",
    "    cbar.ax.axhline(0.00, color='darkred', linestyle='--', linewidth=3, xmax=0.6)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 0.78, 0.95])\n",
    "    \n",
    "    # Save as PNG\n",
    "    plt.savefig(os.path.join(output_dir, f'{dataset_name}_FIC_Heatmaps_{metric}.png'), \n",
    "                dpi=400, bbox_inches='tight')\n",
    "    # Save as PDF\n",
    "    plt.savefig(os.path.join(pdf_dir, f'{dataset_name}_FIC_Heatmaps_{metric}.pdf'), \n",
    "                format='pdf', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_benchmarking_tiers(fic_results, dataset_name, metric='accuracy'):\n",
    "    # Sort alphaF values to ensure consistent order\n",
    "    alphaF_values = sorted(fic_results.keys())\n",
    "    \n",
    "    # Define colors for tiers\n",
    "    colors = {'Optimum': '#2E8B57', 'Acceptable': '#FFD700', \n",
    "              'Questionable': '#FF8C00', 'Unacceptable': '#DC143C'}\n",
    "    \n",
    "    for alphaF in alphaF_values:\n",
    "        if alphaF not in fic_results or not fic_results[alphaF]:\n",
    "            print(f\"No data for alphaF={alphaF} in benchmarking tiers\")\n",
    "            continue\n",
    "        \n",
    "        # Create a figure with EXPANDED width to prevent legend cutoff\n",
    "        fig, ax = plt.subplots(figsize=(20, 8))  # Increased width from 16 to 20\n",
    "        \n",
    "        data = fic_results[alphaF]\n",
    "        pairs = list(data.keys())\n",
    "        fic_scores = [data[p]['fic_score'] for p in pairs]\n",
    "        tiers = [data[p]['tier'] for p in pairs]\n",
    "        \n",
    "        # Find max positive and max negative values\n",
    "        max_positive = max(fic_scores) if fic_scores else 1.0\n",
    "        min_negative = min(fic_scores) if fic_scores else -0.25\n",
    "        \n",
    "        # Add padding (10% on positive side, 10% on negative side)\n",
    "        y_max = max_positive * 1.10 if max_positive > 0 else 0.10\n",
    "        y_min = min_negative * 1.10 if min_negative < 0 else -0.10\n",
    "        \n",
    "        # Ensure at least some range for visualization\n",
    "        if y_max - y_min < 0.5:\n",
    "            # If range is too small, center it around the data\n",
    "            center = (max_positive + min_negative) / 2\n",
    "            y_max = center + 0.25\n",
    "            y_min = center - 0.25\n",
    "        \n",
    "        # Create bar colors based on tiers\n",
    "        bar_colors = [colors[t] for t in tiers]\n",
    "        \n",
    "        # Create bars with smaller width for more compact look\n",
    "        bars = ax.bar(range(len(pairs)), fic_scores, color=bar_colors, \n",
    "                      edgecolor='black', linewidth=1.2, width=0.6)\n",
    "        \n",
    "        # Add tier threshold lines with better styling\n",
    "        ax.axhline(0.75, color='darkgreen', linestyle='--', linewidth=2.0, \n",
    "                   alpha=0.7)\n",
    "        ax.axhline(0.50, color='goldenrod', linestyle='--', linewidth=2.0, \n",
    "                   alpha=0.7)\n",
    "        ax.axhline(0.00, color='darkred', linestyle='--', linewidth=2.0, \n",
    "                   alpha=0.7)\n",
    "        \n",
    "        # Customize axes with better labels\n",
    "        ax.set_xlabel('Inter-Group', fontsize=14, fontweight='bold', labelpad=10)\n",
    "        ax.set_ylabel('FIC Score', fontsize=14, fontweight='bold', labelpad=10)\n",
    "        ax.set_title(f'FIC Benchmarking Tiers ({metric}, αF = {alphaF})',\n",
    "                    fontsize=16, fontweight='bold', pad=15)\n",
    "        \n",
    "        # Set x-ticks with rotation for readability\n",
    "        ax.set_xticks(range(len(pairs)))\n",
    "        ax.set_xticklabels(pairs, rotation=45, ha='right', fontsize=11, fontweight='bold')\n",
    "        \n",
    "        # Set dynamic y-axis limits based on actual max positive and max negative\n",
    "        ax.set_ylim(y_min, y_max)\n",
    "        \n",
    "        # Bold the y-axis tick labels\n",
    "        y_ticks = ax.get_yticks()\n",
    "        ax.set_yticklabels([f'{tick:.2f}' for tick in y_ticks], fontsize=11, fontweight='bold')\n",
    "        \n",
    "        # Add grid with lighter style\n",
    "        ax.grid(True, axis='y', alpha=0.3, linestyle='-', linewidth=0.5)\n",
    "        ax.grid(True, axis='x', alpha=0.1, linestyle='-', linewidth=0.5)\n",
    "        \n",
    "        # Add better legend - moved to top right with fewer items\n",
    "        from matplotlib.patches import Patch\n",
    "        legend_elements = [\n",
    "            Patch(facecolor=colors['Optimum'], edgecolor='black', label='Optimum (FIC > 0.75)'),\n",
    "            Patch(facecolor=colors['Acceptable'], edgecolor='black', label='Acceptable (0.50 < FIC ≤ 0.75)'),\n",
    "            Patch(facecolor=colors['Questionable'], edgecolor='black', label='Questionable (0 < FIC ≤ 0.50)'),\n",
    "            Patch(facecolor=colors['Unacceptable'], edgecolor='black', label='Unacceptable (FIC ≤ 0)')\n",
    "        ]\n",
    "        \n",
    "        \n",
    "        # Create a separate legend for threshold lines\n",
    "        from matplotlib.lines import Line2D\n",
    "        line_legend_elements = [\n",
    "            Line2D([0], [0], color='darkgreen', linestyle='--', linewidth=2, label='Optimum Threshold (0.75)'),\n",
    "            Line2D([0], [0], color='goldenrod', linestyle='--', linewidth=2, label='Acceptable Threshold (0.50)'),\n",
    "            Line2D([0], [0], color='darkred', linestyle='--', linewidth=2, label='Unacceptable Threshold (0.00)')\n",
    "        ]\n",
    "        \n",
    "        # Place tier legend at upper left - MORE SPACE with bbox_to_anchor\n",
    "        tier_legend = ax.legend(handles=legend_elements, fontsize=10, \n",
    "                                loc='upper left', bbox_to_anchor=(1.05, 1.0),\n",
    "                                frameon=True, framealpha=0.9, edgecolor='black',\n",
    "                                title='FIC Tiers', title_fontsize=11)\n",
    "        # Make the legend title bold\n",
    "        tier_legend.get_title().set_fontweight('bold')\n",
    "        ax.add_artist(tier_legend)\n",
    "        \n",
    "        # Place threshold legend at upper left below tier legend - MORE SPACE\n",
    "        threshold_legend = ax.legend(handles=line_legend_elements, fontsize=9, \n",
    "                                     loc='upper left', bbox_to_anchor=(1.05, 0.65),\n",
    "                                     frameon=True, framealpha=0.9, edgecolor='black',\n",
    "                                     title='Thresholds', title_fontsize=10)\n",
    "        # Make the legend title bold\n",
    "        threshold_legend.get_title().set_fontweight('bold')\n",
    "        \n",
    "        # Add annotation for alphaF interpretation\n",
    "        annotation_text = f'αF = {alphaF}\\nFIC = 1 - (ω/αF)\\nω = |$M₁ - M₂$|'\n",
    "        ax.text(0.02, 0.98, annotation_text, transform=ax.transAxes,\n",
    "                fontsize=9, verticalalignment='top', fontweight='bold',\n",
    "                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
    "        \n",
    "        # Adjust layout to make room for legend - MORE SPACE allocated\n",
    "        plt.tight_layout(rect=[0, 0, 0.80, 1])  # Changed from 0.85 to 0.80 for more legend space\n",
    "        \n",
    "        # Save the figure with alphaF in the filename - BOTH PNG AND PDF\n",
    "        png_filename = f'{dataset_name}_Benchmarking_Tiers_alphaF_{alphaF}_{metric}.png'\n",
    "        pdf_filename = f'{dataset_name}_Benchmarking_Tiers_alphaF_{alphaF}_{metric}.pdf'\n",
    "        \n",
    "        plt.savefig(os.path.join(output_dir, png_filename), \n",
    "                    dpi=400, bbox_inches='tight')\n",
    "        plt.savefig(os.path.join(pdf_dir, pdf_filename), \n",
    "                    format='pdf', bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        print(f\"  Saved benchmarking tiers plot for alphaF={alphaF} ({metric})\")\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# 5. ANALYSIS FUNCTIONS - UPDATED FOR ALL METRICS\n",
    "# ============================================\n",
    "\n",
    "def analyze_dataset(dataset_name, data_generator, target_col, protected_col, case_number=1, model_types=['baseline', 'l1', 'l2']):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"CASE {case_number}: {dataset_name}\")\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "    data = data_generator()\n",
    "    fic_framework = FairnessInformationCriterion()\n",
    "\n",
    "    baseline_metrics, _ = train_and_evaluate_models(data, target_col, protected_col, 'baseline')\n",
    "\n",
    "    metrics_df = pd.DataFrame.from_dict(baseline_metrics, orient='index')\n",
    "    metrics_df = metrics_df[['accuracy', 'selection_rate', 'tpr', 'tnr', 'fpr', 'fnr', 'ppv', 'npv', 'f1', 'auc']]\n",
    "    print(\"GROUP METRICS TABLE (Baseline Logistic Regression):\")\n",
    "    print(metrics_df.round(4).to_string())\n",
    "    metrics_df.to_csv(os.path.join(output_dir, f'Case{case_number}_Group_Metrics.csv'))\n",
    "\n",
    "    print(\"\\nGENERATING VISUALIZATIONS FOR ALL METRICS...\")\n",
    "    \n",
    "    # List of all metrics to analyze\n",
    "    all_metrics = ['accuracy', 'selection_rate', 'tpr', 'tnr', 'fpr', 'fnr', 'ppv', 'npv', 'f1', 'auc']\n",
    "    \n",
    "    # Dictionary to store all FIC results\n",
    "    all_fic_results = {}\n",
    "    \n",
    "    for metric in all_metrics:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"ANALYZING METRIC: {metric.upper()}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # Analyze fairness for this metric\n",
    "        fic_results = fic_framework.analyze_fairness(baseline_metrics, metric)\n",
    "        all_fic_results[metric] = fic_results\n",
    "        \n",
    "        # Generate heatmaps for this metric\n",
    "        plot_fic_heatmaps(fic_results, f'Case{case_number}_{dataset_name}_{metric}', metric)\n",
    "        \n",
    "        # Generate benchmarking tiers for this metric\n",
    "        plot_benchmarking_tiers(fic_results, f'Case{case_number}_{dataset_name}_{metric}', metric)\n",
    "        \n",
    "        # Print summary for this metric\n",
    "        print(f\"Summary for {metric}:\")\n",
    "        for af in fic_framework.alphaF_values:\n",
    "            if af in fic_results and fic_results[af]:\n",
    "                omegas = [d['omega'] for d in fic_results[af].values()]\n",
    "                max_o = max(omegas)\n",
    "                avg_o = np.mean(omegas)\n",
    "                fic = FairnessInformationCriterion()\n",
    "                tiers = {'Optimum': 0, 'Acceptable': 0, 'Questionable': 0, 'Unacceptable': 0}\n",
    "                for d in fic_results[af].values():\n",
    "                    tiers[fic.classify_tier(d['fic_score'])] += 1\n",
    "                print(f\"  αF={af}: ω_max={max_o:.4f}, ω_avg={avg_o:.4f}, Tiers={tiers}\")\n",
    "\n",
    "    # Store FIC results for accuracy (original metric) for backward compatibility\n",
    "    fic_results = all_fic_results['accuracy']\n",
    "    \n",
    "    # FIC table for accuracy (original)\n",
    "    fic_table = []\n",
    "    for pair in sorted(set(p for a in fic_results.values() for p in a.keys())):\n",
    "        row = {'Group Pair': pair}\n",
    "        for af in fic_framework.alphaF_values:\n",
    "            if af in fic_results and pair in fic_results[af]:\n",
    "                d = fic_results[af][pair]\n",
    "                row[f'alphaF={af}'] = f\"omega={d['omega']:.4f}, FIC={d['fic_score']:.3f}\"\n",
    "                row[f'Hypothesis alphaF={af}'] = \"Fail to reject Ho (Fair)\" if d['omega'] <= af else \"Reject H₀ (Unfair)\"\n",
    "            else:\n",
    "                row[f'alphaF={af}'] = \"N/A\"; row[f'Hypothesis alphaF={af}'] = \"N/A\"\n",
    "        fic_table.append(row)\n",
    "    fic_df = pd.DataFrame(fic_table)\n",
    "    print(\"\\nFIC ANALYSIS TABLE (Accuracy):\")\n",
    "    print(fic_df.to_string(index=False))\n",
    "    fic_df.to_csv(os.path.join(output_dir, f'Case{case_number}_FIC_Analysis_accuracy.csv'), index=False)\n",
    "\n",
    "    # Tier classification for accuracy (original)\n",
    "    tier_data = []\n",
    "    print(\"\\nTIER CLASSIFICATION (Accuracy):\")\n",
    "    for af in fic_framework.alphaF_values:\n",
    "        print(f\"\\nFor αF = {af}:\")\n",
    "        print(\"-\" * 50)\n",
    "        if af in fic_results:\n",
    "            for pair, d in fic_results[af].items():\n",
    "                tier = fic_framework.classify_tier(d['fic_score'])\n",
    "                msg = tier if d['fic_score'] <= 0.75 else f\"{tier} (omega_max < {0.25*af:.4f})\"\n",
    "                print(f\"{pair}: ω={d['omega']:.4f}, FIC={d['fic_score']:.3f} → {msg}\")\n",
    "                tier_data.append({'alphaF': af, 'Group Pair': pair, 'ω': d['omega'], 'FIC': d['fic_score'], 'Tier': tier})\n",
    "    tier_df = pd.DataFrame(tier_data)\n",
    "    tier_df.to_csv(os.path.join(output_dir, f'Case{case_number}_Tier_Classification_accuracy.csv'), index=False)\n",
    "\n",
    "    # Model comparison\n",
    "    print(\"\\nMODEL COMPARISON:\")\n",
    "    comparison = []\n",
    "    for mt in model_types:\n",
    "        mets, test_data = train_and_evaluate_models(data, target_col, protected_col, mt)\n",
    "        model_fic = fic_framework.analyze_fairness(mets, 'accuracy')\n",
    "        avg_fic = np.mean([d['fic_score'] for d in model_fic[0.10].values()]) if 0.10 in model_fic and model_fic[0.10] else np.nan\n",
    "        max_omega = max([d['omega'] for d in model_fic[0.10].values()]) if 0.10 in model_fic and model_fic[0.10] else np.nan\n",
    "        _, y_test, _, y_pred, _ = test_data\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        comparison.append({\n",
    "            'Model': mt.upper(),\n",
    "            'Overall Accuracy': f\"{acc:.4f}\",\n",
    "            'Avg FIC alphaF=0.10)': f\"{avg_fic:.3f}\" if not np.isnan(avg_fic) else \"N/A\",\n",
    "            'ω_max (alphaF=0.10)': f\"{max_omega:.4f}\" if not np.isnan(max_omega) else \"N/A\"\n",
    "        })\n",
    "    comparison_df = pd.DataFrame(comparison)\n",
    "    print(comparison_df.to_string(index=False))\n",
    "    comparison_df.to_csv(os.path.join(output_dir, f'Case{case_number}_Model_Comparison.csv'), index=False)\n",
    "\n",
    "    return {\n",
    "        'data': data,\n",
    "        'baseline_metrics': baseline_metrics,\n",
    "        'fic_results': fic_results,\n",
    "        'all_fic_results': all_fic_results,  # Store all metrics results\n",
    "        'metrics_df': metrics_df,\n",
    "        'fic_df': fic_df,\n",
    "        'tier_df': tier_df,\n",
    "        'comparison_df': comparison_df\n",
    "    }\n",
    "\n",
    "# ============================================\n",
    "# 6. MAIN ANALYSIS\n",
    "# ============================================\n",
    "\n",
    "def run_complete_analysis():\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"FAIRNESS INFORMATION CRITERION (FIC) ANALYSIS - COMPAS DATASET\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    compas_results = analyze_dataset(\n",
    "        dataset_name=\"COMPAS - Recidivism Risk Prediction\",\n",
    "        data_generator=lambda: generate_compas_data(8000),\n",
    "        target_col='high_risk',\n",
    "        protected_col='race_group',\n",
    "        case_number=1\n",
    "    )\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"SUMMARY REPORT - COMPAS DATASET\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    print(\"COMPAS DATASET KEY FINDINGS:\")\n",
    "    print(\"-\" * 60)\n",
    "    data = compas_results['data']\n",
    "    print(f\"Total samples: {len(data)}\")\n",
    "    print(f\"High risk proportion: {data['high_risk'].mean():.3f}\")\n",
    "    print(\"\\nRace group distribution:\")\n",
    "    race_dist = data['race_group'].value_counts()\n",
    "    for race, count in race_dist.items():\n",
    "        prop = count / len(data)\n",
    "        print(f\"  {race}: {count} ({prop:.3f})\")\n",
    "    \n",
    "    print(\"\\nHigh risk by race group:\")\n",
    "    for race in sorted(data['race_group'].unique()):\n",
    "        subset = data[data['race_group'] == race]\n",
    "        risk_prop = subset['high_risk'].mean()\n",
    "        print(f\"  {race}: {risk_prop:.3f}\")\n",
    "\n",
    "    print(\"\\nFIC ANALYSIS SUMMARY (Accuracy):\")\n",
    "    print(\"-\" * 60)\n",
    "    for af in [0.05, 0.10, 0.15, 0.20]:\n",
    "        if af in compas_results['fic_results'] and compas_results['fic_results'][af]:\n",
    "            items = list(compas_results['fic_results'][af].items())\n",
    "            max_o = max(d['omega'] for _, d in items)\n",
    "            min_o = min(d['omega'] for _, d in items)\n",
    "            avg_o = np.mean([d['omega'] for _, d in items])\n",
    "            worst_pair = max(items, key=lambda x: x[1]['omega'])[0]\n",
    "            best_pair = min(items, key=lambda x: x[1]['omega'])[0]\n",
    "            print(f\"alphaF={af}:\")\n",
    "            print(f\"  omega range: [{min_o:.4f}, {max_o:.4f}], avg: {avg_o:.4f}\")\n",
    "            print(f\"  Most unfair pair: {worst_pair} (ω={max_o:.4f})\")\n",
    "            print(f\"  Most fair pair: {best_pair} (ω={min_o:.4f})\")\n",
    "            \n",
    "            # Tier distribution\n",
    "            fic = FairnessInformationCriterion()\n",
    "            tiers = {'Optimum': 0, 'Acceptable': 0, 'Questionable': 0, 'Unacceptable': 0}\n",
    "            for d in compas_results['fic_results'][af].values():\n",
    "                tiers[fic.classify_tier(d['fic_score'])] += 1\n",
    "            print(f\"  Tier distribution: {tiers}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ANALYSIS COMPLETE - HIGH-QUALITY PLOTS SAVED\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Generated plots for all metrics: accuracy, selection_rate, tpr, tnr, fpr, fnr, ppv, npv, f1, auc\")\n",
    "    print(f\"Each metric has:\")\n",
    "    print(f\"  - 1 heatmap figure (2x2 grid for all alphaF values)\")\n",
    "    print(f\"  - 4 benchmarking tier plots (one for each alphaF: 0.05, 0.10, 0.15, 0.20)\")\n",
    "    print(f\"\\nAll plots saved in both PNG and PDF formats.\")\n",
    "    print(f\"PNG files saved in: {output_dir}/\")\n",
    "    print(f\"PDF files saved in: {pdf_dir}/\")\n",
    "\n",
    "    return compas_results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Check if dataset exists or download it\n",
    "    compas_results = run_complete_analysis()\n",
    "\n",
    "    print(\"\\nAll analysis completed!\")\n",
    "    print(f\"Results saved to: {output_dir}/\")\n",
    "    print(f\"PDF files saved to: {pdf_dir}/\")\n",
    "    print(\"\\nFiles include:\")\n",
    "    print(\"  - Group metrics (CSV)\")\n",
    "    print(\"  - FIC analysis tables for accuracy (CSV)\")\n",
    "    print(\"  - Tier classification for accuracy (CSV)\")\n",
    "    print(\"  - Model comparison (CSV)\")\n",
    "    print(\"  - FIC heatmaps for ALL 10 metrics (PNG + PDF)\")\n",
    "    print(\"  - Benchmarking tiers for ALL 10 metrics (4 plots per metric = 40 PNG + 40 PDF files)\")\n",
    "    print(f\"Total plots generated: {10 + 40} PNG files + {10 + 40} PDF files = {100} total files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a1a65b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcb31f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#.... COMPLETED ALL METRICS PLOTS AND POINT FAIRNESS HYPOTHESIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65731939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FAIRNESS INFORMATION CRITERION (FIC) ANALYSIS - COMPAS DATASET\n",
      "================================================================================\n",
      "Output directory: Compas_NLEGEND_ALL_METRICS_PDF_EXCEL\n",
      "PDF directory: Compas_NLEGEND_ALL_METRICS_PDF_EXCEL\\PDF_plots\n",
      "Excel directory: Compas_NLEGEND_ALL_METRICS_PDF_EXCEL\\Excel_results\n",
      "\n",
      "================================================================================\n",
      "CASE 1: COMPAS - Recidivism Risk Prediction\n",
      "================================================================================\n",
      "Looking for COMPAS dataset at: C:\\Users\\Dr. Akin\\OneDrive\\2025\\Paper_2025\\PHD_Work\\compas-scores-two-years.csv\n",
      "Loaded COMPAS dataset from specified folder\n",
      "Processed dataset shape: (7214, 8)\n",
      "Target distribution (high_risk):\n",
      "high_risk\n",
      "0    0.634599\n",
      "1    0.365401\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Race group distribution:\n",
      "race_group\n",
      "African_American    0.512337\n",
      "Caucasian           0.340172\n",
      "Hispanic            0.088301\n",
      "Other_Race          0.059190\n",
      "Name: proportion, dtype: float64\n",
      "GROUP METRICS TABLE (Baseline Logistic Regression):\n",
      "                  accuracy  selection_rate     tpr     tnr     fpr     fnr     ppv     npv      f1     auc\n",
      "African_American    0.6993          0.3501  0.5498  0.8460  0.1540  0.4502  0.7781  0.6568  0.6443  0.7555\n",
      "Caucasian           0.7976          0.1787  0.4531  0.9139  0.0861  0.5469  0.6397  0.8320  0.5305  0.8210\n",
      "Hispanic            0.8305          0.1525  0.4615  0.9348  0.0652  0.5385  0.6667  0.8600  0.5455  0.8443\n",
      "Other_Race          0.8647          0.1353  0.5000  0.9217  0.0783  0.5000  0.5000  0.9217  0.5000  0.8565\n",
      "✓ Group metrics saved to: Compas_NLEGEND_ALL_METRICS_PDF_EXCEL\\Case1_Group_Metrics.csv\n",
      "\n",
      "GENERATING VISUALIZATIONS FOR ALL METRICS...\n",
      "\n",
      "============================================================\n",
      "ANALYZING METRIC: ACCURACY\n",
      "============================================================\n",
      "  Saved benchmarking tiers plot for alphaF=0.05 (accuracy)\n",
      "  Saved benchmarking tiers plot for alphaF=0.1 (accuracy)\n",
      "  Saved benchmarking tiers plot for alphaF=0.15 (accuracy)\n",
      "  Saved benchmarking tiers plot for alphaF=0.2 (accuracy)\n",
      "Summary for accuracy:\n",
      "\n",
      "============================================================\n",
      "ANALYZING METRIC: SELECTION_RATE\n",
      "============================================================\n",
      "  Saved benchmarking tiers plot for alphaF=0.05 (selection_rate)\n",
      "  Saved benchmarking tiers plot for alphaF=0.1 (selection_rate)\n",
      "  Saved benchmarking tiers plot for alphaF=0.15 (selection_rate)\n",
      "  Saved benchmarking tiers plot for alphaF=0.2 (selection_rate)\n",
      "Summary for selection_rate:\n",
      "\n",
      "============================================================\n",
      "ANALYZING METRIC: TPR\n",
      "============================================================\n",
      "  Saved benchmarking tiers plot for alphaF=0.05 (tpr)\n",
      "  Saved benchmarking tiers plot for alphaF=0.1 (tpr)\n",
      "  Saved benchmarking tiers plot for alphaF=0.15 (tpr)\n",
      "  Saved benchmarking tiers plot for alphaF=0.2 (tpr)\n",
      "Summary for tpr:\n",
      "\n",
      "============================================================\n",
      "ANALYZING METRIC: TNR\n",
      "============================================================\n",
      "  Saved benchmarking tiers plot for alphaF=0.05 (tnr)\n",
      "  Saved benchmarking tiers plot for alphaF=0.1 (tnr)\n",
      "  Saved benchmarking tiers plot for alphaF=0.15 (tnr)\n",
      "  Saved benchmarking tiers plot for alphaF=0.2 (tnr)\n",
      "Summary for tnr:\n",
      "\n",
      "============================================================\n",
      "ANALYZING METRIC: FPR\n",
      "============================================================\n",
      "  Saved benchmarking tiers plot for alphaF=0.05 (fpr)\n",
      "  Saved benchmarking tiers plot for alphaF=0.1 (fpr)\n",
      "  Saved benchmarking tiers plot for alphaF=0.15 (fpr)\n",
      "  Saved benchmarking tiers plot for alphaF=0.2 (fpr)\n",
      "Summary for fpr:\n",
      "\n",
      "============================================================\n",
      "ANALYZING METRIC: FNR\n",
      "============================================================\n",
      "  Saved benchmarking tiers plot for alphaF=0.05 (fnr)\n",
      "  Saved benchmarking tiers plot for alphaF=0.1 (fnr)\n",
      "  Saved benchmarking tiers plot for alphaF=0.15 (fnr)\n",
      "  Saved benchmarking tiers plot for alphaF=0.2 (fnr)\n",
      "Summary for fnr:\n",
      "\n",
      "============================================================\n",
      "ANALYZING METRIC: PPV\n",
      "============================================================\n",
      "  Saved benchmarking tiers plot for alphaF=0.05 (ppv)\n",
      "  Saved benchmarking tiers plot for alphaF=0.1 (ppv)\n",
      "  Saved benchmarking tiers plot for alphaF=0.15 (ppv)\n",
      "  Saved benchmarking tiers plot for alphaF=0.2 (ppv)\n",
      "Summary for ppv:\n",
      "\n",
      "============================================================\n",
      "ANALYZING METRIC: NPV\n",
      "============================================================\n",
      "  Saved benchmarking tiers plot for alphaF=0.05 (npv)\n",
      "  Saved benchmarking tiers plot for alphaF=0.1 (npv)\n",
      "  Saved benchmarking tiers plot for alphaF=0.15 (npv)\n",
      "  Saved benchmarking tiers plot for alphaF=0.2 (npv)\n",
      "Summary for npv:\n",
      "\n",
      "============================================================\n",
      "ANALYZING METRIC: F1\n",
      "============================================================\n",
      "  Saved benchmarking tiers plot for alphaF=0.05 (f1)\n",
      "  Saved benchmarking tiers plot for alphaF=0.1 (f1)\n",
      "  Saved benchmarking tiers plot for alphaF=0.15 (f1)\n",
      "  Saved benchmarking tiers plot for alphaF=0.2 (f1)\n",
      "Summary for f1:\n",
      "\n",
      "============================================================\n",
      "ANALYZING METRIC: AUC\n",
      "============================================================\n",
      "  Saved benchmarking tiers plot for alphaF=0.05 (auc)\n",
      "  Saved benchmarking tiers plot for alphaF=0.1 (auc)\n",
      "  Saved benchmarking tiers plot for alphaF=0.15 (auc)\n",
      "  Saved benchmarking tiers plot for alphaF=0.2 (auc)\n",
      "Summary for auc:\n",
      "\n",
      "FIC ANALYSIS TABLE (Accuracy):\n",
      "                   Group Pair              alphaF=0.05   Hypothesis alphaF=0.05               alphaF=0.1    Hypothesis alphaF=0.1              alphaF=0.15   Hypothesis alphaF=0.15              alphaF=0.2    Hypothesis alphaF=0.2\n",
      " African_American - Caucasian omega=0.0984, FIC=-0.967       Reject H₀ (Unfair)  omega=0.0984, FIC=0.016 Fail to reject Ho (Fair)  omega=0.0984, FIC=0.344 Fail to reject Ho (Fair) omega=0.0984, FIC=0.508 Fail to reject Ho (Fair)\n",
      "  African_American - Hispanic omega=0.1312, FIC=-1.625       Reject H₀ (Unfair) omega=0.1312, FIC=-0.312       Reject H₀ (Unfair)  omega=0.1312, FIC=0.125 Fail to reject Ho (Fair) omega=0.1312, FIC=0.344 Fail to reject Ho (Fair)\n",
      "African_American - Other_Race omega=0.1654, FIC=-2.308       Reject H₀ (Unfair) omega=0.1654, FIC=-0.654       Reject H₀ (Unfair) omega=0.1654, FIC=-0.103       Reject H₀ (Unfair) omega=0.1654, FIC=0.173 Fail to reject Ho (Fair)\n",
      "         Caucasian - Hispanic  omega=0.0329, FIC=0.343 Fail to reject Ho (Fair)  omega=0.0329, FIC=0.671 Fail to reject Ho (Fair)  omega=0.0329, FIC=0.781 Fail to reject Ho (Fair) omega=0.0329, FIC=0.836 Fail to reject Ho (Fair)\n",
      "       Caucasian - Other_Race omega=0.0670, FIC=-0.341       Reject H₀ (Unfair)  omega=0.0670, FIC=0.330 Fail to reject Ho (Fair)  omega=0.0670, FIC=0.553 Fail to reject Ho (Fair) omega=0.0670, FIC=0.665 Fail to reject Ho (Fair)\n",
      "        Hispanic - Other_Race  omega=0.0342, FIC=0.317 Fail to reject Ho (Fair)  omega=0.0342, FIC=0.658 Fail to reject Ho (Fair)  omega=0.0342, FIC=0.772 Fail to reject Ho (Fair) omega=0.0342, FIC=0.829 Fail to reject Ho (Fair)\n",
      "✓ FIC analysis saved to: Compas_NLEGEND_ALL_METRICS_PDF_EXCEL\\Case1_FIC_Analysis_accuracy.csv\n",
      "\n",
      "TIER CLASSIFICATION (Accuracy):\n",
      "\n",
      "For αF = 0.05:\n",
      "--------------------------------------------------\n",
      "African_American - Caucasian: ω=0.0984, FIC=-0.967 → Unacceptable\n",
      "African_American - Hispanic: ω=0.1312, FIC=-1.625 → Unacceptable\n",
      "African_American - Other_Race: ω=0.1654, FIC=-2.308 → Unacceptable\n",
      "Caucasian - Hispanic: ω=0.0329, FIC=0.343 → Questionable\n",
      "Caucasian - Other_Race: ω=0.0670, FIC=-0.341 → Unacceptable\n",
      "Hispanic - Other_Race: ω=0.0342, FIC=0.317 → Questionable\n",
      "\n",
      "For αF = 0.1:\n",
      "--------------------------------------------------\n",
      "African_American - Caucasian: ω=0.0984, FIC=0.016 → Questionable\n",
      "African_American - Hispanic: ω=0.1312, FIC=-0.312 → Unacceptable\n",
      "African_American - Other_Race: ω=0.1654, FIC=-0.654 → Unacceptable\n",
      "Caucasian - Hispanic: ω=0.0329, FIC=0.671 → Acceptable\n",
      "Caucasian - Other_Race: ω=0.0670, FIC=0.330 → Questionable\n",
      "Hispanic - Other_Race: ω=0.0342, FIC=0.658 → Acceptable\n",
      "\n",
      "For αF = 0.15:\n",
      "--------------------------------------------------\n",
      "African_American - Caucasian: ω=0.0984, FIC=0.344 → Questionable\n",
      "African_American - Hispanic: ω=0.1312, FIC=0.125 → Questionable\n",
      "African_American - Other_Race: ω=0.1654, FIC=-0.103 → Unacceptable\n",
      "Caucasian - Hispanic: ω=0.0329, FIC=0.781 → Optimum (omega_max < 0.0375)\n",
      "Caucasian - Other_Race: ω=0.0670, FIC=0.553 → Acceptable\n",
      "Hispanic - Other_Race: ω=0.0342, FIC=0.772 → Optimum (omega_max < 0.0375)\n",
      "\n",
      "For αF = 0.2:\n",
      "--------------------------------------------------\n",
      "African_American - Caucasian: ω=0.0984, FIC=0.508 → Acceptable\n",
      "African_American - Hispanic: ω=0.1312, FIC=0.344 → Questionable\n",
      "African_American - Other_Race: ω=0.1654, FIC=0.173 → Questionable\n",
      "Caucasian - Hispanic: ω=0.0329, FIC=0.836 → Optimum (omega_max < 0.0500)\n",
      "Caucasian - Other_Race: ω=0.0670, FIC=0.665 → Acceptable\n",
      "Hispanic - Other_Race: ω=0.0342, FIC=0.829 → Optimum (omega_max < 0.0500)\n",
      "✓ Tier classification saved to: Compas_NLEGEND_ALL_METRICS_PDF_EXCEL\\Case1_Tier_Classification_accuracy.csv\n",
      "\n",
      "MODEL COMPARISON:\n",
      "   Model Overall Accuracy Avg FIC (αF=0.10) ω_max (αF=0.10)\n",
      "BASELINE           0.7547             0.118          0.1654\n",
      "      L1           0.7547             0.118          0.1654\n",
      "      L2           0.7547             0.118          0.1654\n",
      "✓ Model comparison saved to: Compas_NLEGEND_ALL_METRICS_PDF_EXCEL\\Case1_Model_Comparison.csv\n",
      "\n",
      "================================================================================\n",
      "CREATING COMPREHENSIVE EXCEL REPORT\n",
      "================================================================================\n",
      "1. Saving Group Metrics Table...\n",
      "2. Saving FIC Analysis Tables for all metrics...\n",
      "3. Saving Tier Classification Summary for all metrics...\n",
      "4. Saving Benchmarking Tiers Numerical Values...\n",
      "5. Saving Summary Statistics for each metric...\n",
      "6. Saving Model Comparison...\n",
      "7. Saving Dataset Statistics...\n",
      "8. Creating Fairness Assessment Matrix...\n",
      "  Saved Excel file: COMPAS_FIC_Complete_Analysis.xlsx\n",
      "\n",
      "✓ Excel report saved: Compas_NLEGEND_ALL_METRICS_PDF_EXCEL\\Excel_results\\COMPAS_FIC_Complete_Analysis.xlsx\n",
      "  Total sheets: 35\n",
      "\n",
      "Excel sheets created:\n",
      "   1. Group_Metrics\n",
      "   2. FIC_Analysis_accuracy\n",
      "   3. FIC_Analysis_selection_rate\n",
      "   4. FIC_Analysis_tpr\n",
      "   5. FIC_Analysis_tnr\n",
      "   6. FIC_Analysis_fpr\n",
      "   7. FIC_Analysis_fnr\n",
      "   8. FIC_Analysis_ppv\n",
      "   9. FIC_Analysis_npv\n",
      "  10. FIC_Analysis_f1\n",
      "  11. FIC_Analysis_auc\n",
      "  12. Tier_Summary_accuracy\n",
      "  13. Tier_Summary_selection_rate\n",
      "  14. Tier_Summary_tpr\n",
      "  15. Tier_Summary_tnr\n",
      "  16. Tier_Summary_fpr\n",
      "  17. Tier_Summary_fnr\n",
      "  18. Tier_Summary_ppv\n",
      "  19. Tier_Summary_npv\n",
      "  20. Tier_Summary_f1\n",
      "  21. Tier_Summary_auc\n",
      "  22. Benchmark_Tiers_accuracy\n",
      "  23. Benchmark_Tiers_selection_rate\n",
      "  24. Benchmark_Tiers_tpr\n",
      "  25. Benchmark_Tiers_tnr\n",
      "  26. Benchmark_Tiers_fpr\n",
      "  27. Benchmark_Tiers_fnr\n",
      "  28. Benchmark_Tiers_ppv\n",
      "  29. Benchmark_Tiers_npv\n",
      "  30. Benchmark_Tiers_f1\n",
      "  31. Benchmark_Tiers_auc\n",
      "  32. Summary_Statistics\n",
      "  33. Model_Comparison\n",
      "  34. Dataset_Statistics\n",
      "  35. Fairness_Assessment\n",
      "\n",
      "================================================================================\n",
      "SUMMARY REPORT - COMPAS DATASET\n",
      "================================================================================\n",
      "COMPAS DATASET KEY FINDINGS:\n",
      "------------------------------------------------------------\n",
      "Total samples: 7214\n",
      "High risk proportion: 0.365\n",
      "\n",
      "Race group distribution:\n",
      "  African_American: 3696 (0.512)\n",
      "  Caucasian: 2454 (0.340)\n",
      "  Hispanic: 637 (0.088)\n",
      "  Other_Race: 427 (0.059)\n",
      "\n",
      "High risk by race group:\n",
      "  African_American: 0.489\n",
      "  Caucasian: 0.250\n",
      "  Hispanic: 0.217\n",
      "  Other_Race: 0.178\n",
      "\n",
      "FIC ANALYSIS SUMMARY (Accuracy):\n",
      "------------------------------------------------------------\n",
      "alphaF=0.05:\n",
      "  omega range: [0.0329, 0.1654], avg: 0.0882\n",
      "  Most unfair pair: African_American - Other_Race (ω=0.1654)\n",
      "  Most fair pair: Caucasian - Hispanic (ω=0.0329)\n",
      "  Tier distribution: {'Optimum': 0, 'Acceptable': 0, 'Questionable': 2, 'Unacceptable': 4}\n",
      "alphaF=0.1:\n",
      "  omega range: [0.0329, 0.1654], avg: 0.0882\n",
      "  Most unfair pair: African_American - Other_Race (ω=0.1654)\n",
      "  Most fair pair: Caucasian - Hispanic (ω=0.0329)\n",
      "  Tier distribution: {'Optimum': 0, 'Acceptable': 2, 'Questionable': 2, 'Unacceptable': 2}\n",
      "alphaF=0.15:\n",
      "  omega range: [0.0329, 0.1654], avg: 0.0882\n",
      "  Most unfair pair: African_American - Other_Race (ω=0.1654)\n",
      "  Most fair pair: Caucasian - Hispanic (ω=0.0329)\n",
      "  Tier distribution: {'Optimum': 2, 'Acceptable': 1, 'Questionable': 2, 'Unacceptable': 1}\n",
      "alphaF=0.2:\n",
      "  omega range: [0.0329, 0.1654], avg: 0.0882\n",
      "  Most unfair pair: African_American - Other_Race (ω=0.1654)\n",
      "  Most fair pair: Caucasian - Hispanic (ω=0.0329)\n",
      "  Tier distribution: {'Optimum': 2, 'Acceptable': 2, 'Questionable': 2, 'Unacceptable': 0}\n",
      "\n",
      "================================================================================\n",
      "ANALYSIS COMPLETE - ALL RESULTS SAVED\n",
      "================================================================================\n",
      "\n",
      "📊 VISUALIZATIONS:\n",
      "  Generated plots for all 10 metrics\n",
      "  Each metric has:\n",
      "    - 1 heatmap figure (2x2 grid for all alphaF values)\n",
      "    - 4 benchmarking tier plots (one for each alphaF: 0.05, 0.10, 0.15, 0.20)\n",
      "  Total plots: 50 PNG files + 50 PDF files = 100 total files\n",
      "\n",
      "📈 NUMERICAL RESULTS:\n",
      "  CSV files saved in: Compas_NLEGEND_ALL_METRICS_PDF_EXCEL/\n",
      "  Comprehensive Excel report: Compas_NLEGEND_ALL_METRICS_PDF_EXCEL\\Excel_results\\COMPAS_FIC_Complete_Analysis.xlsx\n",
      "\n",
      "📁 OUTPUT STRUCTURE:\n",
      "  Compas_NLEGEND_ALL_METRICS_PDF_EXCEL/\n",
      "    ├── PDF_plots/          (All PDF visualizations)\n",
      "    ├── Excel_results/      (Complete Excel report)\n",
      "    └── *.csv              (Individual CSV files)\n",
      "\n",
      "================================================================================\n",
      "🎉 ALL ANALYSIS COMPLETED SUCCESSFULLY!\n",
      "================================================================================\n",
      "\n",
      "✅ Key outputs:\n",
      "   1. Comprehensive Excel report with ALL numerical values\n",
      "   2. 100 high-quality visualizations (PNG + PDF)\n",
      "   3. Individual CSV files for quick access\n",
      "\n",
      "📊 Excel report includes:\n",
      "   - Group metrics for all race groups\n",
      "   - FIC analysis for all 10 metrics\n",
      "   - Tier classification for all metrics\n",
      "   - Benchmarking tiers numerical values\n",
      "   - Summary statistics\n",
      "   - Fairness assessment matrix\n",
      "   - Model comparison\n",
      "   - Dataset statistics\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import warnings\n",
    "import os\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "from openpyxl.styles import PatternFill, Font, Alignment, Border, Side\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create output directory\n",
    "output_dir = \"Compas_NLEGEND_ALL_METRICS_PDF_EXCEL\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Also create PDF subdirectory\n",
    "pdf_dir = os.path.join(output_dir, \"PDF_plots\")\n",
    "os.makedirs(pdf_dir, exist_ok=True)\n",
    "\n",
    "# Create Excel subdirectory\n",
    "excel_dir = os.path.join(output_dir, \"Excel_results\")\n",
    "os.makedirs(excel_dir, exist_ok=True)\n",
    "\n",
    "# Set style for publication quality\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Global font settings for consistency\n",
    "plt.rcParams.update({\n",
    "    'font.size': 12,\n",
    "    'axes.titlesize': 16,\n",
    "    'axes.labelsize': 14,\n",
    "    'xtick.labelsize': 12,\n",
    "    'ytick.labelsize': 12,\n",
    "    'legend.fontsize': 12,\n",
    "})\n",
    "\n",
    "# ============================================\n",
    "# 1. LOAD AND PREPROCESS COMPAS DATASET\n",
    "# ============================================\n",
    "\n",
    "def load_compas_data():\n",
    "    \"\"\"\n",
    "    Load and preprocess COMPAS ProPublica dataset from local folder\n",
    "    \"\"\"\n",
    "    # Define your specific folder path\n",
    "    data_folder = r'C:\\Users\\Dr. Akin\\OneDrive\\2025\\Paper_2025\\PHD_Work'\n",
    "    data_file = \"compas-scores-two-years.csv\"\n",
    "    data_path = os.path.join(data_folder, data_file)\n",
    "    \n",
    "    print(f\"Looking for COMPAS dataset at: {data_path}\")\n",
    "    \n",
    "    # Try to load from your specified folder\n",
    "    compas_df = pd.read_csv(data_path)\n",
    "    print(\"Loaded COMPAS dataset from specified folder\")\n",
    "   \n",
    "    \n",
    "    # Filter relevant columns\n",
    "    relevant_columns = [\n",
    "        'age', 'sex', 'race', 'priors_count', 'c_charge_degree',\n",
    "        'juv_fel_count', 'juv_misd_count', 'juv_other_count',\n",
    "        'decile_score', 'two_year_recid'\n",
    "    ]\n",
    "    \n",
    "    # Check which columns exist in the dataset\n",
    "    available_columns = [col for col in relevant_columns if col in compas_df.columns]\n",
    "    compas_df = compas_df[available_columns].copy()\n",
    "    \n",
    "    # Drop rows with missing values\n",
    "    compas_df = compas_df.dropna()\n",
    "    \n",
    "    # Create high_risk target: 0-5 as low risk, 6-10 as high risk\n",
    "    compas_df['high_risk'] = (compas_df['decile_score'] >= 6).astype(int)\n",
    "    \n",
    "    # Consolidate race categories\n",
    "    def consolidate_race(race):\n",
    "        race = str(race).strip().lower()\n",
    "        if 'african' in race or 'black' in race:\n",
    "            return 'African_American'\n",
    "        elif 'caucasian' in race or 'white' in race:\n",
    "            return 'Caucasian'\n",
    "        elif 'hispanic' in race or 'latino' in race:\n",
    "            return 'Hispanic'\n",
    "        elif 'asian' in race or 'arab' in race or 'native' in race or 'other' in race:\n",
    "            return 'Other_Race'\n",
    "        else:\n",
    "            return 'Other_Race'\n",
    "    \n",
    "    compas_df['race_group'] = compas_df['race'].apply(consolidate_race)\n",
    "    \n",
    "    # Filter to keep only our target race groups\n",
    "    target_races = ['African_American', 'Caucasian', 'Hispanic', 'Other_Race']\n",
    "    compas_df = compas_df[compas_df['race_group'].isin(target_races)].copy()\n",
    "    \n",
    "    # Create additional features for better prediction\n",
    "    compas_df['total_juvenile_charges'] = compas_df['juv_fel_count'] + compas_df['juv_misd_count'] + compas_df['juv_other_count']\n",
    "    compas_df['is_felony'] = (compas_df['c_charge_degree'] == 'F').astype(int)\n",
    "    compas_df['age_group'] = pd.cut(compas_df['age'], \n",
    "                                     bins=[0, 25, 35, 45, 55, 100],\n",
    "                                     labels=['18-25', '26-35', '36-45', '46-55', '56+'])\n",
    "    \n",
    "    # Select final columns for analysis\n",
    "    final_columns = [\n",
    "        'age', 'sex', 'race_group', 'priors_count', 'is_felony',\n",
    "        'total_juvenile_charges', 'age_group', 'high_risk'\n",
    "    ]\n",
    "    \n",
    "    # Ensure all columns exist\n",
    "    final_columns = [col for col in final_columns if col in compas_df.columns]\n",
    "    compas_df = compas_df[final_columns]\n",
    "    \n",
    "    print(f\"Processed dataset shape: {compas_df.shape}\")\n",
    "    print(f\"Target distribution (high_risk):\")\n",
    "    print(compas_df['high_risk'].value_counts(normalize=True))\n",
    "    print(f\"\\nRace group distribution:\")\n",
    "    print(compas_df['race_group'].value_counts(normalize=True))\n",
    "    \n",
    "    return compas_df\n",
    "\n",
    "def generate_compas_data(n_samples=None):\n",
    "    \"\"\"\n",
    "    Wrapper function to load COMPAS data\n",
    "    n_samples parameter is kept for compatibility but not used\n",
    "    \"\"\"\n",
    "    data = load_compas_data()\n",
    "    \n",
    "    # If n_samples is specified and smaller than dataset, sample it\n",
    "    if n_samples and n_samples < len(data):\n",
    "        data = data.sample(n=n_samples, random_state=42)\n",
    "    \n",
    "    return data\n",
    "\n",
    "# ============================================\n",
    "# 2-3. MODEL & FIC\n",
    "# ============================================\n",
    "\n",
    "def compute_all_metrics(y_true, y_pred, y_prob):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_true, y_pred),\n",
    "        'selection_rate': (tp + fp) / len(y_true),\n",
    "        'tpr': tp / (tp + fn) if (tp + fn) > 0 else 0,\n",
    "        'tnr': tn / (tn + fp) if (tn + fp) > 0 else 0,\n",
    "        'fpr': fp / (fp + tn) if (fp + tn) > 0 else 0,\n",
    "        'fnr': fn / (tp + fn) if (tp + fn) > 0 else 0,\n",
    "        'ppv': tp / (tp + fp) if (tp + fp) > 0 else 0,\n",
    "        'npv': tn / (tn + fn) if (tn + fn) > 0 else 0,\n",
    "        'f1': f1_score(y_true, y_pred),\n",
    "        'auc': roc_auc_score(y_true, y_prob) if len(np.unique(y_true)) > 1 else np.nan\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "def train_and_evaluate_models(data, target_col, protected_col, model_type='baseline'):\n",
    "    X = data.drop(columns=[target_col, protected_col])\n",
    "    y = data[target_col]\n",
    "    categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "    numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(drop='first'), categorical_cols)\n",
    "    ])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "    protected_test = data.loc[X_test.index, protected_col]\n",
    "\n",
    "    X_train_processed = preprocessor.fit_transform(X_train)\n",
    "    X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "    if model_type == 'baseline':\n",
    "        model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "    elif model_type == 'l1':\n",
    "        model = LogisticRegression(penalty='l1', solver='liblinear', random_state=42, max_iter=1000, C=1.0)\n",
    "    elif model_type == 'l2':\n",
    "        model = LogisticRegression(penalty='l2', random_state=42, max_iter=1000, C=1.0)\n",
    "    else:\n",
    "        model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "    model.fit(X_train_processed, y_train)\n",
    "    y_pred = model.predict(X_test_processed)\n",
    "    y_prob = model.predict_proba(X_test_processed)[:, 1]\n",
    "\n",
    "    group_metrics = {}\n",
    "    for group in protected_test.unique():\n",
    "        mask = protected_test == group\n",
    "        if mask.sum() > 0:\n",
    "            group_metrics[group] = compute_all_metrics(y_test[mask], y_pred[mask], y_prob[mask])\n",
    "\n",
    "    return group_metrics, (X_test, y_test, protected_test, y_pred, y_prob)\n",
    "\n",
    "class FairnessInformationCriterion:\n",
    "    def __init__(self, alphaF_values=[0.05, 0.10, 0.15, 0.20]):\n",
    "        self.alphaF_values = alphaF_values\n",
    "\n",
    "    def compute_omega(self, metric1, metric2):\n",
    "        return abs(metric1 - metric2)\n",
    "\n",
    "    def compute_fic(self, omega, alphaF):\n",
    "        return 1 - (omega / alphaF)\n",
    "\n",
    "    def classify_tier(self, fic_score):\n",
    "        if fic_score > 0.75:\n",
    "            return \"Optimum\"\n",
    "        elif fic_score > 0.50:\n",
    "            return \"Acceptable\"\n",
    "        elif fic_score > 0:\n",
    "            return \"Questionable\"\n",
    "        else:\n",
    "            return \"Unacceptable\"\n",
    "\n",
    "    def analyze_fairness(self, group_metrics, metric_name='accuracy'):\n",
    "        results = {}\n",
    "        groups = list(group_metrics.keys())\n",
    "        for alphaF in self.alphaF_values:\n",
    "            results[alphaF] = {}\n",
    "            for i, g1 in enumerate(groups):\n",
    "                for g2 in groups[i+1:]:\n",
    "                    pair = f\"{g1} - {g2}\"\n",
    "                    m1 = group_metrics[g1].get(metric_name, np.nan)\n",
    "                    m2 = group_metrics[g2].get(metric_name, np.nan)\n",
    "                    if not np.isnan(m1) and not np.isnan(m2):\n",
    "                        omega = self.compute_omega(m1, m2)\n",
    "                        fic_score = self.compute_fic(omega, alphaF)\n",
    "                        tier = self.classify_tier(fic_score)\n",
    "                        results[alphaF][pair] = {\n",
    "                            'omega': omega, 'fic_score': fic_score, 'tier': tier,\n",
    "                            'metric1': m1, 'metric2': m2\n",
    "                        }\n",
    "        return results\n",
    "\n",
    "# ============================================\n",
    "# 4. EXCEL EXPORT FUNCTIONS\n",
    "# ============================================\n",
    "\n",
    "def save_to_excel_with_formatting(data_dict, filename, sheet_name_prefix=\"Case1\"):\n",
    "    \"\"\"\n",
    "    Save multiple dataframes to Excel with formatting\n",
    "    \"\"\"\n",
    "    excel_path = os.path.join(excel_dir, filename)\n",
    "    \n",
    "    with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:\n",
    "        # Save each dataframe to a separate sheet\n",
    "        for sheet_name, df in data_dict.items():\n",
    "            # Create full sheet name\n",
    "            full_sheet_name = f\"{sheet_name_prefix}_{sheet_name}\" if sheet_name_prefix else sheet_name\n",
    "            \n",
    "            # Truncate sheet name if too long (Excel limit is 31 characters)\n",
    "            if len(full_sheet_name) > 31:\n",
    "                full_sheet_name = full_sheet_name[:31]\n",
    "            \n",
    "            # Write dataframe to Excel\n",
    "            df.to_excel(writer, sheet_name=full_sheet_name, index=False)\n",
    "            \n",
    "            # Get the worksheet for formatting\n",
    "            worksheet = writer.sheets[full_sheet_name]\n",
    "            \n",
    "            # Apply formatting\n",
    "            for column in worksheet.columns:\n",
    "                max_length = 0\n",
    "                column_letter = column[0].column_letter\n",
    "                for cell in column:\n",
    "                    try:\n",
    "                        if len(str(cell.value)) > max_length:\n",
    "                            max_length = len(str(cell.value))\n",
    "                    except:\n",
    "                        pass\n",
    "                adjusted_width = min(max_length + 2, 50)\n",
    "                worksheet.column_dimensions[column_letter].width = adjusted_width\n",
    "            \n",
    "            # Freeze the first row\n",
    "            worksheet.freeze_panes = 'A2'\n",
    "    \n",
    "    print(f\"  Saved Excel file: {filename}\")\n",
    "    return excel_path\n",
    "\n",
    "def create_comprehensive_excel_report(compas_results, all_fic_results, metrics_list):\n",
    "    \"\"\"\n",
    "    Create a comprehensive Excel report with all numerical values\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"CREATING COMPREHENSIVE EXCEL REPORT\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    data_dict = {}\n",
    "    \n",
    "    # 1. Group Metrics Table\n",
    "    print(\"1. Saving Group Metrics Table...\")\n",
    "    data_dict['Group_Metrics'] = compas_results['metrics_df'].reset_index().rename(columns={'index': 'Race_Group'})\n",
    "    \n",
    "    # 2. FIC Analysis Tables for all metrics\n",
    "    print(\"2. Saving FIC Analysis Tables for all metrics...\")\n",
    "    for metric in metrics_list:\n",
    "        fic_results = all_fic_results[metric]\n",
    "        \n",
    "        # Create comprehensive FIC table for this metric\n",
    "        fic_table = []\n",
    "        for pair in sorted(set(p for a in fic_results.values() for p in a.keys())):\n",
    "            row = {'Group_Pair': pair}\n",
    "            for af in [0.05, 0.10, 0.15, 0.20]:\n",
    "                if af in fic_results and pair in fic_results[af]:\n",
    "                    d = fic_results[af][pair]\n",
    "                    row[f'omega_alphaF_{af}'] = d['omega']\n",
    "                    row[f'FIC_alphaF_{af}'] = d['fic_score']\n",
    "                    row[f'Tier_alphaF_{af}'] = d['tier']\n",
    "                    row[f'Metric1_{af}'] = d['metric1']\n",
    "                    row[f'Metric2_{af}'] = d['metric2']\n",
    "                else:\n",
    "                    row[f'omega_alphaF_{af}'] = np.nan\n",
    "                    row[f'FIC_alphaF_{af}'] = np.nan\n",
    "                    row[f'Tier_alphaF_{af}'] = \"N/A\"\n",
    "                    row[f'Metric1_{af}'] = np.nan\n",
    "                    row[f'Metric2_{af}'] = np.nan\n",
    "            fic_table.append(row)\n",
    "        \n",
    "        fic_df = pd.DataFrame(fic_table)\n",
    "        data_dict[f'FIC_Analysis_{metric}'] = fic_df\n",
    "    \n",
    "    # 3. Tier Classification Summary for all metrics\n",
    "    print(\"3. Saving Tier Classification Summary for all metrics...\")\n",
    "    for metric in metrics_list:\n",
    "        fic_results = all_fic_results[metric]\n",
    "        \n",
    "        tier_summary = []\n",
    "        for af in [0.05, 0.10, 0.15, 0.20]:\n",
    "            if af in fic_results and fic_results[af]:\n",
    "                tiers = {'Optimum': 0, 'Acceptable': 0, 'Questionable': 0, 'Unacceptable': 0}\n",
    "                fic_framework = FairnessInformationCriterion()\n",
    "                for d in fic_results[af].values():\n",
    "                    tiers[fic_framework.classify_tier(d['fic_score'])] += 1\n",
    "                \n",
    "                total_pairs = sum(tiers.values())\n",
    "                for tier_name, count in tiers.items():\n",
    "                    tier_summary.append({\n",
    "                        'Metric': metric,\n",
    "                        'alphaF': af,\n",
    "                        'Tier': tier_name,\n",
    "                        'Count': count,\n",
    "                        'Percentage': (count / total_pairs * 100) if total_pairs > 0 else 0\n",
    "                    })\n",
    "        \n",
    "        tier_summary_df = pd.DataFrame(tier_summary)\n",
    "        data_dict[f'Tier_Summary_{metric}'] = tier_summary_df\n",
    "    \n",
    "    # 4. Benchmarking Tiers Numerical Values\n",
    "    print(\"4. Saving Benchmarking Tiers Numerical Values...\")\n",
    "    for metric in metrics_list:\n",
    "        fic_results = all_fic_results[metric]\n",
    "        \n",
    "        benchmark_data = []\n",
    "        for af in [0.05, 0.10, 0.15, 0.20]:\n",
    "            if af in fic_results and fic_results[af]:\n",
    "                for pair, d in fic_results[af].items():\n",
    "                    benchmark_data.append({\n",
    "                        'Metric': metric,\n",
    "                        'alphaF': af,\n",
    "                        'Group_Pair': pair,\n",
    "                        'FIC_Score': d['fic_score'],\n",
    "                        'Tier': d['tier'],\n",
    "                        'omega': d['omega'],\n",
    "                        'Metric_Value_Group1': d['metric1'],\n",
    "                        'Metric_Value_Group2': d['metric2']\n",
    "                    })\n",
    "        \n",
    "        benchmark_df = pd.DataFrame(benchmark_data)\n",
    "        data_dict[f'Benchmark_Tiers_{metric}'] = benchmark_df\n",
    "    \n",
    "    # 5. Summary Statistics for each metric\n",
    "    print(\"5. Saving Summary Statistics for each metric...\")\n",
    "    summary_stats = []\n",
    "    for metric in metrics_list:\n",
    "        fic_results = all_fic_results[metric]\n",
    "        \n",
    "        for af in [0.05, 0.10, 0.15, 0.20]:\n",
    "            if af in fic_results and fic_results[af]:\n",
    "                fic_scores = [d['fic_score'] for d in fic_results[af].values()]\n",
    "                omegas = [d['omega'] for d in fic_results[af].values()]\n",
    "                \n",
    "                summary_stats.append({\n",
    "                    'Metric': metric,\n",
    "                    'alphaF': af,\n",
    "                    'FIC_Mean': np.mean(fic_scores),\n",
    "                    'FIC_Std': np.std(fic_scores),\n",
    "                    'FIC_Min': np.min(fic_scores),\n",
    "                    'FIC_Max': np.max(fic_scores),\n",
    "                    'omega_Mean': np.mean(omegas),\n",
    "                    'omega_Std': np.std(omegas),\n",
    "                    'omega_Min': np.min(omegas),\n",
    "                    'omega_Max': np.max(omegas),\n",
    "                    'Num_Pairs': len(fic_scores)\n",
    "                })\n",
    "    \n",
    "    summary_df = pd.DataFrame(summary_stats)\n",
    "    data_dict['Summary_Statistics'] = summary_df\n",
    "    \n",
    "    # 6. Model Comparison\n",
    "    print(\"6. Saving Model Comparison...\")\n",
    "    data_dict['Model_Comparison'] = compas_results['comparison_df']\n",
    "    \n",
    "    # 7. Dataset Statistics\n",
    "    print(\"7. Saving Dataset Statistics...\")\n",
    "    data = compas_results['data']\n",
    "    dataset_stats = pd.DataFrame({\n",
    "        'Statistic': ['Total_Samples', 'High_Risk_Proportion', \n",
    "                      'African_American_Count', 'Caucasian_Count',\n",
    "                      'Hispanic_Count', 'Other_Race_Count',\n",
    "                      'Male_Count', 'Female_Count'],\n",
    "        'Value': [\n",
    "            len(data),\n",
    "            data['high_risk'].mean(),\n",
    "            (data['race_group'] == 'African_American').sum(),\n",
    "            (data['race_group'] == 'Caucasian').sum(),\n",
    "            (data['race_group'] == 'Hispanic').sum(),\n",
    "            (data['race_group'] == 'Other_Race').sum(),\n",
    "            (data['sex'] == 'Male').sum() if 'sex' in data.columns else np.nan,\n",
    "            (data['sex'] == 'Female').sum() if 'sex' in data.columns else np.nan\n",
    "        ]\n",
    "    })\n",
    "    data_dict['Dataset_Statistics'] = dataset_stats\n",
    "    \n",
    "    # 8. Fairness Assessment Matrix\n",
    "    print(\"8. Creating Fairness Assessment Matrix...\")\n",
    "    fairness_matrix = []\n",
    "    for metric in metrics_list:\n",
    "        fic_results = all_fic_results[metric]\n",
    "        \n",
    "        for af in [0.05, 0.10, 0.15, 0.20]:\n",
    "            if af in fic_results and fic_results[af]:\n",
    "                # Count pairs in each tier\n",
    "                fic_framework = FairnessInformationCriterion()\n",
    "                tiers = {'Optimum': 0, 'Acceptable': 0, 'Questionable': 0, 'Unacceptable': 0}\n",
    "                for d in fic_results[af].values():\n",
    "                    tiers[fic_framework.classify_tier(d['fic_score'])] += 1\n",
    "                \n",
    "                # Determine overall fairness status\n",
    "                if tiers['Unacceptable'] > 0:\n",
    "                    overall_status = \"Unfair\"\n",
    "                elif tiers['Questionable'] > 0:\n",
    "                    overall_status = \"Questionable\"\n",
    "                elif tiers['Acceptable'] > 0:\n",
    "                    overall_status = \"Acceptable\"\n",
    "                else:\n",
    "                    overall_status = \"Optimum\"\n",
    "                \n",
    "                fairness_matrix.append({\n",
    "                    'Metric': metric,\n",
    "                    'alphaF': af,\n",
    "                    'Overall_Fairness': overall_status,\n",
    "                    'Optimum_Pairs': tiers['Optimum'],\n",
    "                    'Acceptable_Pairs': tiers['Acceptable'],\n",
    "                    'Questionable_Pairs': tiers['Questionable'],\n",
    "                    'Unacceptable_Pairs': tiers['Unacceptable'],\n",
    "                    'Total_Pairs': sum(tiers.values())\n",
    "                })\n",
    "    \n",
    "    fairness_df = pd.DataFrame(fairness_matrix)\n",
    "    data_dict['Fairness_Assessment'] = fairness_df\n",
    "    \n",
    "    # Save all to Excel\n",
    "    excel_file = save_to_excel_with_formatting(data_dict, \"COMPAS_FIC_Complete_Analysis.xlsx\", \"COMPAS\")\n",
    "    \n",
    "    print(f\"\\n✓ Excel report saved: {excel_file}\")\n",
    "    print(f\"  Total sheets: {len(data_dict)}\")\n",
    "    \n",
    "    # Print sheet names\n",
    "    print(\"\\nExcel sheets created:\")\n",
    "    for i, sheet_name in enumerate(data_dict.keys(), 1):\n",
    "        print(f\"  {i:2d}. {sheet_name}\")\n",
    "    \n",
    "    return excel_file\n",
    "\n",
    "# ============================================\n",
    "# 5. VISUALIZATIONS - UPDATED FOR PDF AND EXPANDED LEGEND\n",
    "# ============================================\n",
    "\n",
    "def plot_fic_heatmaps(fic_results, dataset_name, metric='accuracy'):\n",
    "    alphaF_values = sorted(fic_results.keys())\n",
    "    if not alphaF_values:\n",
    "        return\n",
    "\n",
    "    pairs = list(fic_results[alphaF_values[0]].keys())\n",
    "    all_groups = sorted(set(g for p in pairs for g in p.split(' - ')))\n",
    "\n",
    "    # Larger figure\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(20, 16))\n",
    "    fig.suptitle(f'FIC Heatmaps for Different alphaF Values ({metric})',\n",
    "                 fontsize=20, fontweight='bold', y=0.98)\n",
    "\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for idx, alphaF in enumerate(alphaF_values):\n",
    "        ax = axes[idx]\n",
    "        n = len(all_groups)\n",
    "        mat = np.full((n, n), np.nan)\n",
    "        group_idx = {g: i for i, g in enumerate(all_groups)}\n",
    "\n",
    "        for pair, d in fic_results[alphaF].items():\n",
    "            g1, g2 = pair.split(' - ')\n",
    "            i, j = group_idx[g1], group_idx[g2]\n",
    "            mat[i, j] = mat[j, i] = d['fic_score']\n",
    "\n",
    "        im = ax.imshow(mat, cmap='RdYlGn', vmin=-1, vmax=1, aspect='equal')\n",
    "\n",
    "        # Add value labels inside cells\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                if i != j and not np.isnan(mat[i, j]):\n",
    "                    text = ax.text(j, i, f'{mat[i,j]:.2f}',\n",
    "                                   ha='center', va='center',\n",
    "                                   fontsize=14, fontweight='bold',\n",
    "                                   color='white' if abs(mat[i,j]) > 0.5 else 'black')\n",
    "\n",
    "        ax.set_xticks(range(n))\n",
    "        ax.set_yticks(range(n))\n",
    "        ax.set_xticklabels(all_groups, rotation=45, ha='right', fontsize=13, fontweight='bold')\n",
    "        ax.set_yticklabels(all_groups, fontsize=13, fontweight='bold')\n",
    "        ax.set_title(f'αF = {alphaF}', fontsize=18, fontweight='bold', pad=20)\n",
    "        \n",
    "        # Add grid\n",
    "        ax.set_xticks(np.arange(-.5, n, 1), minor=True)\n",
    "        ax.set_yticks(np.arange(-.5, n, 1), minor=True)\n",
    "        ax.grid(which='minor', color='gray', linestyle='-', linewidth=0.5, alpha=0.3)\n",
    "\n",
    "    # Add a single comprehensive colorbar with tier labels\n",
    "    cbar_ax = fig.add_axes([0.78, 0.15, 0.02, 0.7])  # [left, bottom, width, height]\n",
    "    cbar = fig.colorbar(im, cax=cbar_ax)\n",
    "    cbar.set_label('FIC Score', fontsize=14, fontweight='bold', labelpad=15)\n",
    "    cbar.ax.tick_params(labelsize=12)\n",
    "    \n",
    "    # Bold the colorbar tick labels\n",
    "    for label in cbar.ax.get_yticklabels():\n",
    "        label.set_fontweight('bold')\n",
    "    \n",
    "    # Add tier annotations on the colorbar with more space\n",
    "    cbar.ax.text(1.6, 0.90, 'Optimum', transform=cbar.ax.transAxes, \n",
    "                 fontsize=14, fontweight='bold', va='center', ha='left', color='darkgreen')\n",
    "    cbar.ax.text(1.6, 0.60, 'Acceptable', transform=cbar.ax.transAxes, \n",
    "                 fontsize=14, fontweight='bold', va='center', ha='left', color='goldenrod')\n",
    "    cbar.ax.text(1.6, 0.350, 'Questionable', transform=cbar.ax.transAxes, \n",
    "                 fontsize=14, fontweight='bold', va='center', ha='left', color='darkorange')\n",
    "    cbar.ax.text(1.6, 0.100, 'Unacceptable', transform=cbar.ax.transAxes, \n",
    "                 fontsize=14, fontweight='bold', va='center', ha='left', color='darkred')\n",
    "    \n",
    "    # Add tier threshold lines on colorbar\n",
    "    cbar.ax.axhline(0.75, color='darkgreen', linestyle='--', linewidth=3, xmax=0.6)\n",
    "    cbar.ax.axhline(0.50, color='goldenrod', linestyle='--', linewidth=3, xmax=0.6)\n",
    "    cbar.ax.axhline(0.00, color='darkred', linestyle='--', linewidth=3, xmax=0.6)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 0.78, 0.95])\n",
    "    \n",
    "    # Save as PNG\n",
    "    plt.savefig(os.path.join(output_dir, f'{dataset_name}_FIC_Heatmaps_{metric}.png'), \n",
    "                dpi=400, bbox_inches='tight')\n",
    "    # Save as PDF\n",
    "    plt.savefig(os.path.join(pdf_dir, f'{dataset_name}_FIC_Heatmaps_{metric}.pdf'), \n",
    "                format='pdf', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_benchmarking_tiers(fic_results, dataset_name, metric='accuracy'):\n",
    "    # Sort alphaF values to ensure consistent order\n",
    "    alphaF_values = sorted(fic_results.keys())\n",
    "    \n",
    "    # Define colors for tiers\n",
    "    colors = {'Optimum': '#2E8B57', 'Acceptable': '#FFD700', \n",
    "              'Questionable': '#FF8C00', 'Unacceptable': '#DC143C'}\n",
    "    \n",
    "    for alphaF in alphaF_values:\n",
    "        if alphaF not in fic_results or not fic_results[alphaF]:\n",
    "            print(f\"No data for alphaF={alphaF} in benchmarking tiers\")\n",
    "            continue\n",
    "        \n",
    "        # Create a figure with EXPANDED width to prevent legend cutoff\n",
    "        fig, ax = plt.subplots(figsize=(20, 8))  # Increased width from 16 to 20\n",
    "        \n",
    "        data = fic_results[alphaF]\n",
    "        pairs = list(data.keys())\n",
    "        fic_scores = [data[p]['fic_score'] for p in pairs]\n",
    "        tiers = [data[p]['tier'] for p in pairs]\n",
    "        \n",
    "        # Find max positive and max negative values\n",
    "        max_positive = max(fic_scores) if fic_scores else 1.0\n",
    "        min_negative = min(fic_scores) if fic_scores else -0.25\n",
    "        \n",
    "        # Add padding (10% on positive side, 10% on negative side)\n",
    "        y_max = max_positive * 1.10 if max_positive > 0 else 0.10\n",
    "        y_min = min_negative * 1.10 if min_negative < 0 else -0.10\n",
    "        \n",
    "        # Ensure at least some range for visualization\n",
    "        if y_max - y_min < 0.5:\n",
    "            # If range is too small, center it around the data\n",
    "            center = (max_positive + min_negative) / 2\n",
    "            y_max = center + 0.25\n",
    "            y_min = center - 0.25\n",
    "        \n",
    "        # Create bar colors based on tiers\n",
    "        bar_colors = [colors[t] for t in tiers]\n",
    "        \n",
    "        # Create bars with smaller width for more compact look\n",
    "        bars = ax.bar(range(len(pairs)), fic_scores, color=bar_colors, \n",
    "                      edgecolor='black', linewidth=1.2, width=0.6)\n",
    "        \n",
    "        # Add tier threshold lines with better styling\n",
    "        ax.axhline(0.75, color='darkgreen', linestyle='--', linewidth=2.0, \n",
    "                   alpha=0.7)\n",
    "        ax.axhline(0.50, color='goldenrod', linestyle='--', linewidth=2.0, \n",
    "                   alpha=0.7)\n",
    "        ax.axhline(0.00, color='darkred', linestyle='--', linewidth=2.0, \n",
    "                   alpha=0.7)\n",
    "        \n",
    "        # Customize axes with better labels\n",
    "        ax.set_xlabel('Inter-Group', fontsize=14, fontweight='bold', labelpad=10)\n",
    "        ax.set_ylabel('FIC Score', fontsize=14, fontweight='bold', labelpad=10)\n",
    "        ax.set_title(f'FIC Benchmarking Tiers ({metric}, αF = {alphaF})',\n",
    "                    fontsize=16, fontweight='bold', pad=15)\n",
    "        \n",
    "        # Set x-ticks with rotation for readability\n",
    "        ax.set_xticks(range(len(pairs)))\n",
    "        ax.set_xticklabels(pairs, rotation=45, ha='right', fontsize=11, fontweight='bold')\n",
    "        \n",
    "        # Set dynamic y-axis limits based on actual max positive and max negative\n",
    "        ax.set_ylim(y_min, y_max)\n",
    "        \n",
    "        # Bold the y-axis tick labels\n",
    "        y_ticks = ax.get_yticks()\n",
    "        ax.set_yticklabels([f'{tick:.2f}' for tick in y_ticks], fontsize=11, fontweight='bold')\n",
    "        \n",
    "        # Add grid with lighter style\n",
    "        ax.grid(True, axis='y', alpha=0.3, linestyle='-', linewidth=0.5)\n",
    "        ax.grid(True, axis='x', alpha=0.1, linestyle='-', linewidth=0.5)\n",
    "        \n",
    "        # Add better legend - moved to top right with fewer items\n",
    "        from matplotlib.patches import Patch\n",
    "        legend_elements = [\n",
    "            Patch(facecolor=colors['Optimum'], edgecolor='black', label='Optimum (FIC > 0.75)'),\n",
    "            Patch(facecolor=colors['Acceptable'], edgecolor='black', label='Acceptable (0.50 < FIC ≤ 0.75)'),\n",
    "            Patch(facecolor=colors['Questionable'], edgecolor='black', label='Questionable (0 < FIC ≤ 0.50)'),\n",
    "            Patch(facecolor=colors['Unacceptable'], edgecolor='black', label='Unacceptable (FIC ≤ 0)')\n",
    "        ]\n",
    "        \n",
    "        # Create a separate legend for threshold lines\n",
    "        from matplotlib.lines import Line2D\n",
    "        line_legend_elements = [\n",
    "            Line2D([0], [0], color='darkgreen', linestyle='--', linewidth=2, label='Optimum Threshold (0.75)'),\n",
    "            Line2D([0], [0], color='goldenrod', linestyle='--', linewidth=2, label='Acceptable Threshold (0.50)'),\n",
    "            Line2D([0], [0], color='darkred', linestyle='--', linewidth=2, label='Unacceptable Threshold (0.00)')\n",
    "        ]\n",
    "        \n",
    "        # Place tier legend at upper left - MORE SPACE with bbox_to_anchor\n",
    "        tier_legend = ax.legend(handles=legend_elements, fontsize=10, \n",
    "                                loc='upper left', bbox_to_anchor=(1.05, 1.0),\n",
    "                                frameon=True, framealpha=0.9, edgecolor='black',\n",
    "                                title='FIC Tiers', title_fontsize=11)\n",
    "        # Make the legend title bold\n",
    "        tier_legend.get_title().set_fontweight('bold')\n",
    "        ax.add_artist(tier_legend)\n",
    "        \n",
    "        # Place threshold legend at upper left below tier legend - MORE SPACE\n",
    "        threshold_legend = ax.legend(handles=line_legend_elements, fontsize=9, \n",
    "                                     loc='upper left', bbox_to_anchor=(1.05, 0.65),\n",
    "                                     frameon=True, framealpha=0.9, edgecolor='black',\n",
    "                                     title='Thresholds', title_fontsize=10)\n",
    "        # Make the legend title bold\n",
    "        threshold_legend.get_title().set_fontweight('bold')\n",
    "        \n",
    "        # Add annotation for alphaF interpretation\n",
    "        annotation_text = f'αF = {alphaF}\\nFIC = 1 - (ω/αF)\\nω = |$M₁ - M₂$|'\n",
    "        ax.text(0.02, 0.98, annotation_text, transform=ax.transAxes,\n",
    "                fontsize=9, verticalalignment='top', fontweight='bold',\n",
    "                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
    "        \n",
    "        # Adjust layout to make room for legend - MORE SPACE allocated\n",
    "        plt.tight_layout(rect=[0, 0, 0.80, 1])  # Changed from 0.85 to 0.80 for more legend space\n",
    "        \n",
    "        # Save the figure with alphaF in the filename - BOTH PNG AND PDF\n",
    "        png_filename = f'{dataset_name}_Benchmarking_Tiers_alphaF_{alphaF}_{metric}.png'\n",
    "        pdf_filename = f'{dataset_name}_Benchmarking_Tiers_alphaF_{alphaF}_{metric}.pdf'\n",
    "        \n",
    "        plt.savefig(os.path.join(output_dir, png_filename), \n",
    "                    dpi=400, bbox_inches='tight')\n",
    "        plt.savefig(os.path.join(pdf_dir, pdf_filename), \n",
    "                    format='pdf', bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        print(f\"  Saved benchmarking tiers plot for alphaF={alphaF} ({metric})\")\n",
    "\n",
    "# ============================================\n",
    "# 6. ANALYSIS FUNCTIONS - UPDATED FOR ALL METRICS\n",
    "# ============================================\n",
    "\n",
    "def analyze_dataset(dataset_name, data_generator, target_col, protected_col, case_number=1, model_types=['baseline', 'l1', 'l2']):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"CASE {case_number}: {dataset_name}\")\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "    data = data_generator()\n",
    "    fic_framework = FairnessInformationCriterion()\n",
    "\n",
    "    baseline_metrics, _ = train_and_evaluate_models(data, target_col, protected_col, 'baseline')\n",
    "\n",
    "    metrics_df = pd.DataFrame.from_dict(baseline_metrics, orient='index')\n",
    "    metrics_df = metrics_df[['accuracy', 'selection_rate', 'tpr', 'tnr', 'fpr', 'fnr', 'ppv', 'npv', 'f1', 'auc']]\n",
    "    print(\"GROUP METRICS TABLE (Baseline Logistic Regression):\")\n",
    "    print(metrics_df.round(4).to_string())\n",
    "    \n",
    "    # Save metrics to CSV\n",
    "    metrics_csv_path = os.path.join(output_dir, f'Case{case_number}_Group_Metrics.csv')\n",
    "    metrics_df.to_csv(metrics_csv_path)\n",
    "    print(f\"✓ Group metrics saved to: {metrics_csv_path}\")\n",
    "\n",
    "    print(\"\\nGENERATING VISUALIZATIONS FOR ALL METRICS...\")\n",
    "    \n",
    "    # List of all metrics to analyze\n",
    "    all_metrics = ['accuracy', 'selection_rate', 'tpr', 'tnr', 'fpr', 'fnr', 'ppv', 'npv', 'f1', 'auc']\n",
    "    \n",
    "    # Dictionary to store all FIC results\n",
    "    all_fic_results = {}\n",
    "    \n",
    "    # Dictionary to store metric summaries\n",
    "    metric_summaries = {}\n",
    "    \n",
    "    for metric in all_metrics:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"ANALYZING METRIC: {metric.upper()}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # Analyze fairness for this metric\n",
    "        fic_results = fic_framework.analyze_fairness(baseline_metrics, metric)\n",
    "        all_fic_results[metric] = fic_results\n",
    "        \n",
    "        # Generate heatmaps for this metric\n",
    "        plot_fic_heatmaps(fic_results, f'Case{case_number}_{dataset_name}_{metric}', metric)\n",
    "        \n",
    "        # Generate benchmarking tiers for this metric\n",
    "        plot_benchmarking_tiers(fic_results, f'Case{case_number}_{dataset_name}_{metric}', metric)\n",
    "        \n",
    "        # Store summary for this metric\n",
    "        metric_summary = {}\n",
    "        for af in fic_framework.alphaF_values:\n",
    "            if af in fic_results and fic_results[af]:\n",
    "                omegas = [d['omega'] for d in fic_results[af].values()]\n",
    "                fic_scores = [d['fic_score'] for d in fic_results[af].values()]\n",
    "                tiers = {'Optimum': 0, 'Acceptable': 0, 'Questionable': 0, 'Unacceptable': 0}\n",
    "                fic = FairnessInformationCriterion()\n",
    "                for d in fic_results[af].values():\n",
    "                    tiers[fic.classify_tier(d['fic_score'])] += 1\n",
    "                \n",
    "                metric_summary[f'alphaF_{af}'] = {\n",
    "                    'omega_max': max(omegas),\n",
    "                    'omega_avg': np.mean(omegas),\n",
    "                    'omega_min': min(omegas),\n",
    "                    'fic_max': max(fic_scores),\n",
    "                    'fic_avg': np.mean(fic_scores),\n",
    "                    'fic_min': min(fic_scores),\n",
    "                    'tiers': tiers\n",
    "                }\n",
    "        \n",
    "        metric_summaries[metric] = metric_summary\n",
    "        \n",
    "        # Print summary for this metric\n",
    "        print(f\"Summary for {metric}:\")\n",
    "        for af in fic_framework.alphaF_values:\n",
    "            if af in metric_summary:\n",
    "                summary = metric_summary[f'alphaF_{af}']\n",
    "                print(f\"  αF={af}: ω_max={summary['omega_max']:.4f}, ω_avg={summary['omega_avg']:.4f}, \"\n",
    "                      f\"FIC_avg={summary['fic_avg']:.3f}, Tiers={summary['tiers']}\")\n",
    "\n",
    "    # Store FIC results for accuracy (original metric) for backward compatibility\n",
    "    fic_results = all_fic_results['accuracy']\n",
    "    \n",
    "    # FIC table for accuracy (original)\n",
    "    fic_table = []\n",
    "    for pair in sorted(set(p for a in fic_results.values() for p in a.keys())):\n",
    "        row = {'Group Pair': pair}\n",
    "        for af in fic_framework.alphaF_values:\n",
    "            if af in fic_results and pair in fic_results[af]:\n",
    "                d = fic_results[af][pair]\n",
    "                row[f'alphaF={af}'] = f\"omega={d['omega']:.4f}, FIC={d['fic_score']:.3f}\"\n",
    "                row[f'Hypothesis alphaF={af}'] = \"Fail to reject Ho (Fair)\" if d['omega'] <= af else \"Reject H₀ (Unfair)\"\n",
    "            else:\n",
    "                row[f'alphaF={af}'] = \"N/A\"\n",
    "                row[f'Hypothesis alphaF={af}'] = \"N/A\"\n",
    "        fic_table.append(row)\n",
    "    fic_df = pd.DataFrame(fic_table)\n",
    "    print(\"\\nFIC ANALYSIS TABLE (Accuracy):\")\n",
    "    print(fic_df.to_string(index=False))\n",
    "    \n",
    "    # Save FIC analysis to CSV\n",
    "    fic_csv_path = os.path.join(output_dir, f'Case{case_number}_FIC_Analysis_accuracy.csv')\n",
    "    fic_df.to_csv(fic_csv_path, index=False)\n",
    "    print(f\"✓ FIC analysis saved to: {fic_csv_path}\")\n",
    "\n",
    "    # Tier classification for accuracy (original)\n",
    "    tier_data = []\n",
    "    print(\"\\nTIER CLASSIFICATION (Accuracy):\")\n",
    "    for af in fic_framework.alphaF_values:\n",
    "        print(f\"\\nFor αF = {af}:\")\n",
    "        print(\"-\" * 50)\n",
    "        if af in fic_results:\n",
    "            for pair, d in fic_results[af].items():\n",
    "                tier = fic_framework.classify_tier(d['fic_score'])\n",
    "                msg = tier if d['fic_score'] <= 0.75 else f\"{tier} (omega_max < {0.25*af:.4f})\"\n",
    "                print(f\"{pair}: ω={d['omega']:.4f}, FIC={d['fic_score']:.3f} → {msg}\")\n",
    "                tier_data.append({'alphaF': af, 'Group Pair': pair, 'ω': d['omega'], 'FIC': d['fic_score'], 'Tier': tier})\n",
    "    tier_df = pd.DataFrame(tier_data)\n",
    "    \n",
    "    # Save tier classification to CSV\n",
    "    tier_csv_path = os.path.join(output_dir, f'Case{case_number}_Tier_Classification_accuracy.csv')\n",
    "    tier_df.to_csv(tier_csv_path, index=False)\n",
    "    print(f\"✓ Tier classification saved to: {tier_csv_path}\")\n",
    "\n",
    "    # Model comparison\n",
    "    print(\"\\nMODEL COMPARISON:\")\n",
    "    comparison = []\n",
    "    for mt in model_types:\n",
    "        mets, test_data = train_and_evaluate_models(data, target_col, protected_col, mt)\n",
    "        model_fic = fic_framework.analyze_fairness(mets, 'accuracy')\n",
    "        avg_fic = np.mean([d['fic_score'] for d in model_fic[0.10].values()]) if 0.10 in model_fic and model_fic[0.10] else np.nan\n",
    "        max_omega = max([d['omega'] for d in model_fic[0.10].values()]) if 0.10 in model_fic and model_fic[0.10] else np.nan\n",
    "        _, y_test, _, y_pred, _ = test_data\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        comparison.append({\n",
    "            'Model': mt.upper(),\n",
    "            'Overall Accuracy': f\"{acc:.4f}\",\n",
    "            'Avg FIC (αF=0.10)': f\"{avg_fic:.3f}\" if not np.isnan(avg_fic) else \"N/A\",\n",
    "            'ω_max (αF=0.10)': f\"{max_omega:.4f}\" if not np.isnan(max_omega) else \"N/A\"\n",
    "        })\n",
    "    comparison_df = pd.DataFrame(comparison)\n",
    "    print(comparison_df.to_string(index=False))\n",
    "    \n",
    "    # Save model comparison to CSV\n",
    "    comparison_csv_path = os.path.join(output_dir, f'Case{case_number}_Model_Comparison.csv')\n",
    "    comparison_df.to_csv(comparison_csv_path, index=False)\n",
    "    print(f\"✓ Model comparison saved to: {comparison_csv_path}\")\n",
    "\n",
    "    # Create comprehensive Excel report\n",
    "    excel_file = create_comprehensive_excel_report(\n",
    "        {\n",
    "            'data': data,\n",
    "            'baseline_metrics': baseline_metrics,\n",
    "            'fic_results': fic_results,\n",
    "            'all_fic_results': all_fic_results,\n",
    "            'metrics_df': metrics_df,\n",
    "            'fic_df': fic_df,\n",
    "            'tier_df': tier_df,\n",
    "            'comparison_df': comparison_df\n",
    "        },\n",
    "        all_fic_results,\n",
    "        all_metrics\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        'data': data,\n",
    "        'baseline_metrics': baseline_metrics,\n",
    "        'fic_results': fic_results,\n",
    "        'all_fic_results': all_fic_results,  # Store all metrics results\n",
    "        'metrics_df': metrics_df,\n",
    "        'fic_df': fic_df,\n",
    "        'tier_df': tier_df,\n",
    "        'comparison_df': comparison_df,\n",
    "        'excel_file': excel_file,\n",
    "        'metric_summaries': metric_summaries\n",
    "    }\n",
    "\n",
    "# ============================================\n",
    "# 7. MAIN ANALYSIS\n",
    "# ============================================\n",
    "\n",
    "def run_complete_analysis():\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"FAIRNESS INFORMATION CRITERION (FIC) ANALYSIS - COMPAS DATASET\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Output directory: {output_dir}\")\n",
    "    print(f\"PDF directory: {pdf_dir}\")\n",
    "    print(f\"Excel directory: {excel_dir}\")\n",
    "\n",
    "    compas_results = analyze_dataset(\n",
    "        dataset_name=\"COMPAS - Recidivism Risk Prediction\",\n",
    "        data_generator=lambda: generate_compas_data(8000),\n",
    "        target_col='high_risk',\n",
    "        protected_col='race_group',\n",
    "        case_number=1\n",
    "    )\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"SUMMARY REPORT - COMPAS DATASET\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    print(\"COMPAS DATASET KEY FINDINGS:\")\n",
    "    print(\"-\" * 60)\n",
    "    data = compas_results['data']\n",
    "    print(f\"Total samples: {len(data)}\")\n",
    "    print(f\"High risk proportion: {data['high_risk'].mean():.3f}\")\n",
    "    print(\"\\nRace group distribution:\")\n",
    "    race_dist = data['race_group'].value_counts()\n",
    "    for race, count in race_dist.items():\n",
    "        prop = count / len(data)\n",
    "        print(f\"  {race}: {count} ({prop:.3f})\")\n",
    "    \n",
    "    print(\"\\nHigh risk by race group:\")\n",
    "    for race in sorted(data['race_group'].unique()):\n",
    "        subset = data[data['race_group'] == race]\n",
    "        risk_prop = subset['high_risk'].mean()\n",
    "        print(f\"  {race}: {risk_prop:.3f}\")\n",
    "\n",
    "    print(\"\\nFIC ANALYSIS SUMMARY (Accuracy):\")\n",
    "    print(\"-\" * 60)\n",
    "    for af in [0.05, 0.10, 0.15, 0.20]:\n",
    "        if af in compas_results['fic_results'] and compas_results['fic_results'][af]:\n",
    "            items = list(compas_results['fic_results'][af].items())\n",
    "            max_o = max(d['omega'] for _, d in items)\n",
    "            min_o = min(d['omega'] for _, d in items)\n",
    "            avg_o = np.mean([d['omega'] for _, d in items])\n",
    "            worst_pair = max(items, key=lambda x: x[1]['omega'])[0]\n",
    "            best_pair = min(items, key=lambda x: x[1]['omega'])[0]\n",
    "            print(f\"alphaF={af}:\")\n",
    "            print(f\"  omega range: [{min_o:.4f}, {max_o:.4f}], avg: {avg_o:.4f}\")\n",
    "            print(f\"  Most unfair pair: {worst_pair} (ω={max_o:.4f})\")\n",
    "            print(f\"  Most fair pair: {best_pair} (ω={min_o:.4f})\")\n",
    "            \n",
    "            # Tier distribution\n",
    "            fic = FairnessInformationCriterion()\n",
    "            tiers = {'Optimum': 0, 'Acceptable': 0, 'Questionable': 0, 'Unacceptable': 0}\n",
    "            for d in compas_results['fic_results'][af].values():\n",
    "                tiers[fic.classify_tier(d['fic_score'])] += 1\n",
    "            print(f\"  Tier distribution: {tiers}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ANALYSIS COMPLETE - ALL RESULTS SAVED\")\n",
    "    \n",
    "    return compas_results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run the complete analysis\n",
    "    compas_results = run_complete_analysis()\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ALL ANALYSIS COMPLETED SUCCESSFULLY!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5363905e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1525bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#...... CREDIT SCORING ASSESSMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9b861c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FAIRNESS INFORMATION CRITERION (FIC) ANALYSIS - ADULT DATASET\n",
      "================================================================================\n",
      "Output directory: Adult_NLEGEND_ALL_METRICS_PDF_EXCEL2\n",
      "PDF directory: Adult_NLEGEND_ALL_METRICS_PDF_EXCEL2\\PDF_plots\n",
      "Excel directory: Adult_NLEGEND_ALL_METRICS_PDF_EXCEL2\\Excel_results\n",
      "\n",
      "================================================================================\n",
      "CASE 1: ADULT - Income Prediction\n",
      "================================================================================\n",
      "Looking for Adult dataset at: C:\\Users\\Dr. Akin\\OneDrive\\2025\\Paper_2025\\PHD_Work\\adult.csv\n",
      "Loaded Adult dataset from specified folder\n",
      "Available columns: ['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status', 'occupation', 'relationship', 'race', 'sex', 'capital_gain', 'capital_loss', 'hours_per_week', 'native_country', 'income']\n",
      "Initial dataset shape: (48842, 15)\n",
      "\n",
      "Race group distribution before filtering:\n",
      "race_combined\n",
      "White    41762\n",
      "Black     4685\n",
      "APAI      1989\n",
      "Other      406\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Keeping race groups with at least 100 samples: ['White', 'Black', 'APAI', 'Other']\n",
      "\n",
      "Processed dataset shape: (48842, 15)\n",
      "Target distribution (high_income):\n",
      "high_income\n",
      "0    0.760718\n",
      "1    0.239282\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Race group distribution:\n",
      "race_combined\n",
      "White    0.855043\n",
      "Black    0.095922\n",
      "APAI     0.040723\n",
      "Other    0.008313\n",
      "Name: proportion, dtype: float64\n",
      "GROUP METRICS TABLE (Baseline Logistic Regression):\n",
      "       accuracy  selection_rate     tpr     tnr     fpr     fnr     ppv     npv      f1     auc\n",
      "White    0.7891          0.3854  0.8395  0.7716  0.2284  0.1605  0.5597  0.9329  0.6716  0.8840\n",
      "Black    0.8725          0.1601  0.6389  0.9037  0.0963  0.3611  0.4694  0.9494  0.5412  0.8691\n",
      "APAI     0.7883          0.3796  0.8710  0.7642  0.2358  0.1290  0.5192  0.9529  0.6506  0.8834\n",
      "Other    0.9412          0.1765  1.0000  0.9333  0.0667  0.0000  0.6667  1.0000  0.8000  0.9667\n",
      "Group metrics saved to: Adult_NLEGEND_ALL_METRICS_PDF_EXCEL2\\Case1_Group_Metrics.csv\n",
      "GENERATING VISUALIZATIONS FOR ALL METRICS...\n",
      "\n",
      "============================================================\n",
      "ANALYZING METRIC: ACCURACY\n",
      "============================================================\n",
      "  Saved benchmarking tiers plot for alphaF=0.05 (accuracy)\n",
      "  Saved benchmarking tiers plot for alphaF=0.1 (accuracy)\n",
      "  Saved benchmarking tiers plot for alphaF=0.15 (accuracy)\n",
      "  Saved benchmarking tiers plot for alphaF=0.2 (accuracy)\n",
      "Summary for accuracy:\n",
      "\n",
      "============================================================\n",
      "ANALYZING METRIC: SELECTION_RATE\n",
      "============================================================\n",
      "  Saved benchmarking tiers plot for alphaF=0.05 (selection_rate)\n",
      "  Saved benchmarking tiers plot for alphaF=0.1 (selection_rate)\n",
      "  Saved benchmarking tiers plot for alphaF=0.15 (selection_rate)\n",
      "  Saved benchmarking tiers plot for alphaF=0.2 (selection_rate)\n",
      "Summary for selection_rate:\n",
      "\n",
      "============================================================\n",
      "ANALYZING METRIC: TPR\n",
      "============================================================\n",
      "  Saved benchmarking tiers plot for alphaF=0.05 (tpr)\n",
      "  Saved benchmarking tiers plot for alphaF=0.1 (tpr)\n",
      "  Saved benchmarking tiers plot for alphaF=0.15 (tpr)\n",
      "  Saved benchmarking tiers plot for alphaF=0.2 (tpr)\n",
      "Summary for tpr:\n",
      "\n",
      "============================================================\n",
      "ANALYZING METRIC: TNR\n",
      "============================================================\n",
      "  Saved benchmarking tiers plot for alphaF=0.05 (tnr)\n",
      "  Saved benchmarking tiers plot for alphaF=0.1 (tnr)\n",
      "  Saved benchmarking tiers plot for alphaF=0.15 (tnr)\n",
      "  Saved benchmarking tiers plot for alphaF=0.2 (tnr)\n",
      "Summary for tnr:\n",
      "\n",
      "============================================================\n",
      "ANALYZING METRIC: FPR\n",
      "============================================================\n",
      "  Saved benchmarking tiers plot for alphaF=0.05 (fpr)\n",
      "  Saved benchmarking tiers plot for alphaF=0.1 (fpr)\n",
      "  Saved benchmarking tiers plot for alphaF=0.15 (fpr)\n",
      "  Saved benchmarking tiers plot for alphaF=0.2 (fpr)\n",
      "Summary for fpr:\n",
      "\n",
      "============================================================\n",
      "ANALYZING METRIC: FNR\n",
      "============================================================\n",
      "  Saved benchmarking tiers plot for alphaF=0.05 (fnr)\n",
      "  Saved benchmarking tiers plot for alphaF=0.1 (fnr)\n",
      "  Saved benchmarking tiers plot for alphaF=0.15 (fnr)\n",
      "  Saved benchmarking tiers plot for alphaF=0.2 (fnr)\n",
      "Summary for fnr:\n",
      "\n",
      "============================================================\n",
      "ANALYZING METRIC: PPV\n",
      "============================================================\n",
      "  Saved benchmarking tiers plot for alphaF=0.05 (ppv)\n",
      "  Saved benchmarking tiers plot for alphaF=0.1 (ppv)\n",
      "  Saved benchmarking tiers plot for alphaF=0.15 (ppv)\n",
      "  Saved benchmarking tiers plot for alphaF=0.2 (ppv)\n",
      "Summary for ppv:\n",
      "\n",
      "============================================================\n",
      "ANALYZING METRIC: NPV\n",
      "============================================================\n",
      "  Saved benchmarking tiers plot for alphaF=0.05 (npv)\n",
      "  Saved benchmarking tiers plot for alphaF=0.1 (npv)\n",
      "  Saved benchmarking tiers plot for alphaF=0.15 (npv)\n",
      "  Saved benchmarking tiers plot for alphaF=0.2 (npv)\n",
      "Summary for npv:\n",
      "\n",
      "============================================================\n",
      "ANALYZING METRIC: F1\n",
      "============================================================\n",
      "  Saved benchmarking tiers plot for alphaF=0.05 (f1)\n",
      "  Saved benchmarking tiers plot for alphaF=0.1 (f1)\n",
      "  Saved benchmarking tiers plot for alphaF=0.15 (f1)\n",
      "  Saved benchmarking tiers plot for alphaF=0.2 (f1)\n",
      "Summary for f1:\n",
      "\n",
      "============================================================\n",
      "ANALYZING METRIC: AUC\n",
      "============================================================\n",
      "  Saved benchmarking tiers plot for alphaF=0.05 (auc)\n",
      "  Saved benchmarking tiers plot for alphaF=0.1 (auc)\n",
      "  Saved benchmarking tiers plot for alphaF=0.15 (auc)\n",
      "  Saved benchmarking tiers plot for alphaF=0.2 (auc)\n",
      "Summary for auc:\n",
      "FIC ANALYSIS TABLE (Accuracy):\n",
      "   Group Pair              alphaF=0.05   Hypothesis alphaF=0.05               alphaF=0.1    Hypothesis alphaF=0.1              alphaF=0.15   Hypothesis alphaF=0.15              alphaF=0.2    Hypothesis alphaF=0.2\n",
      " APAI - Other omega=0.1529, FIC=-2.057       Reject H₀ (Unfair) omega=0.1529, FIC=-0.529       Reject H₀ (Unfair) omega=0.1529, FIC=-0.019       Reject H₀ (Unfair) omega=0.1529, FIC=0.236 Fail to reject Ho (Fair)\n",
      " Black - APAI omega=0.0842, FIC=-0.685       Reject H₀ (Unfair)  omega=0.0842, FIC=0.158 Fail to reject Ho (Fair)  omega=0.0842, FIC=0.438 Fail to reject Ho (Fair) omega=0.0842, FIC=0.579 Fail to reject Ho (Fair)\n",
      "Black - Other omega=0.0686, FIC=-0.373       Reject H₀ (Unfair)  omega=0.0686, FIC=0.314 Fail to reject Ho (Fair)  omega=0.0686, FIC=0.542 Fail to reject Ho (Fair) omega=0.0686, FIC=0.657 Fail to reject Ho (Fair)\n",
      " White - APAI  omega=0.0007, FIC=0.985 Fail to reject Ho (Fair)  omega=0.0007, FIC=0.993 Fail to reject Ho (Fair)  omega=0.0007, FIC=0.995 Fail to reject Ho (Fair) omega=0.0007, FIC=0.996 Fail to reject Ho (Fair)\n",
      "White - Black omega=0.0835, FIC=-0.670       Reject H₀ (Unfair)  omega=0.0835, FIC=0.165 Fail to reject Ho (Fair)  omega=0.0835, FIC=0.443 Fail to reject Ho (Fair) omega=0.0835, FIC=0.583 Fail to reject Ho (Fair)\n",
      "White - Other omega=0.1521, FIC=-2.043       Reject H₀ (Unfair) omega=0.1521, FIC=-0.521       Reject H₀ (Unfair) omega=0.1521, FIC=-0.014       Reject H₀ (Unfair) omega=0.1521, FIC=0.239 Fail to reject Ho (Fair)\n",
      "FIC analysis saved to: Adult_NLEGEND_ALL_METRICS_PDF_EXCEL2\\Case1_FIC_Analysis_accuracy.csv\n",
      "TIER CLASSIFICATION (Accuracy):\n",
      "\n",
      "For αF = 0.05:\n",
      "--------------------------------------------------\n",
      "White - Black: ω=0.0835, FIC=-0.670 → Unacceptable\n",
      "White - APAI: ω=0.0007, FIC=0.985 → Optimum (omega_max < 0.0125)\n",
      "White - Other: ω=0.1521, FIC=-2.043 → Unacceptable\n",
      "Black - APAI: ω=0.0842, FIC=-0.685 → Unacceptable\n",
      "Black - Other: ω=0.0686, FIC=-0.373 → Unacceptable\n",
      "APAI - Other: ω=0.1529, FIC=-2.057 → Unacceptable\n",
      "\n",
      "For αF = 0.1:\n",
      "--------------------------------------------------\n",
      "White - Black: ω=0.0835, FIC=0.165 → Questionable\n",
      "White - APAI: ω=0.0007, FIC=0.993 → Optimum (omega_max < 0.0250)\n",
      "White - Other: ω=0.1521, FIC=-0.521 → Unacceptable\n",
      "Black - APAI: ω=0.0842, FIC=0.158 → Questionable\n",
      "Black - Other: ω=0.0686, FIC=0.314 → Questionable\n",
      "APAI - Other: ω=0.1529, FIC=-0.529 → Unacceptable\n",
      "\n",
      "For αF = 0.15:\n",
      "--------------------------------------------------\n",
      "White - Black: ω=0.0835, FIC=0.443 → Questionable\n",
      "White - APAI: ω=0.0007, FIC=0.995 → Optimum (omega_max < 0.0375)\n",
      "White - Other: ω=0.1521, FIC=-0.014 → Unacceptable\n",
      "Black - APAI: ω=0.0842, FIC=0.438 → Questionable\n",
      "Black - Other: ω=0.0686, FIC=0.542 → Acceptable\n",
      "APAI - Other: ω=0.1529, FIC=-0.019 → Unacceptable\n",
      "\n",
      "For αF = 0.2:\n",
      "--------------------------------------------------\n",
      "White - Black: ω=0.0835, FIC=0.583 → Acceptable\n",
      "White - APAI: ω=0.0007, FIC=0.996 → Optimum (omega_max < 0.0500)\n",
      "White - Other: ω=0.1521, FIC=0.239 → Questionable\n",
      "Black - APAI: ω=0.0842, FIC=0.579 → Acceptable\n",
      "Black - Other: ω=0.0686, FIC=0.657 → Acceptable\n",
      "APAI - Other: ω=0.1529, FIC=0.236 → Questionable\n",
      "Tier classification saved to: Adult_NLEGEND_ALL_METRICS_PDF_EXCEL2\\Case1_Tier_Classification_accuracy.csv\n",
      "MODEL COMPARISON:\n",
      "   Model Overall Accuracy Avg FIC (αF=0.10) ω_max (αF=0.10)\n",
      "BASELINE           0.7978             0.097          0.1529\n",
      "      L1           0.8000             0.101          0.1529\n",
      "      L2           0.7978             0.097          0.1529\n",
      "✓ Model comparison saved to: Adult_NLEGEND_ALL_METRICS_PDF_EXCEL2\\Case1_Model_Comparison.csv\n",
      "\n",
      "================================================================================\n",
      "CREATING COMPREHENSIVE EXCEL REPORT\n",
      "================================================================================\n",
      "1. Saving Group Metrics Table...\n",
      "2. Saving FIC Analysis Tables for all metrics...\n",
      "3. Saving Tier Classification Summary for all metrics...\n",
      "4. Saving Benchmarking Tiers Numerical Values...\n",
      "5. Saving Summary Statistics for each metric...\n",
      "6. Saving Model Comparison...\n",
      "7. Saving Dataset Statistics...\n",
      "8. Creating Fairness Assessment Matrix...\n",
      "  Saved Excel file: ADULT_FIC_Complete_Analysis.xlsx\n",
      "\n",
      "✓ Excel report saved: Adult_NLEGEND_ALL_METRICS_PDF_EXCEL2\\Excel_results\\ADULT_FIC_Complete_Analysis.xlsx\n",
      "  Total sheets: 35\n",
      "\n",
      "Excel sheets created:\n",
      "   1. Group_Metrics\n",
      "   2. FIC_Analysis_accuracy\n",
      "   3. FIC_Analysis_selection_rate\n",
      "   4. FIC_Analysis_tpr\n",
      "   5. FIC_Analysis_tnr\n",
      "   6. FIC_Analysis_fpr\n",
      "   7. FIC_Analysis_fnr\n",
      "   8. FIC_Analysis_ppv\n",
      "   9. FIC_Analysis_npv\n",
      "  10. FIC_Analysis_f1\n",
      "  11. FIC_Analysis_auc\n",
      "  12. Tier_Summary_accuracy\n",
      "  13. Tier_Summary_selection_rate\n",
      "  14. Tier_Summary_tpr\n",
      "  15. Tier_Summary_tnr\n",
      "  16. Tier_Summary_fpr\n",
      "  17. Tier_Summary_fnr\n",
      "  18. Tier_Summary_ppv\n",
      "  19. Tier_Summary_npv\n",
      "  20. Tier_Summary_f1\n",
      "  21. Tier_Summary_auc\n",
      "  22. Benchmark_Tiers_accuracy\n",
      "  23. Benchmark_Tiers_selection_rate\n",
      "  24. Benchmark_Tiers_tpr\n",
      "  25. Benchmark_Tiers_tnr\n",
      "  26. Benchmark_Tiers_fpr\n",
      "  27. Benchmark_Tiers_fnr\n",
      "  28. Benchmark_Tiers_ppv\n",
      "  29. Benchmark_Tiers_npv\n",
      "  30. Benchmark_Tiers_f1\n",
      "  31. Benchmark_Tiers_auc\n",
      "  32. Summary_Statistics\n",
      "  33. Model_Comparison\n",
      "  34. Dataset_Statistics\n",
      "  35. Fairness_Assessment\n",
      "\n",
      "================================================================================\n",
      "SUMMARY REPORT - ADULT DATASET\n",
      "================================================================================\n",
      "ADULT DATASET KEY FINDINGS:\n",
      "------------------------------------------------------------\n",
      "Total samples: 8000\n",
      "High income proportion (>50K): 0.242\n",
      "\n",
      "Race group distribution:\n",
      "  White: 6820 (0.853)\n",
      "  Black: 782 (0.098)\n",
      "  APAI: 348 (0.043)\n",
      "  Other: 50 (0.006)\n",
      "\n",
      "High income by race group:\n",
      "  APAI: 0.233\n",
      "  Black: 0.123\n",
      "  Other: 0.120\n",
      "  White: 0.257\n",
      "\n",
      "FIC ANALYSIS SUMMARY (Accuracy):\n",
      "------------------------------------------------------------\n",
      "alphaF=0.05:\n",
      "  omega range: [0.0007, 0.1529], avg: 0.0903\n",
      "  Most unfair pair: APAI - Other (ω=0.1529)\n",
      "  Most fair pair: White - APAI (ω=0.0007)\n",
      "  Tier distribution: {'Optimum': 1, 'Acceptable': 0, 'Questionable': 0, 'Unacceptable': 5}\n",
      "alphaF=0.1:\n",
      "  omega range: [0.0007, 0.1529], avg: 0.0903\n",
      "  Most unfair pair: APAI - Other (ω=0.1529)\n",
      "  Most fair pair: White - APAI (ω=0.0007)\n",
      "  Tier distribution: {'Optimum': 1, 'Acceptable': 0, 'Questionable': 3, 'Unacceptable': 2}\n",
      "alphaF=0.15:\n",
      "  omega range: [0.0007, 0.1529], avg: 0.0903\n",
      "  Most unfair pair: APAI - Other (ω=0.1529)\n",
      "  Most fair pair: White - APAI (ω=0.0007)\n",
      "  Tier distribution: {'Optimum': 1, 'Acceptable': 1, 'Questionable': 2, 'Unacceptable': 2}\n",
      "alphaF=0.2:\n",
      "  omega range: [0.0007, 0.1529], avg: 0.0903\n",
      "  Most unfair pair: APAI - Other (ω=0.1529)\n",
      "  Most fair pair: White - APAI (ω=0.0007)\n",
      "  Tier distribution: {'Optimum': 1, 'Acceptable': 3, 'Questionable': 2, 'Unacceptable': 0}\n",
      "\n",
      "================================================================================\n",
      "ANALYSIS COMPLETE - ALL RESULTS SAVED\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import warnings\n",
    "import os\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "from openpyxl.styles import PatternFill, Font, Alignment, Border, Side\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create output directory\n",
    "output_dir = \"Adult_NLEGEND_ALL_METRICS_PDF_EXCEL2\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Also create PDF subdirectory\n",
    "pdf_dir = os.path.join(output_dir, \"PDF_plots\")\n",
    "os.makedirs(pdf_dir, exist_ok=True)\n",
    "\n",
    "# Create Excel subdirectory\n",
    "excel_dir = os.path.join(output_dir, \"Excel_results\")\n",
    "os.makedirs(excel_dir, exist_ok=True)\n",
    "\n",
    "# Set style for publication quality\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Global font settings for consistency\n",
    "plt.rcParams.update({\n",
    "    'font.size': 12,\n",
    "    'axes.titlesize': 16,\n",
    "    'axes.labelsize': 14,\n",
    "    'xtick.labelsize': 12,\n",
    "    'ytick.labelsize': 12,\n",
    "    'legend.fontsize': 12,\n",
    "})\n",
    "\n",
    "# ============================================\n",
    "# 1. LOAD AND PREPROCESS ADULT DATASET\n",
    "# ============================================\n",
    "\n",
    "def load_adult_data():\n",
    "    \"\"\"\n",
    "    Load and preprocess Adult dataset from UCI\n",
    "    \"\"\"\n",
    "    # Define your specific folder path\n",
    "    data_folder = r'C:\\Users\\Dr. Akin\\OneDrive\\2025\\Paper_2025\\PHD_Work'\n",
    "    data_file = \"adult.csv\"\n",
    "    data_path = os.path.join(data_folder, data_file)\n",
    "    \n",
    "    print(f\"Looking for Adult dataset at: {data_path}\")\n",
    "    \n",
    "    # Try to load from your specified folder\n",
    "    adult_df = pd.read_csv(data_path)\n",
    "    print(\"Loaded Adult dataset from specified folder\")\n",
    "    \n",
    "    # Check column names (Adult dataset might have spaces or different names)\n",
    "    # Standardize column names\n",
    "    adult_df.columns = [col.strip().replace('-', '_').lower() for col in adult_df.columns]\n",
    "    \n",
    "    # Show available columns\n",
    "    print(f\"Available columns: {adult_df.columns.tolist()}\")\n",
    "    print(f\"Initial dataset shape: {adult_df.shape}\")\n",
    "    \n",
    "    # Drop rows with missing values (indicated by '?' in Adult dataset)\n",
    "    adult_df = adult_df.replace('?', np.nan)\n",
    "    adult_df = adult_df.dropna()\n",
    "    \n",
    "    # Clean string columns (remove extra spaces)\n",
    "    string_columns = adult_df.select_dtypes(include=['object']).columns\n",
    "    for col in string_columns:\n",
    "        adult_df[col] = adult_df[col].str.strip()\n",
    "    \n",
    "    # Create binary target: >50K as high income (1), <=50K as low income (0)\n",
    "    adult_df['high_income'] = adult_df['income'].apply(lambda x: 1 if '>50K' in str(x) else 0)\n",
    "    \n",
    "    # Consolidate race categories as specified\n",
    "    def consolidate_race(race):\n",
    "        race = str(race).strip().lower()\n",
    "        if 'white' in race:\n",
    "            return 'White'\n",
    "        elif 'black' in race:\n",
    "            return 'Black'\n",
    "        elif 'asian' in race or 'pac' in race or 'islander' in race:\n",
    "            return 'Asian_Pac_Islander'\n",
    "        elif 'indian' in race or 'eskimo' in race or 'aleut' in race:\n",
    "            return 'Amer_Indian_Eskimo'\n",
    "        else:\n",
    "            return 'Other'\n",
    "    \n",
    "    adult_df['race_group'] = adult_df['race'].apply(consolidate_race)\n",
    "    \n",
    "    # Combine Asian-Pac-Islander and Amer-Indian-Eskimo as specified\n",
    "    def combine_race_groups(race_group):\n",
    "        if race_group in ['Asian_Pac_Islander', 'Amer_Indian_Eskimo']:\n",
    "            return 'APAI' # Asian_Pacific_Amer_Indian\n",
    "        else:\n",
    "            return race_group\n",
    "    \n",
    "    adult_df['race_combined'] = adult_df['race_group'].apply(combine_race_groups)\n",
    "    \n",
    "    # Filter to keep only our target race groups\n",
    "    target_races = ['White', 'Black', 'APAI', 'Other']\n",
    "    adult_df = adult_df[adult_df['race_combined'].isin(target_races)].copy()\n",
    "    \n",
    "    # Check and ensure minimum sample size for each race group\n",
    "    print(\"\\nRace group distribution before filtering:\")\n",
    "    race_counts = adult_df['race_combined'].value_counts()\n",
    "    print(race_counts)\n",
    "    \n",
    "    # Remove groups with too few samples\n",
    "    min_samples = 100  # Minimum samples per group\n",
    "    valid_races = race_counts[race_counts >= min_samples].index.tolist()\n",
    "    adult_df = adult_df[adult_df['race_combined'].isin(valid_races)].copy()\n",
    "    \n",
    "    print(f\"\\nKeeping race groups with at least {min_samples} samples: {valid_races}\")\n",
    "    \n",
    "    # Create additional features for better prediction\n",
    "    # Create age groups\n",
    "    adult_df['age_group'] = pd.cut(adult_df['age'], \n",
    "                                   bins=[0, 25, 35, 45, 55, 65, 100],\n",
    "                                   labels=['18-25', '26-35', '36-45', '46-55', '56-65', '66+'])\n",
    "    \n",
    "    # Create education level groups\n",
    "    def categorize_education(edu):\n",
    "        edu_str = str(edu).lower()\n",
    "        if any(x in edu_str for x in ['preschool', '1st', '2nd', '3rd', '4th', '5th', '6th', '7th', '8th', '9th']):\n",
    "            return 'Primary'\n",
    "        elif any(x in edu_str for x in ['10th', '11th', '12th', 'hs']):\n",
    "            return 'High_School'\n",
    "        elif any(x in edu_str for x in ['some', 'assoc']):\n",
    "            return 'Some_College'\n",
    "        elif any(x in edu_str for x in ['bachelors']):\n",
    "            return 'Bachelors'\n",
    "        elif any(x in edu_str for x in ['masters', 'prof', 'doctorate']):\n",
    "            return 'Graduate'\n",
    "        else:\n",
    "            return 'Other'\n",
    "    \n",
    "    adult_df['education_level'] = adult_df['education'].apply(categorize_education)\n",
    "    \n",
    "    # Create work hours category\n",
    "    adult_df['work_hours_category'] = pd.cut(adult_df['hours_per_week'],\n",
    "                                            bins=[0, 20, 40, 60, 168],\n",
    "                                            labels=['Part_Time', 'Full_Time', 'Overtime', 'Excessive'])\n",
    "    \n",
    "    # Create capital gain/loss indicator\n",
    "    adult_df['has_capital_gain'] = (adult_df['capital_gain'] > 0).astype(int)\n",
    "    adult_df['has_capital_loss'] = (adult_df['capital_loss'] > 0).astype(int)\n",
    "    \n",
    "    # Select final columns for analysis\n",
    "    final_columns = [\n",
    "        'age', 'sex', 'race_combined', 'education_num', 'marital_status',\n",
    "        'occupation', 'relationship', 'hours_per_week', 'workclass',\n",
    "        'education_level', 'age_group', 'work_hours_category',\n",
    "        'has_capital_gain', 'has_capital_loss', 'high_income'\n",
    "    ]\n",
    "    \n",
    "    # Ensure all columns exist\n",
    "    final_columns = [col for col in final_columns if col in adult_df.columns]\n",
    "    adult_df = adult_df[final_columns]\n",
    "    \n",
    "    # Handle rare categories by combining them into 'Other'\n",
    "    categorical_cols = adult_df.select_dtypes(include=['object']).columns\n",
    "    for col in categorical_cols:\n",
    "        # For columns with many unique values, combine rare categories\n",
    "        if adult_df[col].nunique() > 10:\n",
    "            value_counts = adult_df[col].value_counts()\n",
    "            rare_categories = value_counts[value_counts < 50].index\n",
    "            adult_df[col] = adult_df[col].apply(lambda x: 'Other' if x in rare_categories else x)\n",
    "    \n",
    "    print(f\"\\nProcessed dataset shape: {adult_df.shape}\")\n",
    "    print(f\"Target distribution (high_income):\")\n",
    "    print(adult_df['high_income'].value_counts(normalize=True))\n",
    "    print(f\"\\nRace group distribution:\")\n",
    "    print(adult_df['race_combined'].value_counts(normalize=True))\n",
    "    \n",
    "    return adult_df\n",
    "\n",
    "def generate_adult_data(n_samples=None):\n",
    "    \"\"\"\n",
    "    Wrapper function to load Adult data\n",
    "    n_samples parameter is kept for compatibility but not used\n",
    "    \"\"\"\n",
    "    data = load_adult_data()\n",
    "    \n",
    "    # If n_samples is specified and smaller than dataset, sample it\n",
    "    if n_samples and n_samples < len(data):\n",
    "        data = data.sample(n=n_samples, random_state=42)\n",
    "    \n",
    "    return data\n",
    "\n",
    "# ============================================\n",
    "# 2-3. MODEL & FIC (WITH FIX FOR SMALL GROUPS)\n",
    "# ============================================\n",
    "\n",
    "def compute_all_metrics(y_true, y_pred, y_prob):\n",
    "    \"\"\"\n",
    "    Compute comprehensive performance metrics with edge case handling\n",
    "    \"\"\"\n",
    "    # Handle edge cases where confusion matrix might not have all 4 values\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Get unique classes\n",
    "    classes = np.unique(y_true)\n",
    "    \n",
    "    if len(classes) == 2:\n",
    "        # Binary classification with both classes present\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "    elif len(classes) == 1:\n",
    "        # Only one class present (all 0s or all 1s)\n",
    "        if classes[0] == 0:\n",
    "            # All negatives\n",
    "            tn, fp, fn, tp = cm[0, 0], 0, 0, 0\n",
    "        else:\n",
    "            # All positives\n",
    "            tn, fp, fn, tp = 0, 0, 0, cm[0, 0]\n",
    "    else:\n",
    "        # Should not happen for binary classification\n",
    "        tn, fp, fn, tp = 0, 0, 0, 0\n",
    "    \n",
    "    # Calculate metrics with edge case protection\n",
    "    n = len(y_true)\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_true, y_pred) if n > 0 else np.nan,\n",
    "        'selection_rate': (tp + fp) / n if n > 0 else np.nan,\n",
    "        'tpr': tp / (tp + fn) if (tp + fn) > 0 else 0,\n",
    "        'tnr': tn / (tn + fp) if (tn + fp) > 0 else 0,\n",
    "        'fpr': fp / (fp + tn) if (fp + tn) > 0 else 0,\n",
    "        'fnr': fn / (tp + fn) if (tp + fn) > 0 else 0,\n",
    "        'ppv': tp / (tp + fp) if (tp + fp) > 0 else 0,\n",
    "        'npv': tn / (tn + fn) if (tn + fn) > 0 else 0,\n",
    "        'f1': f1_score(y_true, y_pred, zero_division=0) if n > 0 else np.nan,\n",
    "        'auc': roc_auc_score(y_true, y_prob) if len(np.unique(y_true)) > 1 else np.nan\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "def train_and_evaluate_models(data, target_col, protected_col, model_type='baseline'):\n",
    "    X = data.drop(columns=[target_col, protected_col])\n",
    "    y = data[target_col]\n",
    "    categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "    numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "    # Use handle_unknown='ignore' to handle unseen categories in test set\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), categorical_cols)\n",
    "    ])\n",
    "\n",
    "    # Use larger test size to ensure each group has enough samples\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42, stratify=y)\n",
    "    protected_test = data.loc[X_test.index, protected_col]\n",
    "\n",
    "    X_train_processed = preprocessor.fit_transform(X_train)\n",
    "    X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "    if model_type == 'baseline':\n",
    "        model = LogisticRegression(random_state=42, max_iter=1000, class_weight='balanced')\n",
    "    elif model_type == 'l1':\n",
    "        model = LogisticRegression(penalty='l1', solver='liblinear', random_state=42, max_iter=1000, C=1.0, class_weight='balanced')\n",
    "    elif model_type == 'l2':\n",
    "        model = LogisticRegression(penalty='l2', random_state=42, max_iter=1000, C=1.0, class_weight='balanced')\n",
    "    else:\n",
    "        model = LogisticRegression(random_state=42, max_iter=1000, class_weight='balanced')\n",
    "\n",
    "    model.fit(X_train_processed, y_train)\n",
    "    y_pred = model.predict(X_test_processed)\n",
    "    y_prob = model.predict_proba(X_test_processed)[:, 1]\n",
    "\n",
    "    group_metrics = {}\n",
    "    for group in protected_test.unique():\n",
    "        mask = protected_test == group\n",
    "        if mask.sum() > 0:\n",
    "            group_y_true = y_test[mask]\n",
    "            group_y_pred = y_pred[mask]\n",
    "            group_y_prob = y_prob[mask]\n",
    "            \n",
    "            # Check if group has enough samples and both classes\n",
    "            if len(group_y_true) >= 10:  # Minimum samples for reliable metrics\n",
    "                group_metrics[group] = compute_all_metrics(group_y_true, group_y_pred, group_y_prob)\n",
    "            else:\n",
    "                print(f\"  Warning: Group {group} has only {len(group_y_true)} samples in test set - skipping\")\n",
    "    \n",
    "    return group_metrics, (X_test, y_test, protected_test, y_pred, y_prob)\n",
    "\n",
    "class FairnessInformationCriterion:\n",
    "    def __init__(self, alphaF_values=[0.05, 0.10, 0.15, 0.20]):\n",
    "        self.alphaF_values = alphaF_values\n",
    "\n",
    "    def compute_omega(self, metric1, metric2):\n",
    "        return abs(metric1 - metric2)\n",
    "\n",
    "    def compute_fic(self, omega, alphaF):\n",
    "        return 1 - (omega / alphaF)\n",
    "\n",
    "    def classify_tier(self, fic_score):\n",
    "        if fic_score > 0.75:\n",
    "            return \"Optimum\"\n",
    "        elif fic_score > 0.50:\n",
    "            return \"Acceptable\"\n",
    "        elif fic_score > 0:\n",
    "            return \"Questionable\"\n",
    "        else:\n",
    "            return \"Unacceptable\"\n",
    "\n",
    "    def analyze_fairness(self, group_metrics, metric_name='accuracy'):\n",
    "        results = {}\n",
    "        groups = list(group_metrics.keys())\n",
    "        for alphaF in self.alphaF_values:\n",
    "            results[alphaF] = {}\n",
    "            for i, g1 in enumerate(groups):\n",
    "                for g2 in groups[i+1:]:\n",
    "                    pair = f\"{g1} - {g2}\"\n",
    "                    m1 = group_metrics[g1].get(metric_name, np.nan)\n",
    "                    m2 = group_metrics[g2].get(metric_name, np.nan)\n",
    "                    \n",
    "                    # Only compute if both metrics are valid numbers\n",
    "                    if not np.isnan(m1) and not np.isnan(m2):\n",
    "                        omega = self.compute_omega(m1, m2)\n",
    "                        fic_score = self.compute_fic(omega, alphaF)\n",
    "                        tier = self.classify_tier(fic_score)\n",
    "                        results[alphaF][pair] = {\n",
    "                            'omega': omega, 'fic_score': fic_score, 'tier': tier,\n",
    "                            'metric1': m1, 'metric2': m2\n",
    "                        }\n",
    "        return results\n",
    "\n",
    "# ============================================\n",
    "# 4. EXCEL EXPORT FUNCTIONS (UNCHANGED)\n",
    "# ============================================\n",
    "\n",
    "def save_to_excel_with_formatting(data_dict, filename, sheet_name_prefix=\"Case1\"):\n",
    "    \"\"\"\n",
    "    Save multiple dataframes to Excel with formatting\n",
    "    \"\"\"\n",
    "    excel_path = os.path.join(excel_dir, filename)\n",
    "    \n",
    "    with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:\n",
    "        # Save each dataframe to a separate sheet\n",
    "        for sheet_name, df in data_dict.items():\n",
    "            # Create full sheet name\n",
    "            full_sheet_name = f\"{sheet_name_prefix}_{sheet_name}\" if sheet_name_prefix else sheet_name\n",
    "            \n",
    "            # Truncate sheet name if too long (Excel limit is 31 characters)\n",
    "            if len(full_sheet_name) > 31:\n",
    "                full_sheet_name = full_sheet_name[:31]\n",
    "            \n",
    "            # Write dataframe to Excel\n",
    "            df.to_excel(writer, sheet_name=full_sheet_name, index=False)\n",
    "            \n",
    "            # Get the worksheet for formatting\n",
    "            worksheet = writer.sheets[full_sheet_name]\n",
    "            \n",
    "            # Apply formatting\n",
    "            for column in worksheet.columns:\n",
    "                max_length = 0\n",
    "                column_letter = column[0].column_letter\n",
    "                for cell in column:\n",
    "                    try:\n",
    "                        if len(str(cell.value)) > max_length:\n",
    "                            max_length = len(str(cell.value))\n",
    "                    except:\n",
    "                        pass\n",
    "                adjusted_width = min(max_length + 2, 50)\n",
    "                worksheet.column_dimensions[column_letter].width = adjusted_width\n",
    "            \n",
    "            # Freeze the first row\n",
    "            worksheet.freeze_panes = 'A2'\n",
    "    \n",
    "    print(f\"  Saved Excel file: {filename}\")\n",
    "    return excel_path\n",
    "\n",
    "def create_comprehensive_excel_report(adult_results, all_fic_results, metrics_list):\n",
    "    \"\"\"\n",
    "    Create a comprehensive Excel report with all numerical values\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"CREATING COMPREHENSIVE EXCEL REPORT\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    data_dict = {}\n",
    "    \n",
    "    # 1. Group Metrics Table\n",
    "    print(\"1. Saving Group Metrics Table...\")\n",
    "    data_dict['Group_Metrics'] = adult_results['metrics_df'].reset_index().rename(columns={'index': 'Race_Group'})\n",
    "    \n",
    "    # 2. FIC Analysis Tables for all metrics\n",
    "    print(\"2. Saving FIC Analysis Tables for all metrics...\")\n",
    "    for metric in metrics_list:\n",
    "        if metric in all_fic_results:\n",
    "            fic_results = all_fic_results[metric]\n",
    "            \n",
    "            # Create comprehensive FIC table for this metric\n",
    "            fic_table = []\n",
    "            pairs = list(set(p for a in fic_results.values() for p in a.keys()))\n",
    "            \n",
    "            for pair in sorted(pairs):\n",
    "                row = {'Group_Pair': pair}\n",
    "                for af in [0.05, 0.10, 0.15, 0.20]:\n",
    "                    if af in fic_results and pair in fic_results[af]:\n",
    "                        d = fic_results[af][pair]\n",
    "                        row[f'omega_alphaF_{af}'] = d['omega']\n",
    "                        row[f'FIC_alphaF_{af}'] = d['fic_score']\n",
    "                        row[f'Tier_alphaF_{af}'] = d['tier']\n",
    "                        row[f'Metric1_{af}'] = d['metric1']\n",
    "                        row[f'Metric2_{af}'] = d['metric2']\n",
    "                    else:\n",
    "                        row[f'omega_alphaF_{af}'] = np.nan\n",
    "                        row[f'FIC_alphaF_{af}'] = np.nan\n",
    "                        row[f'Tier_alphaF_{af}'] = \"N/A\"\n",
    "                        row[f'Metric1_{af}'] = np.nan\n",
    "                        row[f'Metric2_{af}'] = np.nan\n",
    "                fic_table.append(row)\n",
    "            \n",
    "            if fic_table:\n",
    "                fic_df = pd.DataFrame(fic_table)\n",
    "                data_dict[f'FIC_Analysis_{metric}'] = fic_df\n",
    "    \n",
    "    # 3. Tier Classification Summary for all metrics\n",
    "    print(\"3. Saving Tier Classification Summary for all metrics...\")\n",
    "    for metric in metrics_list:\n",
    "        if metric in all_fic_results:\n",
    "            fic_results = all_fic_results[metric]\n",
    "            \n",
    "            tier_summary = []\n",
    "            for af in [0.05, 0.10, 0.15, 0.20]:\n",
    "                if af in fic_results and fic_results[af]:\n",
    "                    tiers = {'Optimum': 0, 'Acceptable': 0, 'Questionable': 0, 'Unacceptable': 0}\n",
    "                    fic_framework = FairnessInformationCriterion()\n",
    "                    for d in fic_results[af].values():\n",
    "                        tiers[fic_framework.classify_tier(d['fic_score'])] += 1\n",
    "                    \n",
    "                    total_pairs = sum(tiers.values())\n",
    "                    for tier_name, count in tiers.items():\n",
    "                        tier_summary.append({\n",
    "                            'Metric': metric,\n",
    "                            'alphaF': af,\n",
    "                            'Tier': tier_name,\n",
    "                            'Count': count,\n",
    "                            'Percentage': (count / total_pairs * 100) if total_pairs > 0 else 0\n",
    "                        })\n",
    "            \n",
    "            if tier_summary:\n",
    "                tier_summary_df = pd.DataFrame(tier_summary)\n",
    "                data_dict[f'Tier_Summary_{metric}'] = tier_summary_df\n",
    "    \n",
    "    # 4. Benchmarking Tiers Numerical Values\n",
    "    print(\"4. Saving Benchmarking Tiers Numerical Values...\")\n",
    "    for metric in metrics_list:\n",
    "        if metric in all_fic_results:\n",
    "            fic_results = all_fic_results[metric]\n",
    "            \n",
    "            benchmark_data = []\n",
    "            for af in [0.05, 0.10, 0.15, 0.20]:\n",
    "                if af in fic_results and fic_results[af]:\n",
    "                    for pair, d in fic_results[af].items():\n",
    "                        benchmark_data.append({\n",
    "                            'Metric': metric,\n",
    "                            'alphaF': af,\n",
    "                            'Group_Pair': pair,\n",
    "                            'FIC_Score': d['fic_score'],\n",
    "                            'Tier': d['tier'],\n",
    "                            'omega': d['omega'],\n",
    "                            'Metric_Value_Group1': d['metric1'],\n",
    "                            'Metric_Value_Group2': d['metric2']\n",
    "                        })\n",
    "            \n",
    "            if benchmark_data:\n",
    "                benchmark_df = pd.DataFrame(benchmark_data)\n",
    "                data_dict[f'Benchmark_Tiers_{metric}'] = benchmark_df\n",
    "    \n",
    "    # 5. Summary Statistics for each metric\n",
    "    print(\"5. Saving Summary Statistics for each metric...\")\n",
    "    summary_stats = []\n",
    "    for metric in metrics_list:\n",
    "        if metric in all_fic_results:\n",
    "            fic_results = all_fic_results[metric]\n",
    "            \n",
    "            for af in [0.05, 0.10, 0.15, 0.20]:\n",
    "                if af in fic_results and fic_results[af]:\n",
    "                    fic_scores = [d['fic_score'] for d in fic_results[af].values()]\n",
    "                    omegas = [d['omega'] for d in fic_results[af].values()]\n",
    "                    \n",
    "                    summary_stats.append({\n",
    "                        'Metric': metric,\n",
    "                        'alphaF': af,\n",
    "                        'FIC_Mean': np.mean(fic_scores),\n",
    "                        'FIC_Std': np.std(fic_scores),\n",
    "                        'FIC_Min': np.min(fic_scores),\n",
    "                        'FIC_Max': np.max(fic_scores),\n",
    "                        'omega_Mean': np.mean(omegas),\n",
    "                        'omega_Std': np.std(omegas),\n",
    "                        'omega_Min': np.min(omegas),\n",
    "                        'omega_Max': np.max(omegas),\n",
    "                        'Num_Pairs': len(fic_scores)\n",
    "                    })\n",
    "    \n",
    "    if summary_stats:\n",
    "        summary_df = pd.DataFrame(summary_stats)\n",
    "        data_dict['Summary_Statistics'] = summary_df\n",
    "    \n",
    "    # 6. Model Comparison\n",
    "    print(\"6. Saving Model Comparison...\")\n",
    "    if 'comparison_df' in adult_results:\n",
    "        data_dict['Model_Comparison'] = adult_results['comparison_df']\n",
    "    \n",
    "    # 7. Dataset Statistics\n",
    "    print(\"7. Saving Dataset Statistics...\")\n",
    "    data = adult_results['data']\n",
    "    dataset_stats_data = []\n",
    "    \n",
    "    # Basic statistics\n",
    "    dataset_stats_data.append({\n",
    "        'Statistic': 'Total_Samples',\n",
    "        'Value': len(data)\n",
    "    })\n",
    "    \n",
    "    # Target variable statistics\n",
    "    target_col = 'high_income'\n",
    "    dataset_stats_data.append({\n",
    "        'Statistic': f'{target_col.capitalize()}_Proportion',\n",
    "        'Value': data[target_col].mean()\n",
    "    })\n",
    "    \n",
    "    # Protected attribute statistics\n",
    "    protected_col = 'race_combined'\n",
    "    for group in data[protected_col].unique():\n",
    "        count = (data[protected_col] == group).sum()\n",
    "        proportion = count / len(data)\n",
    "        dataset_stats_data.append({\n",
    "            'Statistic': f'{protected_col.capitalize()}_{group}_Count',\n",
    "            'Value': count\n",
    "        })\n",
    "        dataset_stats_data.append({\n",
    "            'Statistic': f'{protected_col.capitalize()}_{group}_Proportion',\n",
    "            'Value': proportion\n",
    "        })\n",
    "    \n",
    "    dataset_stats_df = pd.DataFrame(dataset_stats_data)\n",
    "    data_dict['Dataset_Statistics'] = dataset_stats_df\n",
    "    \n",
    "    # 8. Fairness Assessment Matrix\n",
    "    print(\"8. Creating Fairness Assessment Matrix...\")\n",
    "    fairness_matrix = []\n",
    "    for metric in metrics_list:\n",
    "        if metric in all_fic_results:\n",
    "            fic_results = all_fic_results[metric]\n",
    "            \n",
    "            for af in [0.05, 0.10, 0.15, 0.20]:\n",
    "                if af in fic_results and fic_results[af]:\n",
    "                    # Count pairs in each tier\n",
    "                    fic_framework = FairnessInformationCriterion()\n",
    "                    tiers = {'Optimum': 0, 'Acceptable': 0, 'Questionable': 0, 'Unacceptable': 0}\n",
    "                    for d in fic_results[af].values():\n",
    "                        tiers[fic_framework.classify_tier(d['fic_score'])] += 1\n",
    "                    \n",
    "                    # Determine overall fairness status\n",
    "                    if tiers['Unacceptable'] > 0:\n",
    "                        overall_status = \"Unfair\"\n",
    "                    elif tiers['Questionable'] > 0:\n",
    "                        overall_status = \"Questionable\"\n",
    "                    elif tiers['Acceptable'] > 0:\n",
    "                        overall_status = \"Acceptable\"\n",
    "                    else:\n",
    "                        overall_status = \"Optimum\"\n",
    "                    \n",
    "                    fairness_matrix.append({\n",
    "                        'Metric': metric,\n",
    "                        'alphaF': af,\n",
    "                        'Overall_Fairness': overall_status,\n",
    "                        'Optimum_Pairs': tiers['Optimum'],\n",
    "                        'Acceptable_Pairs': tiers['Acceptable'],\n",
    "                        'Questionable_Pairs': tiers['Questionable'],\n",
    "                        'Unacceptable_Pairs': tiers['Unacceptable'],\n",
    "                        'Total_Pairs': sum(tiers.values())\n",
    "                    })\n",
    "    \n",
    "    if fairness_matrix:\n",
    "        fairness_df = pd.DataFrame(fairness_matrix)\n",
    "        data_dict['Fairness_Assessment'] = fairness_df\n",
    "    \n",
    "    # Save all to Excel\n",
    "    excel_filename = \"ADULT_FIC_Complete_Analysis.xlsx\"\n",
    "    excel_file = save_to_excel_with_formatting(data_dict, excel_filename, \"ADULT\")\n",
    "    \n",
    "    print(f\"\\n✓ Excel report saved: {excel_file}\")\n",
    "    print(f\"  Total sheets: {len(data_dict)}\")\n",
    "    \n",
    "    # Print sheet names\n",
    "    print(\"\\nExcel sheets created:\")\n",
    "    for i, sheet_name in enumerate(data_dict.keys(), 1):\n",
    "        print(f\"  {i:2d}. {sheet_name}\")\n",
    "    \n",
    "    return excel_file\n",
    "\n",
    "# ============================================\n",
    "# 5. VISUALIZATIONS - UPDATED FOR PDF AND EXPANDED LEGEND\n",
    "# ============================================\n",
    "\n",
    "def plot_fic_heatmaps(fic_results, dataset_name, metric='accuracy'):\n",
    "    alphaF_values = sorted(fic_results.keys())\n",
    "    if not alphaF_values:\n",
    "        return\n",
    "\n",
    "    pairs = list(fic_results[alphaF_values[0]].keys())\n",
    "    all_groups = sorted(set(g for p in pairs for g in p.split(' - ')))\n",
    "\n",
    "    # Larger figure\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(20, 16))\n",
    "    fig.suptitle(f'FIC Heatmaps for Different alphaF Values ({metric})',\n",
    "                 fontsize=20, fontweight='bold', y=0.98)\n",
    "\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for idx, alphaF in enumerate(alphaF_values):\n",
    "        ax = axes[idx]\n",
    "        n = len(all_groups)\n",
    "        mat = np.full((n, n), np.nan)\n",
    "        group_idx = {g: i for i, g in enumerate(all_groups)}\n",
    "\n",
    "        for pair, d in fic_results[alphaF].items():\n",
    "            g1, g2 = pair.split(' - ')\n",
    "            i, j = group_idx[g1], group_idx[g2]\n",
    "            mat[i, j] = mat[j, i] = d['fic_score']\n",
    "\n",
    "        im = ax.imshow(mat, cmap='RdYlGn', vmin=-1, vmax=1, aspect='equal')\n",
    "\n",
    "        # Add value labels inside cells\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                if i != j and not np.isnan(mat[i, j]):\n",
    "                    text = ax.text(j, i, f'{mat[i,j]:.2f}',\n",
    "                                   ha='center', va='center',\n",
    "                                   fontsize=14, fontweight='bold',\n",
    "                                   color='white' if abs(mat[i,j]) > 0.5 else 'black')\n",
    "\n",
    "        ax.set_xticks(range(n))\n",
    "        ax.set_yticks(range(n))\n",
    "        ax.set_xticklabels(all_groups, rotation=45, ha='right', fontsize=13, fontweight='bold')\n",
    "        ax.set_yticklabels(all_groups, fontsize=13, fontweight='bold')\n",
    "        ax.set_title(f'αF = {alphaF}', fontsize=18, fontweight='bold', pad=20)\n",
    "        \n",
    "        # Add grid\n",
    "        ax.set_xticks(np.arange(-.5, n, 1), minor=True)\n",
    "        ax.set_yticks(np.arange(-.5, n, 1), minor=True)\n",
    "        ax.grid(which='minor', color='gray', linestyle='-', linewidth=0.5, alpha=0.3)\n",
    "\n",
    "    # Add a single comprehensive colorbar with tier labels\n",
    "    cbar_ax = fig.add_axes([0.78, 0.15, 0.02, 0.7])  # [left, bottom, width, height]\n",
    "    cbar = fig.colorbar(im, cax=cbar_ax)\n",
    "    cbar.set_label('FIC Score', fontsize=14, fontweight='bold', labelpad=15)\n",
    "    cbar.ax.tick_params(labelsize=12)\n",
    "    \n",
    "    # Bold the colorbar tick labels\n",
    "    for label in cbar.ax.get_yticklabels():\n",
    "        label.set_fontweight('bold')\n",
    "    \n",
    "    # Add tier annotations on the colorbar with more space\n",
    "    cbar.ax.text(1.6, 0.90, 'Optimum', transform=cbar.ax.transAxes, \n",
    "                 fontsize=14, fontweight='bold', va='center', ha='left', color='darkgreen')\n",
    "    cbar.ax.text(1.6, 0.60, 'Acceptable', transform=cbar.ax.transAxes, \n",
    "                 fontsize=14, fontweight='bold', va='center', ha='left', color='goldenrod')\n",
    "    cbar.ax.text(1.6, 0.350, 'Questionable', transform=cbar.ax.transAxes, \n",
    "                 fontsize=14, fontweight='bold', va='center', ha='left', color='darkorange')\n",
    "    cbar.ax.text(1.6, 0.100, 'Unacceptable', transform=cbar.ax.transAxes, \n",
    "                 fontsize=14, fontweight='bold', va='center', ha='left', color='darkred')\n",
    "    \n",
    "    # Add tier threshold lines on colorbar\n",
    "    cbar.ax.axhline(0.75, color='darkgreen', linestyle='--', linewidth=3, xmax=0.6)\n",
    "    cbar.ax.axhline(0.50, color='goldenrod', linestyle='--', linewidth=3, xmax=0.6)\n",
    "    cbar.ax.axhline(0.00, color='darkred', linestyle='--', linewidth=3, xmax=0.6)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 0.78, 0.95])\n",
    "    \n",
    "    # Save as PNG\n",
    "    plt.savefig(os.path.join(output_dir, f'{dataset_name}_FIC_Heatmaps_{metric}.png'), \n",
    "                dpi=400, bbox_inches='tight')\n",
    "    # Save as PDF\n",
    "    plt.savefig(os.path.join(pdf_dir, f'{dataset_name}_FIC_Heatmaps_{metric}.pdf'), \n",
    "                format='pdf', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_benchmarking_tiers(fic_results, dataset_name, metric='accuracy'):\n",
    "    # Sort alphaF values to ensure consistent order\n",
    "    alphaF_values = sorted(fic_results.keys())\n",
    "    \n",
    "    # Define colors for tiers\n",
    "    colors = {'Optimum': '#2E8B57', 'Acceptable': '#FFD700', \n",
    "              'Questionable': '#FF8C00', 'Unacceptable': '#DC143C'}\n",
    "    \n",
    "    for alphaF in alphaF_values:\n",
    "        if alphaF not in fic_results or not fic_results[alphaF]:\n",
    "            print(f\"No data for alphaF={alphaF} in benchmarking tiers\")\n",
    "            continue\n",
    "        \n",
    "        # Create a figure with EXPANDED width to prevent legend cutoff\n",
    "        fig, ax = plt.subplots(figsize=(20, 8))  # Increased width from 16 to 20\n",
    "        \n",
    "        data = fic_results[alphaF]\n",
    "        pairs = list(data.keys())\n",
    "        fic_scores = [data[p]['fic_score'] for p in pairs]\n",
    "        tiers = [data[p]['tier'] for p in pairs]\n",
    "        \n",
    "        # Find max positive and max negative values\n",
    "        max_positive = max(fic_scores) if fic_scores else 1.0\n",
    "        min_negative = min(fic_scores) if fic_scores else -0.25\n",
    "        \n",
    "        # Add padding (10% on positive side, 10% on negative side)\n",
    "        y_max = max_positive * 1.10 if max_positive > 0 else 0.10\n",
    "        y_min = min_negative * 1.10 if min_negative < 0 else -0.10\n",
    "        \n",
    "        # Ensure at least some range for visualization\n",
    "        if y_max - y_min < 0.5:\n",
    "            # If range is too small, center it around the data\n",
    "            center = (max_positive + min_negative) / 2\n",
    "            y_max = center + 0.25\n",
    "            y_min = center - 0.25\n",
    "        \n",
    "        # Create bar colors based on tiers\n",
    "        bar_colors = [colors[t] for t in tiers]\n",
    "        \n",
    "        # Create bars with smaller width for more compact look\n",
    "        bars = ax.bar(range(len(pairs)), fic_scores, color=bar_colors, \n",
    "                      edgecolor='black', linewidth=1.2, width=0.6)\n",
    "        \n",
    "        # Add tier threshold lines with better styling\n",
    "        ax.axhline(0.75, color='darkgreen', linestyle='--', linewidth=2.0, \n",
    "                   alpha=0.7)\n",
    "        ax.axhline(0.50, color='goldenrod', linestyle='--', linewidth=2.0, \n",
    "                   alpha=0.7)\n",
    "        ax.axhline(0.00, color='darkred', linestyle='--', linewidth=2.0, \n",
    "                   alpha=0.7)\n",
    "        \n",
    "        # Customize axes with better labels\n",
    "        ax.set_xlabel('Inter-Group', fontsize=14, fontweight='bold', labelpad=10)\n",
    "        ax.set_ylabel('FIC Score', fontsize=14, fontweight='bold', labelpad=10)\n",
    "        ax.set_title(f'FIC Benchmarking Tiers ({metric}, αF = {alphaF})',\n",
    "                    fontsize=16, fontweight='bold', pad=15)\n",
    "        \n",
    "        # Set x-ticks with rotation for readability\n",
    "        ax.set_xticks(range(len(pairs)))\n",
    "        ax.set_xticklabels(pairs, rotation=45, ha='right', fontsize=11, fontweight='bold')\n",
    "        \n",
    "        # Set dynamic y-axis limits based on actual max positive and max negative\n",
    "        ax.set_ylim(y_min, y_max)\n",
    "        \n",
    "        # Bold the y-axis tick labels\n",
    "        y_ticks = ax.get_yticks()\n",
    "        ax.set_yticklabels([f'{tick:.2f}' for tick in y_ticks], fontsize=11, fontweight='bold')\n",
    "        \n",
    "        # Add grid with lighter style\n",
    "        ax.grid(True, axis='y', alpha=0.3, linestyle='-', linewidth=0.5)\n",
    "        ax.grid(True, axis='x', alpha=0.1, linestyle='-', linewidth=0.5)\n",
    "        \n",
    "        # Add better legend - moved to top right with fewer items\n",
    "        from matplotlib.patches import Patch\n",
    "        legend_elements = [\n",
    "            Patch(facecolor=colors['Optimum'], edgecolor='black', label='Optimum (FIC > 0.75)'),\n",
    "            Patch(facecolor=colors['Acceptable'], edgecolor='black', label='Acceptable (0.50 < FIC ≤ 0.75)'),\n",
    "            Patch(facecolor=colors['Questionable'], edgecolor='black', label='Questionable (0 < FIC ≤ 0.50)'),\n",
    "            Patch(facecolor=colors['Unacceptable'], edgecolor='black', label='Unacceptable (FIC ≤ 0)')\n",
    "        ]\n",
    "        \n",
    "        # Create a separate legend for threshold lines\n",
    "        from matplotlib.lines import Line2D\n",
    "        line_legend_elements = [\n",
    "            Line2D([0], [0], color='darkgreen', linestyle='--', linewidth=2, label='Optimum Threshold (0.75)'),\n",
    "            Line2D([0], [0], color='goldenrod', linestyle='--', linewidth=2, label='Acceptable Threshold (0.50)'),\n",
    "            Line2D([0], [0], color='darkred', linestyle='--', linewidth=2, label='Unacceptable Threshold (0.00)')\n",
    "        ]\n",
    "        \n",
    "        # Place tier legend at upper left - MORE SPACE with bbox_to_anchor\n",
    "        tier_legend = ax.legend(handles=legend_elements, fontsize=10, \n",
    "                                loc='upper left', bbox_to_anchor=(1.05, 1.0),\n",
    "                                frameon=True, framealpha=0.9, edgecolor='black',\n",
    "                                title='FIC Tiers', title_fontsize=11)\n",
    "        # Make the legend title bold\n",
    "        tier_legend.get_title().set_fontweight('bold')\n",
    "        ax.add_artist(tier_legend)\n",
    "        \n",
    "        # Place threshold legend at upper left below tier legend - MORE SPACE\n",
    "        threshold_legend = ax.legend(handles=line_legend_elements, fontsize=9, \n",
    "                                     loc='upper left', bbox_to_anchor=(1.05, 0.65),\n",
    "                                     frameon=True, framealpha=0.9, edgecolor='black',\n",
    "                                     title='Thresholds', title_fontsize=10)\n",
    "        # Make the legend title bold\n",
    "        threshold_legend.get_title().set_fontweight('bold')\n",
    "        \n",
    "        # Add annotation for alphaF interpretation\n",
    "        annotation_text = f'αF = {alphaF}\\nFIC = 1 - (ω/αF)\\nω = |$M₁ - M₂$|'\n",
    "        ax.text(0.02, 0.98, annotation_text, transform=ax.transAxes,\n",
    "                fontsize=9, verticalalignment='top', fontweight='bold',\n",
    "                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
    "        \n",
    "        # Adjust layout to make room for legend - MORE SPACE allocated\n",
    "        plt.tight_layout(rect=[0, 0, 0.80, 1])  # Changed from 0.85 to 0.80 for more legend space\n",
    "        \n",
    "        # Save the figure with alphaF in the filename - BOTH PNG AND PDF\n",
    "        png_filename = f'{dataset_name}_Benchmarking_Tiers_alphaF_{alphaF}_{metric}.png'\n",
    "        pdf_filename = f'{dataset_name}_Benchmarking_Tiers_alphaF_{alphaF}_{metric}.pdf'\n",
    "        \n",
    "        plt.savefig(os.path.join(output_dir, png_filename), \n",
    "                    dpi=400, bbox_inches='tight')\n",
    "        plt.savefig(os.path.join(pdf_dir, pdf_filename), \n",
    "                    format='pdf', bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        print(f\"  Saved benchmarking tiers plot for alphaF={alphaF} ({metric})\")\n",
    "\n",
    "# ============================================\n",
    "# 6. ANALYSIS FUNCTIONS - UPDATED FOR ALL METRICS\n",
    "# ============================================\n",
    "\n",
    "def analyze_dataset(dataset_name, data_generator, target_col, protected_col, case_number=1, model_types=['baseline', 'l1', 'l2']):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"CASE {case_number}: {dataset_name}\")\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "    data = data_generator()\n",
    "    fic_framework = FairnessInformationCriterion()\n",
    "\n",
    "    baseline_metrics, _ = train_and_evaluate_models(data, target_col, protected_col, 'baseline')\n",
    "    \n",
    "    # Check if we have valid metrics\n",
    "    if not baseline_metrics:\n",
    "        print(\"Warning: No valid group metrics computed. Dataset may be too small or imbalanced.\")\n",
    "        return None\n",
    "\n",
    "    metrics_df = pd.DataFrame.from_dict(baseline_metrics, orient='index')\n",
    "    metrics_df = metrics_df[['accuracy', 'selection_rate', 'tpr', 'tnr', 'fpr', 'fnr', 'ppv', 'npv', 'f1', 'auc']]\n",
    "    print(\"GROUP METRICS TABLE (Baseline Logistic Regression):\")\n",
    "    print(metrics_df.round(4).to_string())\n",
    "    \n",
    "    # Save metrics to CSV\n",
    "    metrics_csv_path = os.path.join(output_dir, f'Case{case_number}_Group_Metrics.csv')\n",
    "    metrics_df.to_csv(metrics_csv_path)\n",
    "    print(f\"Group metrics saved to: {metrics_csv_path}\")\n",
    "\n",
    "    print(\"GENERATING VISUALIZATIONS FOR ALL METRICS...\")\n",
    "    \n",
    "    # List of all metrics to analyze\n",
    "    all_metrics = ['accuracy', 'selection_rate', 'tpr', 'tnr', 'fpr', 'fnr', 'ppv', 'npv', 'f1', 'auc']\n",
    "    \n",
    "    # Dictionary to store all FIC results\n",
    "    all_fic_results = {}\n",
    "    \n",
    "    # Dictionary to store metric summaries\n",
    "    metric_summaries = {}\n",
    "    \n",
    "    for metric in all_metrics:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"ANALYZING METRIC: {metric.upper()}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # Analyze fairness for this metric\n",
    "        fic_results = fic_framework.analyze_fairness(baseline_metrics, metric)\n",
    "        all_fic_results[metric] = fic_results\n",
    "        \n",
    "        # Only generate visualizations if we have results\n",
    "        if fic_results and any(fic_results.values()):\n",
    "            # Generate heatmaps for this metric\n",
    "            plot_fic_heatmaps(fic_results, f'Case{case_number}_{dataset_name}_{metric}', metric)\n",
    "            \n",
    "            # Generate benchmarking tiers for this metric\n",
    "            plot_benchmarking_tiers(fic_results, f'Case{case_number}_{dataset_name}_{metric}', metric)\n",
    "        \n",
    "        # Store summary for this metric\n",
    "        metric_summary = {}\n",
    "        for af in fic_framework.alphaF_values:\n",
    "            if af in fic_results and fic_results[af]:\n",
    "                omegas = [d['omega'] for d in fic_results[af].values()]\n",
    "                fic_scores = [d['fic_score'] for d in fic_results[af].values()]\n",
    "                tiers = {'Optimum': 0, 'Acceptable': 0, 'Questionable': 0, 'Unacceptable': 0}\n",
    "                fic = FairnessInformationCriterion()\n",
    "                for d in fic_results[af].values():\n",
    "                    tiers[fic.classify_tier(d['fic_score'])] += 1\n",
    "                \n",
    "                metric_summary[f'alphaF_{af}'] = {\n",
    "                    'omega_max': max(omegas) if omegas else np.nan,\n",
    "                    'omega_avg': np.mean(omegas) if omegas else np.nan,\n",
    "                    'omega_min': min(omegas) if omegas else np.nan,\n",
    "                    'fic_max': max(fic_scores) if fic_scores else np.nan,\n",
    "                    'fic_avg': np.mean(fic_scores) if fic_scores else np.nan,\n",
    "                    'fic_min': min(fic_scores) if fic_scores else np.nan,\n",
    "                    'tiers': tiers\n",
    "                }\n",
    "        \n",
    "        metric_summaries[metric] = metric_summary\n",
    "        \n",
    "        # Print summary for this metric\n",
    "        print(f\"Summary for {metric}:\")\n",
    "        for af in fic_framework.alphaF_values:\n",
    "            if af in metric_summary:\n",
    "                summary = metric_summary[f'alphaF_{af}']\n",
    "                print(f\"  αF={af}: ω_max={summary['omega_max']:.4f}, ω_avg={summary['omega_avg']:.4f}, \"\n",
    "                      f\"FIC_avg={summary['fic_avg']:.3f}, Tiers={summary['tiers']}\")\n",
    "\n",
    "    # Store FIC results for accuracy (original metric) for backward compatibility\n",
    "    fic_results = all_fic_results.get('accuracy', {})\n",
    "    \n",
    "    if fic_results:\n",
    "        # FIC table for accuracy (original)\n",
    "        fic_table = []\n",
    "        for pair in sorted(set(p for a in fic_results.values() for p in a.keys())):\n",
    "            row = {'Group Pair': pair}\n",
    "            for af in fic_framework.alphaF_values:\n",
    "                if af in fic_results and pair in fic_results[af]:\n",
    "                    d = fic_results[af][pair]\n",
    "                    row[f'alphaF={af}'] = f\"omega={d['omega']:.4f}, FIC={d['fic_score']:.3f}\"\n",
    "                    row[f'Hypothesis alphaF={af}'] = \"Fail to reject Ho (Fair)\" if d['omega'] <= af else \"Reject H₀ (Unfair)\"\n",
    "                else:\n",
    "                    row[f'alphaF={af}'] = \"N/A\"\n",
    "                    row[f'Hypothesis alphaF={af}'] = \"N/A\"\n",
    "            fic_table.append(row)\n",
    "        fic_df = pd.DataFrame(fic_table)\n",
    "        print(\"FIC ANALYSIS TABLE (Accuracy):\")\n",
    "        print(fic_df.to_string(index=False))\n",
    "        \n",
    "        # Save FIC analysis to CSV\n",
    "        fic_csv_path = os.path.join(output_dir, f'Case{case_number}_FIC_Analysis_accuracy.csv')\n",
    "        fic_df.to_csv(fic_csv_path, index=False)\n",
    "        print(f\"FIC analysis saved to: {fic_csv_path}\")\n",
    "\n",
    "        # Tier classification for accuracy\n",
    "        tier_data = []\n",
    "        print(\"TIER CLASSIFICATION (Accuracy):\")\n",
    "        for af in fic_framework.alphaF_values:\n",
    "            print(f\"\\nFor αF = {af}:\")\n",
    "            print(\"-\" * 50)\n",
    "            if af in fic_results:\n",
    "                for pair, d in fic_results[af].items():\n",
    "                    tier = fic_framework.classify_tier(d['fic_score'])\n",
    "                    msg = tier if d['fic_score'] <= 0.75 else f\"{tier} (omega_max < {0.25*af:.4f})\"\n",
    "                    print(f\"{pair}: ω={d['omega']:.4f}, FIC={d['fic_score']:.3f} → {msg}\")\n",
    "                    tier_data.append({'alphaF': af, 'Group Pair': pair, 'ω': d['omega'], 'FIC': d['fic_score'], 'Tier': tier})\n",
    "        \n",
    "        tier_df = pd.DataFrame(tier_data)\n",
    "        \n",
    "        # Save tier classification to CSV\n",
    "        tier_csv_path = os.path.join(output_dir, f'Case{case_number}_Tier_Classification_accuracy.csv')\n",
    "        tier_df.to_csv(tier_csv_path, index=False)\n",
    "        print(f\"Tier classification saved to: {tier_csv_path}\")\n",
    "    else:\n",
    "        print(\"No FIC results for accuracy metric - skipping FIC analysis table\")\n",
    "\n",
    "    # Model comparison\n",
    "    print(\"MODEL COMPARISON:\")\n",
    "    comparison = []\n",
    "    for mt in model_types:\n",
    "        mets, test_data = train_and_evaluate_models(data, target_col, protected_col, mt)\n",
    "        if mets:  # Only if we got valid metrics\n",
    "            model_fic = fic_framework.analyze_fairness(mets, 'accuracy')\n",
    "            avg_fic = np.mean([d['fic_score'] for d in model_fic[0.10].values()]) if 0.10 in model_fic and model_fic[0.10] else np.nan\n",
    "            max_omega = max([d['omega'] for d in model_fic[0.10].values()]) if 0.10 in model_fic and model_fic[0.10] else np.nan\n",
    "            _, y_test, _, y_pred, _ = test_data\n",
    "            acc = accuracy_score(y_test, y_pred)\n",
    "            comparison.append({\n",
    "                'Model': mt.upper(),\n",
    "                'Overall Accuracy': f\"{acc:.4f}\",\n",
    "                'Avg FIC (αF=0.10)': f\"{avg_fic:.3f}\" if not np.isnan(avg_fic) else \"N/A\",\n",
    "                'ω_max (αF=0.10)': f\"{max_omega:.4f}\" if not np.isnan(max_omega) else \"N/A\"\n",
    "            })\n",
    "    \n",
    "    if comparison:\n",
    "        comparison_df = pd.DataFrame(comparison)\n",
    "        print(comparison_df.to_string(index=False))\n",
    "        \n",
    "        # Save model comparison to CSV\n",
    "        comparison_csv_path = os.path.join(output_dir, f'Case{case_number}_Model_Comparison.csv')\n",
    "        comparison_df.to_csv(comparison_csv_path, index=False)\n",
    "        print(f\"✓ Model comparison saved to: {comparison_csv_path}\")\n",
    "    else:\n",
    "        comparison_df = pd.DataFrame()\n",
    "\n",
    "    # Create comprehensive Excel report\n",
    "    excel_file = create_comprehensive_excel_report(\n",
    "        {\n",
    "            'data': data,\n",
    "            'baseline_metrics': baseline_metrics,\n",
    "            'fic_results': fic_results,\n",
    "            'all_fic_results': all_fic_results,\n",
    "            'metrics_df': metrics_df,\n",
    "            'comparison_df': comparison_df\n",
    "        },\n",
    "        all_fic_results,\n",
    "        all_metrics\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        'data': data,\n",
    "        'baseline_metrics': baseline_metrics,\n",
    "        'fic_results': fic_results,\n",
    "        'all_fic_results': all_fic_results,  # Store all metrics results\n",
    "        'metrics_df': metrics_df,\n",
    "        'comparison_df': comparison_df,\n",
    "        'excel_file': excel_file,\n",
    "        'metric_summaries': metric_summaries\n",
    "    }\n",
    "\n",
    "# ============================================\n",
    "# 7. MAIN ANALYSIS\n",
    "# ============================================\n",
    "\n",
    "def run_complete_analysis():\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"FAIRNESS INFORMATION CRITERION (FIC) ANALYSIS - ADULT DATASET\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Output directory: {output_dir}\")\n",
    "    print(f\"PDF directory: {pdf_dir}\")\n",
    "    print(f\"Excel directory: {excel_dir}\")\n",
    "\n",
    "    adult_results = analyze_dataset(\n",
    "        dataset_name=\"ADULT - Income Prediction\",\n",
    "        data_generator=lambda: generate_adult_data(8000),\n",
    "        target_col='high_income',\n",
    "        protected_col='race_combined',\n",
    "        case_number=1\n",
    "    )\n",
    "    \n",
    "    if adult_results is None:\n",
    "        print(\"\\nAnalysis failed. Check dataset and try again.\")\n",
    "        return None\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"SUMMARY REPORT - ADULT DATASET\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    print(\"ADULT DATASET KEY FINDINGS:\")\n",
    "    print(\"-\" * 60)\n",
    "    data = adult_results['data']\n",
    "    print(f\"Total samples: {len(data)}\")\n",
    "    print(f\"High income proportion (>50K): {data['high_income'].mean():.3f}\")\n",
    "    print(\"\\nRace group distribution:\")\n",
    "    race_dist = data['race_combined'].value_counts()\n",
    "    for race, count in race_dist.items():\n",
    "        prop = count / len(data)\n",
    "        print(f\"  {race}: {count} ({prop:.3f})\")\n",
    "    \n",
    "    print(\"\\nHigh income by race group:\")\n",
    "    for race in sorted(data['race_combined'].unique()):\n",
    "        subset = data[data['race_combined'] == race]\n",
    "        income_prop = subset['high_income'].mean()\n",
    "        print(f\"  {race}: {income_prop:.3f}\")\n",
    "\n",
    "    print(\"\\nFIC ANALYSIS SUMMARY (Accuracy):\")\n",
    "    print(\"-\" * 60)\n",
    "    fic_results = adult_results.get('fic_results', {})\n",
    "    if fic_results:\n",
    "        for af in [0.05, 0.10, 0.15, 0.20]:\n",
    "            if af in fic_results and fic_results[af]:\n",
    "                items = list(fic_results[af].items())\n",
    "                if items:\n",
    "                    max_o = max(d['omega'] for _, d in items)\n",
    "                    min_o = min(d['omega'] for _, d in items)\n",
    "                    avg_o = np.mean([d['omega'] for _, d in items])\n",
    "                    worst_pair = max(items, key=lambda x: x[1]['omega'])[0]\n",
    "                    best_pair = min(items, key=lambda x: x[1]['omega'])[0]\n",
    "                    print(f\"alphaF={af}:\")\n",
    "                    print(f\"  omega range: [{min_o:.4f}, {max_o:.4f}], avg: {avg_o:.4f}\")\n",
    "                    print(f\"  Most unfair pair: {worst_pair} (ω={max_o:.4f})\")\n",
    "                    print(f\"  Most fair pair: {best_pair} (ω={min_o:.4f})\")\n",
    "                    \n",
    "                    # Tier distribution\n",
    "                    fic = FairnessInformationCriterion()\n",
    "                    tiers = {'Optimum': 0, 'Acceptable': 0, 'Questionable': 0, 'Unacceptable': 0}\n",
    "                    for d in fic_results[af].values():\n",
    "                        tiers[fic.classify_tier(d['fic_score'])] += 1\n",
    "                    print(f\"  Tier distribution: {tiers}\")\n",
    "    else:\n",
    "        print(\"No FIC results available.\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ANALYSIS COMPLETE - ALL RESULTS SAVED\")\n",
    "    \n",
    "    return adult_results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run the complete analysis\n",
    "    adult_results = run_complete_analysis()\n",
    "    \n",
    "    if adult_results:\n",
    "        print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a761c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the script\n",
    "#python adult_fic_analysis_fixed2.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
